Меня зовут Юрий Бушмелев. Я работаю в Lazada. Я сегодня буду рассказывать про то как мы делали наши логи, как мы их собирали и что мы туда пишем. 

Откуда мы? кто мы такие? Lazada это интернет-магазинам №1 в шести странах юго-восточной азии. Все эти страны у нас разсованны по дата-центрам. Всего дата-центров сейчас 4. Почему это важно? Потому что некоторые решения были обусловлены тем, например что между центрами есть очень слабый link. У нас микро сервисная архитектура. На данный момент я с удивлением насчитал уже 80 микросервисов. Хотя, когда я начинал готовить доклад, их было 60. Когда я начинал над этим работать их было примерно штук 20. Плюс есть довольно большой кусок PHP legacy, с которым тоже приходится жить и мириться. Все это генерирует нам на данный момент более 6 миллионов сообщений в минуту по системе в целом. Дальше я буду показывать как мы с этим пытаемся жить и почему это так.



С этими 6 миллионами сообщений надо как-то жить. Что мы с ними должны сделать? 6 миллионов сообщений, которые надо отправить из приложения, которые надо принять для доставки, которые надо доставить куда дальше для анализа и хранения. Их нужно проанализировать и как-то хранить.



Когда появилось три миллиона сообщений, у меня была примерно такой же вид. Потому что мы начинали с каких-то копеек. Понятно что туда пишутся логи приложений. Например, не смог подключиться к базе данных, смог подключиться к базе данных, но не смог что-то прочитать. Но кроме этого каждый наш микросервис пишет еще и access log. Каждый запрос прилетевший на микросервис падает в лог. Зачем мы это делаем? Разработчики хотят иметь возможность трейсинга. В каждом access логе лежит поле traceid, по которому дальше специальный интерфейс раскручивает все цепочку и красиво показывает trace. Trace показывает как проходил запрос и это помогает нашим разработчикам быстрее справляться со всякой неопознанной фигней. 



Как с этим жить? Сейчас вкратце я расскажу поле вариантов вообще как эта проблема решается. Как решать задачу сбора, передачи и хранения логов. 

Как писать из приложения? Понятно что есть разные способы. В частности есть best practice как нам завещают модные товарищи. Есть old school в двух видах как завещали деды. Есть другие способы. 



Со сбором логов примерно такая же ситуация. Вариантов решения этой конкретной части не так много. Их уже больше, но ещё не так много. 



А вот с доставкой и последующим анализом - большое количество вариаций. Мозг начинает взрываться. Описывать каждый вариант сейчас не буду. Думаю что все кто интересовался темой, у них основные варианты на слуху. 



Я покажу как мы делали это в Lazada и как собственно все это начиналось. 

Год назад я пришёл Lazada и меня бросили на проект про логи. Там было примерно вот так. Log из приложения писался в stdout и stderr. Все сделали по-модному. Но дальше разработчики это выкинули из стандартных потоков, а дальше там как-нибудь специалисты по инфраструктуре разберуться. Между инфраструктурным специалистом и разработчиком есть релизеры, которые сказали "давайте файл завернем просто в SHELL". А поскольку все это в контейнере, то завернули прям в самом контейнере, промапили внутрь каталог и положили это туда. Думаю что всем примерно очевидно что из этого получилось.



Посмотрим пока чуть подальше. Как мы эти логи доставляли. Кто-то выбрал td-agent, который на самом деле fluentd, но не совсем fluentd. Я так и не понял отношения этих двух проектов. Они вроде бы об одном и том же. Вот этот вот fluentd, написанный на Ruby читал файлы логов, парсил их в JSON по каким-то регуляркам. Потом их отправлял в Kafka. Причем в Kafka на каждую API у нас было 4 отдельных топика. Почему 4? Потому что есть live, есть staging и потому что есть stdout и stderr. Разработчики их плодят, а инфраструктурщики должны их создавать в Kafka. Контролировал Kafka другой отдел. Поэтому над было создавать ticket, чтобы они создали там 4 топика на каждый api. Все про это забывали. В общем был треш и угар. 



Что мы дальше с этим делали? Мы отправляли это в Kafka. Дальше из кафки половина логов улетало в Logstash. Другая половина логов улетала в Graylog. В итоге все это улетало в один кластер Elasticsearch.



Вот так это выглядит, если отдаленно посмотреть. Здесь вот циферками сразу отмечены проблемные места. Это вот прям совсем проблемные, с которыми надо что то делать. Про каждые грабли отдельно расскажу. 



Под пунктами 1,2,3 пишутся файлы и соответственно здесь три грабли. 

1 - это нам надо их куда-то писать. Не всегда хотелось бы давать API. Желательно чтобы запись логов была запущена в контейнере. 

2,3 - это у нас много запросов приходит в API. API пишет много данных в файл. Файлы растут. Нам их надо ротировать. Потому что иначе там никаких дисков не напасешься. Ротировать их плохо, потому что они сделаны редиректом через SHELL в каталог. Мы никак не можем его от ротировать. Нельзя сказать приложению чтобы он переоткрыл дескрипторы. Потому что разработчики на тебя посмотрят как на дурака. Какие дескрипторы? Мы вообще в stdout пишем. Инфраструктурщики сделали copy truncate в logrotate, который делает просто копию файла, truncate оригинал. Между этими процессами копирования обычно кончается место на диске.

4 - У нас были разные форматы были в разных API. Они немножко отличались. Но regexp надо было писать разные. Поскольку все это управлялось Puppet, то там была большая вязанка классов со своими тараканами. Плюс еще td-agent большую часть времени мвог есть память, тупить, он мог просто делать вид что он работает и ничего не делать. Снаружи понять что он ничего не делает было невозможно. В лучшем случае он упадет и его кто-нибудь поднимет потом. Точнее пролетит alert и кто-нибудь пойдет руками приподнимает. 

6 - И самый трэш и угар это было elasticsearch. Потому что это была старая версия. потому что у нас не было выделенных мастеров на тот момент. У нас были разнородные логи, у которых поля могли пересекаться. Разные логи разных приложений могли писаться с одинаковыми названиями полей. Но при этом внутри могли быть разные данные. Один лог приходит с Integer в поле например level. Другой лог приходит с String в поле. В отсутствие статического маппинга получается такая замечательно вещь. Если после ротации индекса elasticsearch первым пролетело сообщение со строкой, то мы живем нормально. Если вот первым пролетел с integer, то все последующие сообщения, которые прилетели со String просто отбрасываются. Потому что не совпадает тип поля.



Мы начали задаваться вот этими вопросами. Мы решили не искать виноватых. 

А на второй вопрос ответ надо что то делать. Очевидная вещь - надо завести стандарты. Некоторые стандарты у нас уже были. Некоторые мы завели чуть позже. К счастью, единый формат логов для всех api уже утвердили на тот момент. Он прописан прямо в стандарт взаимодействия сервисов. Кто хочет получать логи, они должны писать их в этом формате. Если кто-то не пишет логи в этом формате, значит мы ничего не гарантируем. Далее хотелось бы завести единый стандарт на способы записи, доставки и сбора логов. Собственно куда их писать и чем их доставлять. Идеальная ситуация это когда в проектах используется одна и та же библиотека. Вот есть отдельная библиотека логирования для Go, есть отдельный библиотека для PHP. Все кто у нас, все должны их использовать. Но на данный момент я бы сказал что процентов на 80 у нас это получается. Но некоторые продолжают есть кактусы.И вот там вот еле-еле начинает проступать SLA на доставку логов. Его пока нет, но мы над этим работаем. Потому что это очень удобно, когда инфра говорит что если вы пишете в таком формате туда-то в такой-то то место и не более N сообщений в секунду, то с вероятностью такой-то доставим туда то. Это снимает кучу головняка. Просто если SLA есть, это прямо замечательно. 



Как мы начали решать проблему? Основная грабля была с td-agent. Было непонятно куда у нас деваются логи. Поэтому первым пунктом было решено заменить td-agent. Варианты на что его заменить вот вкратце. Я здесь набросал то что мы вспоминали. Fluentd, во-первых, я с ним сталкивался в на предыдущей работе и он там тоже периодически подал. Во-вторых, это тоже самое только в профиль. Filebeat чем был удобен для нас? Тем что он на Go, а у нас большая экспертиза в Go. Cоответственно, если что мы могли его под себя как-то дописать. Поэтому мы его и не взяли. Чтобы даже соблазна никакого не было начинать его под себя записывать. Как бы очевидным решением оставшимся это всякие сислоги в таком вот количестве. Либо написать что-то свое, но мы это отбросили ровно как filebeat. Если что-то писать, то лучше писать что-то полезное для бизнеса. Для доставки логов лучше взять что-то готовое. Поэтому выбор фактически свелся syslog-ng/rsyslog. Cклонился в сторону rsyslog просто потому что у нас в Puppet уже были классы для rsyslog и я не нашел между ними очевидной разницы. Что там syslog что тут syslog.

И немножко про rsyslog. Во-первых, он клёвый потому что у него есть много модулей. У него человеко-понятный RainerScript. Офигенный бонус что мы могли его штатными средствами сэмулировать поведение td-agent и для приложений ничего не поменялось. Мы меняем td-agent на rsyslog, все остальные пока не трогаем. Cразу получаем работающую доставку. Далее mmnormalize это офигенная штука в rsyslog. Она позволяет парсить логи, но не с помощью Grok и Regexp. Она делает abstract index tree. Она парси логи примерно как компилятор парсит исходники. Поэтому это позволяет работать очень быстро, жрать мало CPU. В общем прям очень клёвая штука. Есть куча других бонусов. Я о них не буду останавливаться.



У неё есть ещё куча недостатков. Они примерно такие же как и бонусы. Основная проблема надо уметь его готовить и надо подбирать версию. Мы решили что будем писать логи в socket unix away. Причем не вв /dev/log потому что там у нас каша из системных логов, там journald в этом pipeline. Поэтому давайте писать в кастомные socket. Мы его прицеплен к отдельному rules. Не будем ничего мешать. Будет все прозрачно и понятно. Так мы собственно и сделали. Каталог с этими сокетами стандартизирован и пробрасывается во все контейнеры. Контейнеры могут видеть нужный ему socket, открывать и писать него. Почему не файл? Потому что все читали [статью про подушечку](https://habr.com/ru/company/badoo/blog/280606/), которая пыталась пробросить файл в docker и обнаруживалось что после рестарта rsyslog меняется file descriptor и docker теряет этот файл. Он держит открытом что то другое, но уже не тот socket куда пишут. Мы решили что мы обойдем эту проблему и заодно обойдем проблему блокировки.



Rsyslog делает действия указанные на слайде. Отправляет либо в релей либо в Kafka. Kafka соответствует старому способу. Релей - это я попытался использовать чисто rsyslog для доставки логов без Message Queqe стандартными средствами rsyslog. В принципе это работает. 



Но есть нюансы с тем как запихивать их потом в соответственно в эту часть. Эта часть используется между дата центрами. Здесь compressed tcp link, который позволяет сэкономить bandwidth и соответственно как-то увеличить вероятность того что мы получим какие-то логи из другого datacenter в условиях когда сильно загружен bandwidth. Потому что нас есть индонезия, в которой все плохо. Вот там эта постоянная проблема. Я подсветил часть с Logstash, Graylog и elasticsearch красным. 



Мы задумались над тем как нам собственно промониторить логи, которые мы записали из приложения. С какой вероятностью доезжают до того конца? Мы решили завести метрики. У rsyslog есть свой модуль сбора статистики, в котором есть какие-то счетчики. Он может показать вам размер в очереди, сколько сообщение пришло в такой-то action. Из них уже можно что-то взять. У нее есть кастомный счетчик, который можно настроить и он будет вам показывать количество сообщений, который записала ваше приложение. Я написал rsyslog_exporter на Python. Мы все это отправили в Prometheus, построили графики. 

С чем возникли проблемы? Проблемы возникли в том что у нас обнаружилось внезапно что наши Live API пишут по 50к сообщений в секунду. Это только Live API без staging. FА Greylog показывает только 12 тысяч сообщений в секунду. Возник резонный вопрос. А где остатки? Из чего мы сделали вывод что Greylog просто не справляется. Посмотрели. Действительно Greylog с elasticsearch не справляли этот поток. Далее другие открытия, которые мы сделали в процессе. Запись socket блокируются. Как это случилось? Когда я использовал rsyslog для доставки. В какой-то момент у нас сломался канал между datacenter. Встала доставка в одном месте, встала доставка другом месте. Все это докатилась до машины с Live API, которые пишут в socket rsyslog. Там заполнилась очередь. Потом заполась очередь на запись в unix socket, который по умолчанию 128 пакетов. Следующий write в приложении блокируется. Когда мы смотрели в библиотечку, которая пользуемся в Go приложениях, там было написано что мы пишем в socket в не блокирующим с режиме. Мы были уверенны что ничего не блокируется. Потому что мы читали [статью про подушечку](https://habr.com/ru/company/badoo/blog/280606/), которая про это написал но есть момент потому что вокруг этого вызова был еще бесконечный цикл в котором он постоянно пытался его запихать в этот сотен вот его мы не заметили в общем пришлось переписать библиотеку с тех пор она несколько раз менялась но сейчас мы избавились от блокировок во всех под системах и можно поэтому останавливаться кислоты ничего не упадет далее нужно мониторить размер очередей что соответственно как помогает вот не наступить на эти грабли во первых мы можем они тались когда мы начинаем терять сообщение во вторых можем мониторить что нас какая-то принцип проблемы с доставкой и еще неприятный момент амплификация в 10 раз в микро сервисные церкви архитектуре это вот прям вот легко на ровном месте то есть у нас входящих там запросов не так много но вот за всей этой изографы по которому бегают эти сообщения дальше и загс с логов мы реально увеличиваем нагрузку примерно раз в десять вот навскидку я к сожалению не успел посчитать точные цифры но микро сервиса они такие то есть вот это надо иметь в виду и получается что на данный момент про систему сбора логов самой нагруженная глаза де то есть там реально больше всего рпс of ну и обнаружилось что мы растем как решить проблему отцы ластиком если надо быстро получить логе в одном месте чтобы не бегать по всем машинам не собирать их там вот прям вот вот вот это вот вещь файловые хранилища это она просто железный работает гарантированно короче если вам надо собрать блоге в одном месте 1 чувак сделать от сделать вот эту вещь она офигенная она реально работает она делает banggood из любого сервака но тупо натыкать туда дисков и поставить услуг все после этого у вас в одном месте гарантированно все логе есть дальше уже можно будет настраивать какой-то там elastic какие-то игры логином чинить еще не торопясь но у вас уже есть все логе и причем вы их можете хранить сколько угодно долго ну то есть тупо насколько хватает рейдов и так вот то есть на данный момент моего доклада схема стала выглядеть вот так файл мы практически перестали писать и сейчас скорее всего отключим вообще остатки есть на локальных машинах на которых запущены а фишечки файлы написать перестанем ну во первых есть файловое хранилище которая работает очень хорошо вторых там постоянно кончается место там короче надо его мониторить весь этот геморрой и как бы проще просто закопать совсем и все дальше да вот это вот часть сока старшим грей лагом она реально парит поэтому надо от нее избавиться надо выбрать что-то одно потому что иначе это вечный геморрой мы решили выкинуть слог стаж акебоно потому что у нас есть отдел безопасности какая связь связь в том что акебоно без xs bk без шилда соответственно не позволяет сделать вот сюда вот ходить одним сюда ходить другим то есть эти данные могут видеть одни отделы эти данные могут видеть другие дела ему заморачиваться покупкой всеми этими делами было неохотой как бы надо всем уже будут что вчера все работал поэтому взять грейлок в нем все это есть у меня не нравится но он работает соответственно и далее мы просто купили нового железа поставил там свежий грелок перенесли все структурированы жестко логе со строгими форматами в отдельной игры лог что вот того там тех взрывов с тем что у нас тут интеджер и тут стринги не возникало там мы решили это просто организационного что собственно новый игрок входит на данный момент вот эти вот вернет это еще не на данный момент это еще раньше мы просто записали все в докер взяли кучку серверов раскатали там три инстанции кафки 7 и серверов горелова двоечку потому что хотелось elastic черт 5 там два три то бишь все это на рейдах из и ждите подняли увидели index in raid до 100 км до 100 тысяч сообщений в секунду и увидели цифру что 40 терабайт данных в неделю мне показывают стоп у меня осталось буквально три слайда и соответственно как бы вот вот вот опять блины затыки у нас идет 2 распродажу там про которые рассказывали яндекс деньги только что мы переехали за 6 миллионов у нас брелок не успевает прожевывать как-то надо опять выживать выжили мы вот так то есть добавили еще немножко серверов и ssd на данный момент то есть мы живем вот таким способом и сейчас мы проживаем уже 160 сообщений в секунду но пока еще не понятно сколько там еще то есть мы не уперлись в лимит пока непонятно сколько мы реально можем вытянуть из этого и вот такие у нас планы на будущее то есть из них реально самое важное наверное вот муха это круто у нас его пока нет потому что доставкой orsis лог запущен на верное несколько машин настроены одинаково но настроенность так что едет все через одну машину то есть надо потратить время чтобы настроить какой-то файлов между ними собрать метрики логос сделать родители мид и чтобы у нас одна сумма сошедшая с ума а фишечка не убивал там нам бандуристы все остальное и наконец подписать какой-то с разработчиками что чуваки мы реально можем служить вот столько если вы пишете больше ну блин ну извините и написать документацию кратенько итоге всего что мы пережили во-первых стандарты во-вторых эти слоги торт третьих как syslog работает именно вот так как написано ну и в общем давайте наверно перейдём к вопросам [аплодисменты] описать файл надо опять очень не хотелось то есть это когда у тебя а фишечка пишет там не знает тысячи сообщений в секунду ну ты даже если у вас сейчас будешь ротировать надо писать либо в pipe ну на что меня разработчики спросили а что будет если вот тот процессу который мы пишем упадет я просто не нашел чем ответить искал ok давайте мы не будем так делать просто и все привет спасибо за доклад вопрос почему вы не пишете логе просто выжди fs это следующий этап то есть мы про него подумали самом начале но поскольку в данный момент тупо нет ресурсов этим заниматься он у нас висит так в long term solution где-нибудь там потом это но собственно в догонку просто колоночный формат был бы более я все понимаю мы мы за обеими руками приходить надо здесь ходить нельзя да и второй вопрос не совсем понятно вот вы сказали что пишите версий слог там можно и дипе можно чипе но если египет то тогда как вы гарантируете доставку есть два момента первый я сразу всем говорю что мы не гарантируем доставку логов чуваки это это реально очень клёвая штука теле запомните и всегда говорится и себе в том числе потому что он реально когда разработчики приходят и говорят о давайте мы туда начнем писать как вот финансовые данные и будем гарантировать что вот и вы нам там их где-нибудь будете складывать на случай если что случится отлично тему чуваки давайте вы начнете блокироваться на запись socket и делать это в транзакциях вот сок гарантированно вы это нам socket положили и вы видели что мы это с той стороны получили и тут вот в этот момент всем сразу становится не надо то есть ну не надо вам окей тогда как каких на вопрос если вы не гарантировать запись соки тому как зачем нам гарантировать доставку мы как бы делаем bst ford мы реально стараемся доставить вот как можно больше и как можно лучше но мы не даем стопроцентной гарантией поэтому не надо писать туда финансовые данные для этого есть база данных транзакциями вот туда туда туда а там кстати вопрос какой то как-то по-другому я сейчас вот часть рассказал помощью чё ты там было спасибо за доклад у меня вопрос следующий когда api генерирует какое-то сообщение в лоб и далее передает управление микро сервисом то не сталкивались не сталкивались ли вы с проблемой что сообщение от разных микро сервисов приходится в неправильном порядке и соответственно когда службе эксплуатации нужно следить порядок прохождения сообщения через микро сервис и вот возникает путаница это нормально что они приходят в разном порядке к этому надо быть готовым потому что любая сетевая доставка вам не гарантирует порядок то есть надо либо то есть нам тратить специально ресурсы на это мы это как но если вот возьмем файловые хранилища то туда она прилетает просто вот кладется в файл на каждую каждая пишите есть свой файл куда она кладет свои логе получается верный там марсе слог просто их раскладывается по папочкам соответственно там у каждого api там есть слова и свои логе куда можно пойти посмотреть и потом по времени по таймс темпу в этом блоге можно их потом по сопоставлять как бы если они идут смотреть брелок игры лог не упал на данный момент он работает это можно реально посмотреть то там от сортируется по таймс темпу там все будет хорошо ну соответственно таймс темп может отличаться на некоторые долю миллисекунды и timestream генерит самоа фишечка в этом в этом собственно вся фишка то есть теперь у нас есть три типа к счастью наконец вот у нас соответственно и 5 генерит таймс темпл уже в самом сообщении то есть его не ел чеснок добавлять спасибо спасибо заглянет доклад подскажите вот не очень понятно касательно взаимодействие между дата центрами то есть вам когда-то центра понятно как логе там собрали обработали и так далее вот что дальше между dc или каждый dc живет своей жизнью и только так почти то есть венчур и у нас каждая страна она находится в каком-то одном дата-центре то есть нас нету на данный момент нет размазывания чтобы один венчур был размещен по разным доцентом поэтому не надо их объединять как бы эти куски внутри каждого центра и склок relay то есть это число собственно сервер на самом деле две менеджмент машины это они одинаково настроены как я уже сказал но пока просто трафик идет через одну из них она там логе все агрегирует у нее с диска очередь на всякий случай она жмет их и отправляет в центральный в один дат в центр сингапурский где дальше они уже пихают в грейлок и файловый столь же у нас пир да да это центр то есть каждый до центре есть свой файловый стоишь на случай как раз если у нас пропала connectivity мы все-таки имеем все логе там и они все они там останутся они там будут сохранены то есть соответственно если вдруг что вы оттуда и поднимай ну тоже можно пойти туда и посмотреть как link поднял спасибо за доклад скажите пожалуйста как вы мониторите то что вы не теряете логе хороший вопрос мы их теряем на самом деле и мы эту мониторим я но это запустили блям вот буквально может быть месяц назад в библиотеке которые используют гош ушные опиши чеки есть метрики то есть она умеет посчитать сколько раз она не смогла записать в socket то есть там на данный момент есть хитро эвристик а то есть он как там есть буфер он пытается записывать из него сообщение в соке соответственно если буфер переполнится он начинает их дропать и еще считает сколько он их подгруппу соответственно если там начинает переполняться счетчики мы об этом узнаем они сейчас приезжают также в прометей и у графа не можно посмотреть графики is configured alert и соответственно тоже можно но пока непонятно кому из вас есть еще над чем работать спасибо власти кивы с резервированием хранить в логе сколько вас одна одна реплика одна реплика то есть это всего одна реплика ли это мастер и репликами . но в двух экземплярах данные хранятся домой а еще размер буфера из логова как-то подкручивали ли вы там на стандартном сказали что вот не больше восьми килобайт разработчикам дайте мусор хара хорошо кстати что ты опять упомянул потому что про это забыл презентаций указать мы пишем в кастомные unix socket в дейтаграммы unix socket это нам сразу же накладывает ограничение 128 килобайт то есть мы не можем записать в него просто больше сначала разработчика тильтом дайте нам 16 мегабайт хотя бы не сказали ну давайте дописать в сеть они сказали ну нет ладно давайте сюда . лабдхва это всем и на этом мы собственно как бы и ограничили их и прописали сейчас тоже в стандарт поэтому вот кто хочет подать старик жизнь те пишут 128 килобайт библиотеки причем обрезают и ставит флаг что сообщение обрезана у нас стандарте самого вот этого сообщения у них есть прям специальные поле которая показывает была ли она обрезана при записи или нет так что мы имеем возможность отследить и этот тоже момент битый час он и соответственно вы не пишете битве джейсон будет отброшен самим на руси слогом потому что он потом нет кафе слогом нибудь отброшена будет отброшен либо авелем relay потому что слишком большой пакет либо потом уже и ластиком потом ниткой логом потому что не сможет джейсон распарсить но здесь есть нюансы которые надо фиксить и они большей частью завязанный от syslog то есть я уже заполнил туда несколько и shews над которыми надо еще работать спасибо полу с той стороны у кого-то будущего просто трясти подскажите пожалуйста почему кафка ребятни пробуйте вопрос если можно сразу по поводу грей logo как он не складывается вообще на таких нагрузках на таких объемов и вот масштабируется не складывается у нас с грегом не складывается до ogre лог у нас складывается то есть но с ним реально проблема он своеобразная штукой на самом деле он не нужен я бы предпочел писать за все слова напрямую власти и смотреть потомки банной но надо утрясти вопрос с безопасниками то есть это возможный вариант нашего развития когда мы вытянем грейлок и мы будем использовать икебану блок стоишь смысла не будет потому что я могу все это же самое сделать со слогом поэтому и у него есть модуль для записи власти ксир чьи там все стороны все хорошо закрыл логом но вот пока вот мы с ним пытаемся как-то жить мы его даже немножко потяни ли ну там есть еще пространство для улучшений насчет кафки ну во-первых так исторически сложилось когда я пришел она уже была и в нее уже писали логин the first просто подняли другой кластер и переехали в него лагами как что потому сейчас он стал наш прям вот мы его менеджер мы знаем как он себя чувствует насчет рабби танки у нас совершенно у нас не складывается мжд темпе у нас складывается но до недавнего момента прямо с продакшене он есть и с ним были проблемы вот сейчас вроде бы перед 1111 его заманили и он стал нормально работать но до этого я был не готов и выпускать production есть еще один момент да я вспомнил когда я про него думал брелок умеет читать версию мтп 0.9 мл syslog умеет писать вершинки и 1.0 и нет ни одной из овчины которые посередине умеет и то и другое есть есть либо то либо другое и поэтому на данный момент только кафка но там тоже свои нюансы потому что мгк той версии слова которые мы используем может потерять вот весь буфер сообщение которое она выгребла из кафе слога но пока мы с этим миримся ботинок 2 доклад вот про кавказ . точнее вы есть пользу потому что она у вас в было датой больше никаких целей не столь она используется командой дать сайнс а вот та которая была сразу и у них там какие-то свои вещи в ней там то есть это совсем отдельный проект и которая к сожалению чего рассказать не могу мне не в курсе но на совместно она она была на самом деле видение команда додает сайнс мы просто ее вот когда логе заводили решили просто использовать чтобы не ставить еще и свою сейчас мы обновили грейлок у нас предатель алла совместимость потому что довольно старенькая версия и нам пришлось запада завести сейчас свою и заодно мы избавились от этих четырех топиков на каждые 5 мы сделали один широкий топик на все лайвы один широкий hot topic на все стринги и просто все туда пуляем у нас там брелок параллельно все это выгребает и все хорошо спасибо последний вопрос ну еще под человек вот здесь вот спасибо меня зовут алексей 2 вопрос если можно 1 зачем нужно вот это шаманство с сокетами пробовали или использовать лук драйвер syslog для контейнеров на тот момент когда мы этим вопросом задавались с докера у нас были отношения очень напряженные потому что был какой-то 1.0 может быть даже или 0.9 docker и он сам по себе был странные как бы в продакшене особенно во вторых если в него еще и логе пихать месть непроверенные подозрение что он пропускает все логе через себя то есть через демон собственного докера и в этом случае если у нас 1 и 5 сходит с ума то остальные поют и каются в то что они могут отправить как бы выступать с т д л я не знаю к чему это приведет то есть у меня есть подозрение основаны на каком-то внутреннем ощущении что не надо просто его вот в этом месте использовать если у вас там есть у нас функциональное тестирование у них есть свой собственный кола стиральщика слугами они используют лоб драйверы и у них там вроде бы даже все хорошо пока не поумнел сразу пишут в грейлок мы на тот момент когда все это затевали нам надо был чтобы она просто работала ту потому что все наелись уже все это эти пустоты всем очень хотел чтобы она работала и поэтому решили сделать вот так может быть со временем когда технологии ужас кто-то придет и скажет да ладно на сто лет уже работает нормально ну скажем ok давайте попробуем мы здесь не фиксированы этом спасибо и второй вопрос вы доставку между центрами делаете на все слоги почему не на кафки мы делаем итак итак на самом деле по двум причинам если канал совсем убитый то у нас все логе даже в сжатом виде не пролазит него а кафка позволяет их просто терять в процессе то есть мы этим способом избавляемся от залипания вот этих влогов то есть просто используем кафку в этом случае напрямую если у нас канал хороший и хочется освободить его то мы используем их syslog но на самом деле можно настроить его так чтобы он дропал как бы точно не пролезла сам но пока вот как бы оно работает я туда не лазил как сейчас время появится после продаж после 11 11 11 от полезут снова как бы рефакторинг взять кусок еще раз возможно попробую на данный момент мы просто где-то используем доставку и rsi слогом упрямую где-то кафку понятном спасибо большое если у вас есть ещё вопросы вы можете подойти задать их лично давайте юрию спасибо [аплодисменты]