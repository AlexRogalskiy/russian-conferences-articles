ну давайте мы начнем потому что мы и так пять минут до ждали на всякий случай чтобы все кто желает успели дойти меня зовут юрий бушмелев я работаю в лозанне я сегодня буду рассказывать про то как мы делали наши логе как мы их собирали и что мы туда пишем я к сожалению пропустил доклад предыдущего оратора у меня есть подозрение что многие вещи уже успел рассказать и многие вещи мы сделали примерно одинаково поэтому извините если я буду повторяться ну зато можно будет потом посравнивать решить у кого решение круче и кому еще идти дальше так куда здесь тыкать предел вот здесь должен торчать он назим на радиорынке он включен батарейка работает вперед назад никто фокус все дела фокусе в какой стороны она открыта вот уже да да и фокус удался ну собственно откуда мы кто мы такие и почему у нас все вот так я работаю глаза dia конкретно работаю в сингапурском офисе но москве тоже есть большой разработки и это в общем то вот theologie которые мне приходится обрабатывать это заслуга наших московских коллег большей частью поэтому коллеги если здесь присутствуете но извините кто собственно мы такие лозада это интернет-магазинами разин шести странах юго-восточной азии ну и вот они там дальше перечислены собственно все эти страны у нас обработку обрабатываются они как раз саванны по дата-центром всего до центра сейчас 4 почему это важно ну потому что некоторые решения были обусловлены тем например что между центрами есть очень слабый lingq от которой плохо и медленно влазит все включая логе у нас микро сервисной архитектура то есть на данный момент я с удивлением на считал уже 80 микро сервисов хотя когда я начинал готовить от доклад их было 60 когда я начинал над этим работать и было примерно штук 20 и плюс есть довольно большой кусок legacy bh пышного в котором тоже приходится жить и мириться и вот все вот это вот генерирует нам на данный момент более 6 миллионов сообщений в минуту по системе в целом то есть вот такой url каунтер вот 6 миллионов сообщений и дальше я буду показывать как мы с этим пытаемся жить и почему это так вот собственно эти 6 миллионов сообщений с ними надо как-то жить как я уже говорил что мы с ними должны сделать это 6 миллионов сообщений которые надо отправить из приложения которое надо принять для доставки который надо ставить куда дальше для анализа и хранения соответственно проанализировать и как-то хранить и вот когда я увидел уже вот когда появилось три миллиона сообщений вот у меня была примерно такой же вот вид потому что господи мы начинали с каких-то копеек чего туда пишется ну понятно что пишут слоги приложений то есть там не смог подключиться к базе данных смог подключиться к базе данных на весь мог четко прочитать и всякие такие вещи на кроме этого каждая наша каждый наш микро сервис пишет еще и axis lock то есть каждый запрос прилетевший микро сервис падает в лог зачем мы это делаем отвечает разработчики они наверное отвечать не будут они хотят иметь возможность рейтинга я краем уха услышал что ломоты есть что-то похожее мы видим мы делаем от одинаковым то есть в каждом access логе лежит палитрой сойди по которому дальше специальные специальный интерфейс раскручивает все цепочку и красиво показывает trace то есть как проходил запрос и это помогает нашим разработчикам быстрее справляться с со всякими со всякой неопознанный фигней как с этим жить вот сейчас вкратце я расскажу поле вариантов вообще как эта проблема решается как держать задачу сбора передачи и хранения логов то есть как писать из приложения понятно что есть разные способы ну вот тут в частности как бы есть best practice зови как нам завещают всякие модные товарищи есть old school в двух видах там как завещали деды как завещали отцы ну есть всякие другие способы со сбором логов ну примерно такая же ситуация то есть вариант решение этой этой конкретной части ну не так много они их уже больше но ещё не так много а вот сюда вставка из последующим анализом там вариации просто начинает взрываться и описывать каждый вариант и опрос сейчас не буду я думаю что все кто интересовался темой все примерно на слуху у них вот все основные вариант я покажу как мы делали это в ла сзади и как собственно все это начиналось год назад я пришёл по заду и меня бросили на проект прологе и там было примерно вот так то есть лук из приложения писался в стадо от стр то есть все сделали по-модному но дальше как бы разработчики это выкинули из стандартных потоков дальше там как intense разберется ну там между инфра и разработчик место лидера которые сказали ну ладно давайте файл завернем просто сел и мы все а поскольку все это в контейнер то завернули прям в самом контейнере промо пили внутрь каталог и положили оттуда но я думаю что в общем всем примерно очевидны что из этого получилось ну давайте посмотрим пока ты чуть подальше как мы эти блоги доставляли то есть кто-то выбрал тебе jint который на самом деле фрунзе но не совсем френди то есть я так и не понял для по краткому в угле нею отношения этих двух проектов они вроде бы об одном и том же и вот этот вот frenzy написанный на руках читал файлы логов пар силы джейсон по каким-то там вот там и панк-рок внутри и потом их отправлял в кафку причем в кафку он улетал у нас был на каждую а фишечку отдельных 4 топиков кафки почему 4 потому что есть лайв есть стейджинг и потому что из теста дауд std эру и разработчики их плодят а инфра как бы должна их создавать в кафки причем кафка контролировал с другим отделам и поэтому над был лишь ticket чтобы они создали там 4 топика на каждой api и все про это забывали и общем был про шугар как мы дальше это что мы дальше с этим делали мы отправляли это то есть в кафку дальше из кафки половины там логов улетал в лог стаж другая половина логов улетал там делилась в один брелок что там какая-то выиграй лог я на это torello 5 вот той же с тем же видом джеки чана и и в общем все это в итоге все это улетала в один в один кластер ластик search а то есть вот это весь бардак он падал туда опять же скорее всего в предыдущем докладе уже описали почему так делать не надо ну и вот так вот это в принципе выглядел если так отдаленно сверху посмотреть не надо это фотографировать не надо так делать не надо вот здесь вот циферками сразу отмечены проблемные места ну их на самом деле больше ну 6 это вот который прям совсем проблемная которыми надо что то делать и по которая сейчас отдельно расскажу то есть здесь вот они описаны давай давайте я сейчас вернусь просто это оставим тем кто будет потом читать эту презентацию уже без моего доклада то есть смотрите значит вот вот здесь у нас вот пишутся файл и соответственно здесь сразу три грабли 1 это нам надо их куда-то писать и не всегда хотелось бы давай записочки возможность куда записать то есть примут файл там желательно чтобы она была запущена в контейнере еще лучше чтобы она была readonly я просто сисадмин как бы я ни разработчик поэтому меня немножко альтернативные взгляды на эту вещь вот второй момент это у нас много запросов приходит в опишу опишите пишет много файлов вернее много данных в файл файл и растут нам их надо рокировать потому что иначе там никаких дисков не напасешься ротировать их как плохо потому что они сделаны редиректом через шею в каталог и мы никак не можем его от ротировать то есть нельзя сказать приложению ты там это дескрипторы период крой потому что разработчики на тебя посмотрят как на дурака какие дескриптором вообще вас тут пишут и как бы ну окей сказала инфра сделала капитан кейт в логово трети который сделал просто копию файла танкист оригинал соответствие между вот этими процессами копирования происходит кончается место на диске и понеслась в общем дальше дальше у нас вот этот тебе gent а нет у нас еще вот отчетом 4 а ну да нас еще разные форматы были в разных кошечках они немножко отличались но regexp а надо было писать разные и поскольку все это менеджер спать там там была вот такая вязанка классов со своими тараканами и плюс еще cd джин большую часть времени просто тут он мог есть память он мог купить он мог просто сделать ведь что он работает и ничего не делать и снаружи понять что он ничего не делает был невозможно лучшем случае он упадет и его кто-нибудь поднимет потом нет пролетит alert в инфаркта не пойдет руками приподнимает вот и самый трэш и угар это было ластик search потому что вот потому что это была старая версия потому что у нас не было выделенных мастеров на тот момент у нас были разнородные логе которые у которых поля могли пересекаться то есть разные логе разных приложений могли писаться с одинаковыми названиями полей новые при этом внутри могли быть разные данные то есть один блок приходит с интерьером в поле например level другой лак приходит со стрингами в пользу и в отсутствие статического маппинга получается такая замечательно вечность если первому прилетела сообщение после ротации индекса власти ксир чьи первым пролетела сообщение со строкой то мы живем нормально если вот первым пролетел с интерьером то все последующие сообщения которые прилетели со стрингами они просто отбрасываются потому что не совпадает типа ли все куда логе делись кто ну вот на вот и вот мы начали сдаваться вот этими вопросами ну первый вопрос мы решили не не искать виноват хочу делать надо надо что то делать и как бы очевидней шайа вещи надо завести стандарты ну некоторые стандарт у нас уже были некоторые мы завели чуть позже то есть к счастью единый формат логов для всех api уже утвердили на тот момент он прописан прямо в стандарт взаимодействия сервисов соответственно вот кто хочет получать логе они должны писать их в этом формате если кто-то не пишет логин от информация значит мы ничего не гарантируем чуваки молодцы пишите как хотите сами доставлять мы ничего с этим сделать не будет далее хотелось бы завести единый стандарт на способы записи доставки и не сбора логов то есть собственно куда их писать и чем их доставлять и вообще идеальная ситуация это когда в проектах используется одна и та же библиотека вот есть отдельно библиотекам лакирование для кошечки есть отдельный библиотека для пых пышечки и все кто у нас есть все должны их использовать но на данный момент я бы сказал что процентов на 80 у нас это получается некоторые продолжают есть кактусы и вот там вот еле-еле так начинает проступать усилий на доставку логов его пока нет но мы над этим работаем потому что это очень удобно когда инфра говорит что если вы пишете в таком формате туда-то в такой-то то место и не более сталь кит сообщений в секунду условно говоря там и это с вероятностью такой-то доставим туда то это снимает кучу головняка просто если она есть это прямо замечательно как мы начали решать проблему основная граблю было стейджинг то есть был непонятный куда у нас девайс слоги доставляются они собираются и они где они вообще поэтому первым пунктом было решено заменить содержит варианты на что его заменить вот вкратце я здесь набросал это то что мы вспоминали о frenzy как бы во-первых я с ним сталкивался в хелпе и уже и он там тоже периодически подол во вторых ну как бы тоже самое только в профиль файл бит чем был удобен для нас тем что нога а у нас большая экспертиза в г соответственно если что мы могли его под себя как-то дописать и поэтому мы его и не взяли даже соблазна никакого не было начинать его в себя записывать нафиг сразу ну и как бы очевидным решением оставшимся опять же я сисадмин монета привычно это всякие си слоги вот в таком вот количестве либо написать что-то свое но мы его отбросили волн как файл бит сразу заниматься лучше слив счет писать лучше 50 счет полезны для бизнеса для доставки логов light взять что-то вы готовы поэтому выбор фактически свелся водка число конверсий слог и склонился в сторону syslog просто потому что у нас в памяти уже были класс или rsi слога и я не нашел между ними очевидной разницы как было что там на все слог что тут с лодкой да у них там документацию кого-то хуже у кого-то лучше кто-то уметь так кто-то умеет по-другому и немножко правил syslog прямо кратенько во-первых он клёвый потому что куча модулей у него человек понятки райнер скриптонита упячка которые вы часто видите вот так упячки она уже deep реки это ты не надо ей пользоваться использовать красивая линия скрипт офигенный бонус что мы могли его штатными средствами samuli ровать поведение tidy джон то и соответственно для приложений ничего не поменялось то есть мы меняем сидеть на верфи слог все остальные пока не трогаем сразу получаем работающую доставку далее ммр мало из это просто это прямо офигенная штука в карте слоги она позволяет парсить логе но не грока my legs to me она делает абстракции индекс 3 то есть она parkside логика примерно как не знаю как компилятор парсит исходники и поэтому это позволяет работать очень быстро жрать малую просто и в общем прям очень клёвая штука есть и есть куча других бонусов я о них не буду останавливаться у неё есть ещё куча недостатков они примерно такие же как и бонусы и вот основная проблема надо уметь его готовить и надо подбирать версию дальше можно в кулуарах будет обсудить дальше соответственно мы решили что будем мы писать логе в socket unix away причем не в d флаг потому что там у нас каши и системных логов там на журнал д в этом плане и нафиг все это не надо поэтому давайте писать в кастомные socket принцип мы его прицеплен к отдельному rules эту не будем ничего мешать будет все прозрачно и понятно так мы собственно и сделали и каталог с этими сокетами стандартизированы пробрасывать во все контейнеры соответственно контейнеры могут видеть каждый это нужно ему соки и братья открывать и писать него почему не файл потому что все читали статью на хопре про подушечку по моему которая пыталась пробросить файл в docker и обнаружил что после рестарта ростислава меняется file descriptor и докер теряет этот файл то есть он держит открытом что то другое но уже не тот соки туда пишут вот мы решили что мы так мы обойдем эту проблему и заодно обойдем проблему блокировки ну про нее чуть позже может быть упомянут дальше соответственно и число квот делает все эти действия и отправляет либо в релейный буковку кафка чтобы соответствие старому способу или это я попытался использовать чисто сыр syslog для доставки логов вот то есть без всяких там мисочку просто примут стандартными средствами эти слога в принципе это работает но есть нюансы с тем как запихивать их потом в соответственно вот в эту часть так тут у нас цвета немножко поплыли ну ладно в общем то есть вот эта часть она используется между дата центрами то есть здесь compressed спеллинг который позволяет сэкономить банды и соответственно как-то увеличить вероятность того что мы получим какие-то logis ольгово до центра в условиях когда в anviz собственно такой прям в общем канал за sram условно говоря потому что нас есть индонезия в которой все плохо и вот там эта постоянная проблема далее здесь вот я подсветил вот эту часть слог стажем грей лагом и ластиком красным потому что вроде бы все зафер все заработало короче логе поехали все хорошо и тут мы задумались над тема как нам собственно промониторить вообще в итоге которые мы записали из приложения ни с какой вероятностью доезжают до того конца не чтобы где мы их видим уже окей мы решили завести метрики возраст слово есть своя с свой модуль сбора статистики которым есть какие-то счетчики например он может показать вам размер в очереди или там сколько сообщение пришло в такой-то action соответственно из них уже можно что-то взять плюс у нее есть кастомный счетчик который можно настроить и он будет вам показывать например количество сообщений который записал какая-то а фишечка далее я написал вам число как spare tire на питание и мы все это пули в прометея усы построили графики всё клёво графики красивые метрики диалогов очень хотелось бы но пока мы не успели их настроить с чем возникли проблемы проблемы возникли в том что у нас обнаружилось внезапно что нашла его и опишите пишут по 50к сообщений в секунду то есть это только лайвы бестий джин гав и без всякого там у соседних всяких товарищей of grey логином показывает только 12 тысяч сообщений в секунду и как возник резонный вопрос а где остатки то собственного из чего мы сделали вывод что крыло просто не справляется то есть посмотрели действительно крыло xy ластик search меня силе вали этот поток далее другие открытие которые мы сделали в процессе это запись socket блокируются оно случается то есть если вы как это случилось когда я использовал эти слов для доставки какой-то момент у нас сломал ну канал между центрами общем поломались цивики встала доставка в одном месте встала доставка другом месте стала доставка тесен том месте соответственно все и докатилась до машины с опечатками которые пишут высоких карте слога там заполнилась очередь потом заполнены с очередь на запись в собственной уникса высоки который помощью что 27 и пакетов с восемь пакетов и следующий write он все он блокируется если специально когда мы смотрели в библиотечку которыми пользуемся в год там было написано что мы зовем соки в прям вот не ну то есть он остается не блокирующим с режиме все было клёво мы были уверенны что ничего не блокируется потому что мы читали статью про подушечку которая про это написал но есть момент потому что вокруг этого вызова был еще бесконечный цикл в котором он постоянно пытался его запихать в этот сотен вот его мы не заметили в общем пришлось переписать библиотеку с тех пор она несколько раз менялась но сейчас мы избавились от блокировок во всех под системах и можно поэтому останавливаться кислоты ничего не упадет далее нужно мониторить размер очередей что соответственно как помогает вот не наступить на эти грабли во первых мы можем они тались когда мы начинаем терять сообщение во вторых можем мониторить что нас какая-то принцип проблемы с доставкой и еще неприятный момент амплификация в 10 раз в микро сервисные церкви архитектуре это вот прям вот легко на ровном месте то есть у нас входящих там запросов не так много но вот за всей этой изографы по которому бегают эти сообщения дальше и загс с логов мы реально увеличиваем нагрузку примерно раз в десять вот навскидку я к сожалению не успел посчитать точные цифры но микро сервиса они такие то есть вот это надо иметь в виду и получается что на данный момент про систему сбора логов самой нагруженная глаза де то есть там реально больше всего рпс of ну и обнаружилось что мы растем как решить проблему отцы ластиком если надо быстро получить логе в одном месте чтобы не бегать по всем машинам не собирать их там вот прям вот вот вот это вот вещь файловые хранилища это она просто железный работает гарантированно короче если вам надо собрать блоге в одном месте 1 чувак сделать от сделать вот эту вещь она офигенная она реально работает она делает banggood из любого сервака но тупо натыкать туда дисков и поставить услуг все после этого у вас в одном месте гарантированно все логе есть дальше уже можно будет настраивать какой-то там elastic какие-то игры логином чинить еще не торопясь но у вас уже есть все логе и причем вы их можете хранить сколько угодно долго ну то есть тупо насколько хватает рейдов и так вот то есть на данный момент моего доклада схема стала выглядеть вот так файл мы практически перестали писать и сейчас скорее всего отключим вообще остатки есть на локальных машинах на которых запущены а фишечки файлы написать перестанем ну во первых есть файловое хранилище которая работает очень хорошо вторых там постоянно кончается место там короче надо его мониторить весь этот геморрой и как бы проще просто закопать совсем и все дальше да вот это вот часть сока старшим грей лагом она реально парит поэтому надо от нее избавиться надо выбрать что-то одно потому что иначе это вечный геморрой мы решили выкинуть слог стаж акебоно потому что у нас есть отдел безопасности какая связь связь в том что акебоно без xs bk без шилда соответственно не позволяет сделать вот сюда вот ходить одним сюда ходить другим то есть эти данные могут видеть одни отделы эти данные могут видеть другие дела ему заморачиваться покупкой всеми этими делами было неохотой как бы надо всем уже будут что вчера все работал поэтому взять грейлок в нем все это есть у меня не нравится но он работает соответственно и далее мы просто купили нового железа поставил там свежий грелок перенесли все структурированы жестко логе со строгими форматами в отдельной игры лог что вот того там тех взрывов с тем что у нас тут интеджер и тут стринги не возникало там мы решили это просто организационного что собственно новый игрок входит на данный момент вот эти вот вернет это еще не на данный момент это еще раньше мы просто записали все в докер взяли кучку серверов раскатали там три инстанции кафки 7 и серверов горелова двоечку потому что хотелось elastic черт 5 там два три то бишь все это на рейдах из и ждите подняли увидели index in raid до 100 км до 100 тысяч сообщений в секунду и увидели цифру что 40 терабайт данных в неделю мне показывают стоп у меня осталось буквально три слайда и соответственно как бы вот вот вот опять блины затыки у нас идет 2 распродажу там про которые рассказывали яндекс деньги только что мы переехали за 6 миллионов у нас брелок не успевает прожевывать как-то надо опять выживать выжили мы вот так то есть добавили еще немножко серверов и ssd на данный момент то есть мы живем вот таким способом и сейчас мы проживаем уже 160 сообщений в секунду но пока еще не понятно сколько там еще то есть мы не уперлись в лимит пока непонятно сколько мы реально можем вытянуть из этого и вот такие у нас планы на будущее то есть из них реально самое важное наверное вот муха это круто у нас его пока нет потому что доставкой orsis лог запущен на верное несколько машин настроены одинаково но настроенность так что едет все через одну машину то есть надо потратить время чтобы настроить какой-то файлов между ними собрать метрики логос сделать родители мид и чтобы у нас одна сумма сошедшая с ума а фишечка не убивал там нам бандуристы все остальное и наконец подписать какой-то с разработчиками что чуваки мы реально можем служить вот столько если вы пишете больше ну блин ну извините и написать документацию кратенько итоге всего что мы пережили во-первых стандарты во-вторых эти слоги торт третьих как syslog работает именно вот так как написано ну и в общем давайте наверно перейдём к вопросам [аплодисменты] описать файл надо опять очень не хотелось то есть это когда у тебя а фишечка пишет там не знает тысячи сообщений в секунду ну ты даже если у вас сейчас будешь ротировать надо писать либо в pipe ну на что меня разработчики спросили а что будет если вот тот процессу который мы пишем упадет я просто не нашел чем ответить искал ok давайте мы не будем так делать просто и все привет спасибо за доклад вопрос почему вы не пишете логе просто выжди fs это следующий этап то есть мы про него подумали самом начале но поскольку в данный момент тупо нет ресурсов этим заниматься он у нас висит так в long term solution где-нибудь там потом это но собственно в догонку просто колоночный формат был бы более я все понимаю мы мы за обеими руками приходить надо здесь ходить нельзя да и второй вопрос не совсем понятно вот вы сказали что пишите версий слог там можно и дипе можно чипе но если египет то тогда как вы гарантируете доставку есть два момента первый я сразу всем говорю что мы не гарантируем доставку логов чуваки это это реально очень клёвая штука теле запомните и всегда говорится и себе в том числе потому что он реально когда разработчики приходят и говорят о давайте мы туда начнем писать как вот финансовые данные и будем гарантировать что вот и вы нам там их где-нибудь будете складывать на случай если что случится отлично тему чуваки давайте вы начнете блокироваться на запись socket и делать это в транзакциях вот сок гарантированно вы это нам socket положили и вы видели что мы это с той стороны получили и тут вот в этот момент всем сразу становится не надо то есть ну не надо вам окей тогда как каких на вопрос если вы не гарантировать запись соки тому как зачем нам гарантировать доставку мы как бы делаем bst ford мы реально стараемся доставить вот как можно больше и как можно лучше но мы не даем стопроцентной гарантией поэтому не надо писать туда финансовые данные для этого есть база данных транзакциями вот туда туда туда а там кстати вопрос какой то как-то по-другому я сейчас вот часть рассказал помощью чё ты там было спасибо за доклад у меня вопрос следующий когда api генерирует какое-то сообщение в лоб и далее передает управление микро сервисом то не сталкивались не сталкивались ли вы с проблемой что сообщение от разных микро сервисов приходится в неправильном порядке и соответственно когда службе эксплуатации нужно следить порядок прохождения сообщения через микро сервис и вот возникает путаница это нормально что они приходят в разном порядке к этому надо быть готовым потому что любая сетевая доставка вам не гарантирует порядок то есть надо либо то есть нам тратить специально ресурсы на это мы это как но если вот возьмем файловые хранилища то туда она прилетает просто вот кладется в файл на каждую каждая пишите есть свой файл куда она кладет свои логе получается верный там марсе слог просто их раскладывается по папочкам соответственно там у каждого api там есть слова и свои логе куда можно пойти посмотреть и потом по времени по таймс темпу в этом блоге можно их потом по сопоставлять как бы если они идут смотреть брелок игры лог не упал на данный момент он работает это можно реально посмотреть то там от сортируется по таймс темпу там все будет хорошо ну соответственно таймс темп может отличаться на некоторые долю миллисекунды и timestream генерит самоа фишечка в этом в этом собственно вся фишка то есть теперь у нас есть три типа к счастью наконец вот у нас соответственно и 5 генерит таймс темпл уже в самом сообщении то есть его не ел чеснок добавлять спасибо спасибо заглянет доклад подскажите вот не очень понятно касательно взаимодействие между дата центрами то есть вам когда-то центра понятно как логе там собрали обработали и так далее вот что дальше между dc или каждый dc живет своей жизнью и только так почти то есть венчур и у нас каждая страна она находится в каком-то одном дата-центре то есть нас нету на данный момент нет размазывания чтобы один венчур был размещен по разным доцентом поэтому не надо их объединять как бы эти куски внутри каждого центра и склок relay то есть это число собственно сервер на самом деле две менеджмент машины это они одинаково настроены как я уже сказал но пока просто трафик идет через одну из них она там логе все агрегирует у нее с диска очередь на всякий случай она жмет их и отправляет в центральный в один дат в центр сингапурский где дальше они уже пихают в грейлок и файловый столь же у нас пир да да это центр то есть каждый до центре есть свой файловый стоишь на случай как раз если у нас пропала connectivity мы все-таки имеем все логе там и они все они там останутся они там будут сохранены то есть соответственно если вдруг что вы оттуда и поднимай ну тоже можно пойти туда и посмотреть как link поднял спасибо за доклад скажите пожалуйста как вы мониторите то что вы не теряете логе хороший вопрос мы их теряем на самом деле и мы эту мониторим я но это запустили блям вот буквально может быть месяц назад в библиотеке которые используют гош ушные опиши чеки есть метрики то есть она умеет посчитать сколько раз она не смогла записать в socket то есть там на данный момент есть хитро эвристик а то есть он как там есть буфер он пытается записывать из него сообщение в соке соответственно если буфер переполнится он начинает их дропать и еще считает сколько он их подгруппу соответственно если там начинает переполняться счетчики мы об этом узнаем они сейчас приезжают также в прометей и у графа не можно посмотреть графики is configured alert и соответственно тоже можно но пока непонятно кому из вас есть еще над чем работать спасибо власти кивы с резервированием хранить в логе сколько вас одна одна реплика одна реплика то есть это всего одна реплика ли это мастер и репликами . но в двух экземплярах данные хранятся домой а еще размер буфера из логова как-то подкручивали ли вы там на стандартном сказали что вот не больше восьми килобайт разработчикам дайте мусор хара хорошо кстати что ты опять упомянул потому что про это забыл презентаций указать мы пишем в кастомные unix socket в дейтаграммы unix socket это нам сразу же накладывает ограничение 128 килобайт то есть мы не можем записать в него просто больше сначала разработчика тильтом дайте нам 16 мегабайт хотя бы не сказали ну давайте дописать в сеть они сказали ну нет ладно давайте сюда . лабдхва это всем и на этом мы собственно как бы и ограничили их и прописали сейчас тоже в стандарт поэтому вот кто хочет подать старик жизнь те пишут 128 килобайт библиотеки причем обрезают и ставит флаг что сообщение обрезана у нас стандарте самого вот этого сообщения у них есть прям специальные поле которая показывает была ли она обрезана при записи или нет так что мы имеем возможность отследить и этот тоже момент битый час он и соответственно вы не пишете битве джейсон будет отброшен самим на руси слогом потому что он потом нет кафе слогом нибудь отброшена будет отброшен либо авелем relay потому что слишком большой пакет либо потом уже и ластиком потом ниткой логом потому что не сможет джейсон распарсить но здесь есть нюансы которые надо фиксить и они большей частью завязанный от syslog то есть я уже заполнил туда несколько и shews над которыми надо еще работать спасибо полу с той стороны у кого-то будущего просто трясти подскажите пожалуйста почему кафка ребятни пробуйте вопрос если можно сразу по поводу грей logo как он не складывается вообще на таких нагрузках на таких объемов и вот масштабируется не складывается у нас с грегом не складывается до ogre лог у нас складывается то есть но с ним реально проблема он своеобразная штукой на самом деле он не нужен я бы предпочел писать за все слова напрямую власти и смотреть потомки банной но надо утрясти вопрос с безопасниками то есть это возможный вариант нашего развития когда мы вытянем грейлок и мы будем использовать икебану блок стоишь смысла не будет потому что я могу все это же самое сделать со слогом поэтому и у него есть модуль для записи власти ксир чьи там все стороны все хорошо закрыл логом но вот пока вот мы с ним пытаемся как-то жить мы его даже немножко потяни ли ну там есть еще пространство для улучшений насчет кафки ну во-первых так исторически сложилось когда я пришел она уже была и в нее уже писали логин the first просто подняли другой кластер и переехали в него лагами как что потому сейчас он стал наш прям вот мы его менеджер мы знаем как он себя чувствует насчет рабби танки у нас совершенно у нас не складывается мжд темпе у нас складывается но до недавнего момента прямо с продакшене он есть и с ним были проблемы вот сейчас вроде бы перед 1111 его заманили и он стал нормально работать но до этого я был не готов и выпускать production есть еще один момент да я вспомнил когда я про него думал брелок умеет читать версию мтп 0.9 мл syslog умеет писать вершинки и 1.0 и нет ни одной из овчины которые посередине умеет и то и другое есть есть либо то либо другое и поэтому на данный момент только кафка но там тоже свои нюансы потому что мгк той версии слова которые мы используем может потерять вот весь буфер сообщение которое она выгребла из кафе слога но пока мы с этим миримся ботинок 2 доклад вот про кавказ . точнее вы есть пользу потому что она у вас в было датой больше никаких целей не столь она используется командой дать сайнс а вот та которая была сразу и у них там какие-то свои вещи в ней там то есть это совсем отдельный проект и которая к сожалению чего рассказать не могу мне не в курсе но на совместно она она была на самом деле видение команда додает сайнс мы просто ее вот когда логе заводили решили просто использовать чтобы не ставить еще и свою сейчас мы обновили грейлок у нас предатель алла совместимость потому что довольно старенькая версия и нам пришлось запада завести сейчас свою и заодно мы избавились от этих четырех топиков на каждые 5 мы сделали один широкий топик на все лайвы один широкий hot topic на все стринги и просто все туда пуляем у нас там брелок параллельно все это выгребает и все хорошо спасибо последний вопрос ну еще под человек вот здесь вот спасибо меня зовут алексей 2 вопрос если можно 1 зачем нужно вот это шаманство с сокетами пробовали или использовать лук драйвер syslog для контейнеров на тот момент когда мы этим вопросом задавались с докера у нас были отношения очень напряженные потому что был какой-то 1.0 может быть даже или 0.9 docker и он сам по себе был странные как бы в продакшене особенно во вторых если в него еще и логе пихать месть непроверенные подозрение что он пропускает все логе через себя то есть через демон собственного докера и в этом случае если у нас 1 и 5 сходит с ума то остальные поют и каются в то что они могут отправить как бы выступать с т д л я не знаю к чему это приведет то есть у меня есть подозрение основаны на каком-то внутреннем ощущении что не надо просто его вот в этом месте использовать если у вас там есть у нас функциональное тестирование у них есть свой собственный кола стиральщика слугами они используют лоб драйверы и у них там вроде бы даже все хорошо пока не поумнел сразу пишут в грейлок мы на тот момент когда все это затевали нам надо был чтобы она просто работала ту потому что все наелись уже все это эти пустоты всем очень хотел чтобы она работала и поэтому решили сделать вот так может быть со временем когда технологии ужас кто-то придет и скажет да ладно на сто лет уже работает нормально ну скажем ok давайте попробуем мы здесь не фиксированы этом спасибо и второй вопрос вы доставку между центрами делаете на все слоги почему не на кафки мы делаем итак итак на самом деле по двум причинам если канал совсем убитый то у нас все логе даже в сжатом виде не пролазит него а кафка позволяет их просто терять в процессе то есть мы этим способом избавляемся от залипания вот этих влогов то есть просто используем кафку в этом случае напрямую если у нас канал хороший и хочется освободить его то мы используем их syslog но на самом деле можно настроить его так чтобы он дропал как бы точно не пролезла сам но пока вот как бы оно работает я туда не лазил как сейчас время появится после продаж после 11 11 11 от полезут снова как бы рефакторинг взять кусок еще раз возможно попробую на данный момент мы просто где-то используем доставку и rsi слогом упрямую где-то кафку понятном спасибо большое если у вас есть ещё вопросы вы можете подойти задать их лично давайте юрию спасибо [аплодисменты]