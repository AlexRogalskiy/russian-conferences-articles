**Здесь переводится видео в статью Андрея Половова из Флант "ТОП ошибок в инфраструктуре, мешающих высоким нагрузкам.md"**

Ссылка на видеодоклад https://www.youtube.com/watch?v=3fJ5ptx5g7M

**Текст сделан из субтитров. Буду очень благодарен в форматировании текста, его вычитки. Для этого достаточно знать русский язык.
Присылайте свои pull request или присылайте текст на почту patsev.anton[собака]gmail.com**


здравствуйте друзья меня зовут андрей и я работаю в компании флант в качестве руководителей архитектор проектов наш com ну а в зале сидит коллега который помогал мне делать это доклад его зовут андрей классов и случае чего он не посодействует наша компания занимается технической поддержкой и devops он для lenovo проектов и обычно это выглядит следующим образом мы берем на обслуживание некий проект доводим его до ума и продолжаем обслуживать но теперь уже с круглосуточными дежурными и с гарантией после среди наших клиентов немало проектов которые можно назвать высоконагруженные так о чем же доклад дело в том что на этапе доведения дома мы обнаружили что многие ошибки или кейсы кочуют из проект проект а иногда имеет общие корни так вот мы эти кейсы решили собрать систематизировать и поделиться с вами собственно в течение доклада мы затронем затронем кейсы которые связаны с базами с кодом с архитектурой и сетью и не обойдется без человеческого фактора многие проблемы покажутся вам примитивными очевидными и вы будете правы но несмотря на это мы продолжаем 7 сталкиваться из проектов проект и поэтому имеет смысл а не говорить начнем мы наш обзор с проблемами которые связаны с базы и начнем с приема который игнорирует очень многие программисты речь идет о транзакциях я думаю все вы знаете такое и я же их раскрою с точки зрения производительности предположим у нас есть некий сайт которые платят автором деньги за просмотры статей и нам для того чтобы показать одну страничку требуется выполнить 4 запросы в некую абстрактную базу данных и что за запрос мы берем собственно этот текст обновляем счетчик просмотров начисляем автору денег а потом эти же деньги списываем из бюджета проекта и в данном случае мы получим если мы эти запросы выполним напрямую в базу безо всяких транзакций мы получим 4 абстрактные дисковые операции в то же время если мы завернём эти четыре запроса в одну транзакцию то вместо все об этике все изменения от этих амулетиков прилетят на диск только в том случае если мы выполним commit и таким образом вместо четырех абстрактных операций мы получим 2 дисковой по рации и таким образом мы сократим заметно нагрузку на систему особенно серьезный прирост производительности вы заметите на операциях большие загрузке больших объемов данных то есть например если у вас есть интернет-магазин вам наверняка приходится парсить прайс-листы поставщиков и заливать эти данную свою базу так вот если вы все запросы все свои insert и апдейты делаете по одиночке то наверняка ваша база справляется но реализует эту задачу достаточно долго но свидетели вы завернете все свои запросы ну разобьете свои запросы на пачке по 1000 штук и завернете их транзакцию срочно то дело пойдет гораздо быстрее и базовом заяц скажи спасибо особенно часто по нашей практике игнорирует этот прием программисты ногам печати понял дело в том что в москве из коробки включен off to commit и все запросы в данном случае прозрачен для пользователя заворачиваются в отдельной транзакции и программист об этом не думает и лепит запросы как ему удобно так вот если бы программе использовался фреймворком то он бы незаметно для себя этой проблемы и сбежал потому что многие фреймворке все запросы который генерит программист как правило заворачивают в отдельные небольшие транзакции и данные проблемы но для таких проект просто не актуальны как быть если под вашу ответственность оказалось база данных а вы при этом админ база данных которое генерит большую нагрузку на диск и при этом не так уж много запросов обрабатывает по вашим ощущений тут достаточно простой вам потребуется вытащить из базы блок запросов случае мы искали вы можете посмотреть белок или в дженнер лак и если вы увидите что количество апдейтов примерно равно количеству коммитов то скорее всего где то что то можно оптимизировать следующий кейс также часто игнорируют многие программисты особенно на этапах когда проект молодой дело в том что если проект маленький то и база данных у него скорее всего маленькая и с легкостью влазит в оперативку в таком случае любые запросы выполняются достаточно быстро несмотря на то что не настроен никакая индексации и связано это с тем что просто в оперативке перебирать все эти таблички не так же накладно но как только база подрастает то в этом случае таблички перестает власть в оперативку и базе приходится все чаще за ними ходить на диск и выгружать соответственно полностью но индексации то у нас не настроена из-за этого диск начинает проседать вместе с ним проседают ваши запросы избежать всего этого можно было бы если бы программист уже на этапе создание таблички хорошенько продумал возможны индексы которые могут пригодиться но я понимаю что это в принципе не всегда возможно и поэтому правильным решением будет держать эти индексы в актуальном состоянии то есть если вы добавляете в свой проект некий запрос то актуализирует и индекс которого съесть и все у вас будет хорошо и того а забыл про диагностику если вы админ и в вашем хозяйстве вдруг оказалась база данных которая вдруг не с того не всего начала медленно выполнять казалось бы простые запросы даже без и даже без джайнов как же им пользоваться то для вас алгоритм тоже достаточно простой вам потребуется выяснить эти самые жирные запросы случае мушки вам поможет слог если же либо какой нибудь профайлер а если у вас пузыря да еще и настрой у ног метр то вам здорово повезло вас уже есть замечательный table как одессите запросы от ранжированы далее вы берете этот самый вычисленный жирный запрос скармливаете в explain у вашей базы данных и добавляйте не недостающий индекс о котором вам этот текст он скажет следующий кейс встречается достаточно редко но если встречается то выглядит он следующим образом есть у нас проект обслуживания у которого между базой и приложением перманента летит по 200 мегабит трафик в то время как конечный пользователь получает всего 5 мегабит куда же делись все эти данные которые базы отправил сторону приложения дело в том что программисты поленились и все запросы в проекта сделали через звездочку и в принципе эта схема рабочая и не такая страшная но в данном случае они рискуют тем что рано или поздно их они просто упрутся в канал и что кстати однажды с этим проектом произошло ну и плюс в этом случае запросы будут выполняться несколько медленней просто за счет того что придется по сети гонять лишние данные как итог с базовыми проектами немножко подытожим рассмотрели два кейса мораль которых такого что держите а что делаете свои запросы более однозначно чтобы базе не приходилось слать лишние данные да тут вин и держите ваши индекс в актуальном состоянии когда вы добавляете новый запрос свой проект а также транзакции вам помогут даже в том случае если вам нужна какая-то особая у вас нет каких-то особых требований к in системности хранения данных то транзакции вам скорее всего помогут с точки зрения производительности в следующем разделе мы собрали кейс пару кейсов который связан с кодом и так как мы в первую очередь все-таки админы они программисты то и кейсы подобрали более системные и начнем с нашего любимого связано с внешними запросами актуален тогда когда например перед программистом встает задача обратиться какой-то внешней опискин например он хочет где-нибудь в уголке разместить последнюю новость с какую стороннего сайта он добавляет скотт нечто подобное и радуется у него все хорошо но только до тех пор пока этот внешний сайт не начнет тормозить ведь вместе с ним на всю тормозить и ваши странички а в конечном итоге с очень большой долей вероятности ваш сайт просто ляжет почему так происходит дело в том что любой веб-сервер мы для примера возьмем патч для обработки каждого отдельного запроса выделяет worker а то есть выделяет отдельный процесс для обработки конкретно этого запроса и в нашем случае эти маркеры будут заниматься тем что будут висеть и ожидать ответа от стороннего сайта и соответственно будут висеть на запросы тем самым тем временем будут все прилетать и прилетать и apache будет вынужден платить и платить эти бургеры а бесконечно он этого делать не может потому что у любого веб-сервер есть лимит случай apache это макс lines ну и в конечном итоге когда маркер и кончается то тот перестает принимать соединение ваш сайт упал фишка в том этого кейса что его не так то и просто продиагностировать то есть когда у вас покупал сайт вы заходите на сервер и вы видите что у вас просто особо не нагружен оперативки полно а база база данных выполняет ваши запросы о сексе равно не работает тут вам диагностики блин тут в диагностике поможет профайлер например в случае new relic а есть замечательные вкладчик и в бэг страну в которой все внешние заброса отражены и [музыка] отражены результаты их выполнения ну или если у вас нет возможности поставить профайлер то хотя бы посмотрите в над стад и возможно вы что-нибудь обнаружите как же правильно поступать с этими запросами обязательно с этими запросами надо поступать осторожно если вам требуется сделать ну забрать какое-то в стороне пышки какие-то данные то обязательно кефир уйти ответы которые она генерит если же вам надо данный отправлять через записку например вы хотите отправить эту миску или почтовое сообщение то используйте какой-нибудь менеджер очередей ну или если совсем припёрло и вам у вас уже вы уже столкнулись с этой проблемой то хотя бы поставьте тайм-аута до секундочку и в этом случае критичность будет снята следующий кейс актуален тогда когда перед программистом встает задача реализовать какую не фоновую процедуру и наша практика говорит о том что проще всего сделать эту программисту на движке сайта почему да потому что он так привык у него под рукой все необходимые объекты уже нецензированная уже есть все настройки баз данных остается только написать процедурку спрятать и в какой-нибудь секретный у ролик типа такого выключить лимит на выполнение покупаешь ну например и все это дело уложить крон но у этого метода есть подводные камни дело в том что фоновая процедура это задача достаточно ресурсоемкая как правило и этой задачей вы заставляете пошевелить apache чтобы тот выделил лишний worker но и если крановых процедур таких вас будет достаточно много то у вас перманента в памяти будут висеть какие-то в бургеры которые будут заниматься тем что рендерить ваши фоновый процедуру но самое страшное произойдет в тот момент когда какая-нибудь из этих процедур по 2 снят по какой-то причине ну из ошибки программист и в этом случае и если в этом случае крон будет продолжать тикать и вызывать все новые и новые процедуры то apache будет плодиться и плодиться пока не упрется в лимит правильно поступать здесь следующим образом если у вас старайтесь использовать консольную версию своего движка следите обязательно со временем выполнения ваших фоновых процедур и обязательно ставьте соответствующий тайм-аут и а также совершенно не повредит ставить блокировки на случай если одна и та же фон фоновая процедуру решить запустится несколько раз и того с кодом опять же будьте осторожны с крым заданиями и всегда делаете ваши внешние типичные запросы с осторожностью и не делаете их напрямую следующий кейс следующий раздел посвящен тем или иным архитектурным проблемам и начнем эскиз и с которым просто стали бороться дело в том что многие админы и программисты любят организовать сайт таким образом чтобы его веб-server- висел восьмидесятом потом в интернет и обслуживал запросы пользователя напрямую побочные эффекты здесь вполне очевидно apache эта штука тяжёлая и вы заставляете его заниматься не интеллектуальным трудом пар индару страниц а отдачей файликов с вашей файловой системы но проблема реальная наступит в тот момент когда к вам придет клиент у которого очень медленный интернет и тогда он будет выгружать ваши файлики очень долго из-за этого квартиры будут очень долго висеть и если таких клиентов вам придет десяток the apache скорее всего умрет решение тут элементарное никогда не оставляйте apache 1 и ставьте перед ним engine x он с радостью возьмет на себя задачу по отдаче статичных роликов и возьмет на себя медленных клиентов без проблем слову я вам приведу небольшую статистику который собрал нет крафт судя по ней 46 процентов серверов в интернете представляются как apache и в принципе можно считать что все эти сервера находится в группе риска по данному кейс следующий кейс я взял из нашего чек-листа по обслуживанию пока пышных проектов дело в том что есть и из коробки хранит сессии пользователей в файловой системе и в этом случае чем больше к вам приходят пользователи тем больше пвп вынуждена ворочать файлика my и соответственно вы рискуете тем что ваш диск просядет но самое страшное произойдет тот момент когда у вас кончится и моды и сайт вас гарантированно ляжет мы в этом случае поступаем следующим образом если нет особых требований по надежному хранению сессий пользователей то мы используем либо ведь без ли вы мукеш по обстоятельствам следующий кейс актуален например случае если у вас есть сервер на котором крутится бэкенд высоконагруженных приложения и вы уже произвели все возможные манипуляции по его оптимизации но ресурсов вам все равно не хватает какой здесь может быть логичное решение для того чтобы снять нагрузку с такого букин да я на самом деле имел в виду масштабирование действительно вы покупаете еще один или несколько серверов копируйте на них приложения и балансируйте между ними нагрузку таким образом вы не только снизить и среднюю нагрузку на один сервер но и получите некую отказоустойчивость но скорее всего сделать это у вас не получится просто так наверняка у вас есть какая-нибудь админка через который вы загружаете картинки или вы генерить и какие документы pdf кино пример их хранить их в локальной файловой системе и в таком случае если вы решите скопировать приложение на другой сервер то он придется еще решить задачу по синхронизации файликов которые вы нагини riley а это на самом деле нормальная такая головная боль еще не дай бог вы завязались на какую-нибудь экзотическую база данных например на и skylight в этом случае вы не то что от реплицировать между серверами не сможете вы не сможете ее просто вынести в отдельный сервер и соответственно не финт с масштабированием не пройдет решение такое если вы проектируете приложения и чувствуете что рано или поздно его придется масштабировать то организуйте вот таким образом чтобы она хранила файлики в истре и речь тут идет не о конкретной amazon s3 многие могли подумать о любом сервере любом сервисе сервере собственным которые умеют протокол из 3 например цех ну и не завязывайте с ним ни на какие сомнительные базы данных это вам не раз спасет ситуацию следующий кейс это буквально неотъемлемая часть любого нагруженного проекта дело в том что действительно самый надежный способ снять нагрузку с бэкенда это не слать эту нагрузку на него а за кешировать ответы которую он сгенерил потому что далеко не всегда есть смысл генерит для каждого отдельного пользователя страничку заново потому что они банально не меняются ну или даже если они меняются то всегда есть возможность воспользоваться каким-нибудь varnish им но сейчас о самом простом случае примером далеко ходить не надо если вы были на хай-лоу где прошла осень то могли заметить что страничка с расписанием в первый день изрядно так тормозил дело в том что оно генерируя десятки а як запрос вы за которых бэкенд захлебнуться вот подобных и решение было очень простым мы просто взяли затишье равале их на одну минутку и вопрос был решен и достаточно было даже зафиксировать нам на одну на 10 секунд и все равно бэкенд сказал бы нам спасибо и того если вы проектируете приложение которое чувствуете что когда-нибудь будет испытывать нагрузки то проектировать его таким образом чтобы в будущем вы без проблем могли эти странички зафиксировать ну и ни в коем случае не заставляйте apache обрабатывать запросы пользователей напрямую если у вас пока пышный проекту рассмотрите возможность принести сессии в какой-нибудь memcache или редис пишете приложение так чтобы их без проблем можно было масштабировать по моему сюда если же ой если же в следующем разделе мы собрали кейсы которые так или иначе связаны с сетью и сеть это достаточно штука объемная и в нее куча нюансов но мы собрали кейсы которые более-менее применимы для нагруженных проектов и начнем с самого распространенного дело в том что во многих проектах так сложилось что типичные сессии между разными углами между фронтэнда мы бы kindom например между приложением и базой живут очень недолго и открываются на каждый внешний 6 типичный запрос и тут есть на самом деле подводные камни и начнем с очевидного что линуксу для того чтобы создать новый соки приходится немножко пошевелить процессором и при этом по вашей сети будут гулять лишние типичные служебные пакетики но это был на самом деле зачастую копейки настоящая проблема наступает в тот момент когда вы заставляете на каждый новый внешний запрос базу данных точнее приложения оставлю открывать соединение с базой данных и в этом случае базе приходится не только создать socket ей приходится еще называть куча всяких служебных процедур там проверить права пользователя там выделить какой нибудь окружение или какие-нибудь блокировки поставить зависит от базы данных но в любом случае что-то придется поделать и еще одна проблема есть у коротких соединений связана она с тем что если у вас в системе умрет много сокетов то скорее всего она у вас переполнена за китами режиме time with a них я расскажу чуть попозже так вот из всего этого реальную настоящую угрозу несут короткие соединения между базой и приложений и если вы решите с ними бороться то скорее всего вам придется лезть в логику приложения что в принципе не всегда возможно но если у вас подря то вам здорово повезло опять же для пожгли есть специальная прокси которая создана буквально для этой задачи ставите перед подгруппу bouncer и снимайте с него лишнюю нагрузку это хороший метод также в случае джинкс в отдельных случаях имеет смысл установить брендом перманентное соединение но будьте осторожны не все веб-сервера такую умеют например по моим где ник он не умеет неважно как и обещал расскажу немножко вот там высоких суть в том что linux устроен таким образом что когда тот закрывает соединение закрывается кит то он не стремится удалить его из системы бесследно а оставляет вы еще повисеть минутку в режиме time weight и принципе это несет одну небольшую угрозу дело в том что в этом случае да и в принципе в любом случае линуксу приходится на каждый входящий пакетик искать соответствие среди всех сокетов которые здесь наличии а так как среди сойки то все полно мертвых душ в виде time вы это то ему приходится перебрать этот массив несколько дольше но это на самом деле не такая серьезная проблема да и по другим параметрам эти соки то толком на вашу систему не влияют почему я не говорю дело в том что админы зачастую любят очень с ними бороться и когда они заходят на сирот и видит заходит на сервак чтобы решить какую-то очередную проблему и тут они видят что их система переполнена подобными сокетами то они сразу начинают во всем винить их и идут в интернет за советом и первое что они видят это совет включите это два параметра в ядре речь идет о товаре us это вырез ай-q если первый параметр вам не навредит и принципе можно считать его полезным есть случаи когда он поможет то из-за второго вы замучаетесь де бо жить почему отдельные пользователи которые ничем не отличаются других казалось бы не могут подключиться к вашему сайту причем таких будет процента 3 и вы не сразу об этом узнаете привет проблема в том что эти два параметра толком никак не задокументировано и чтобы разобраться как они работают придется немного попотеть и если вам любопытный сетки как они работают подходите на наш стенд я вам обрисую сейчас не будем итогам про на правильное решение для борьбы с этими там высокими будет первое не паниковать и комплекс из двух еще мер включите все таки это varius он вам не повредит и старайтесь в вашей системе свести к минимуму короткие типичные соединения то есть старайтесь как можно больше использовать prezi на connection а они полезны следующий кейс на самом деле единичный но несет мораль которая подойдет для любого времени серьезного проект есть у нас проект на обслуживание которого есть специфика он состоит из двух виртуалок которые хотят косились на недавнее время в 10 лучше не и эти виртуалке перманентно испытывали одинаковую нагрузку в течение дня у специфика такая и как-то раз совершенно неожиданно этот проект друг начал тормозить причем ночью работает хорошо одним тормозит залез когда мы зашли в профайлер мы увидели что запросы базе данных выполняется в течение дня покажет он светит очень долго вторыми как ночи все хорошо и эти же самые запросы в это же самое время по версии базы данных выполняются быстро немножко по разбежавшись мы выяснили что в держит ложь и не между виртуалками начало проседать сеть причем днем она тормозит а ночью все хорошо и мы не стали разбираться и просто уехали на собственный гипервизор а мораль такова что если у вас более-менее серьезный проект то старайтесь свести к минимуму использование коммунальных инфраструктур чтобы не нарваться на какие-нибудь неожиданные сюрпризы ну либо пристально следите за ними чтобы опять же быть готовым случае чего проговорили итог правил коммунальную инфраструктуру старайтесь подытожим сетевой раздел постарайтесь использовать как можно меньше коротких соединений между вашими компонентами не перестарайтесь в борьбе с a time with a ну да три кейса все верно в следующем разделе мы собрали ошибки которые могут помешать вашему проекту и начнем мы самый банальный самый очевидный но почему-то многие программисты или админ уверены что если они добавят проект какую новую технологию то настроек из коробки и мы обязательно хватит и выясняется что это не так как правило уже на этапе первых нагрузок и решение это тоже простой очевидно если добавляете свой проект какой-то новую технологию то обязательно разберите с ней и настройте превентивно на чтобы она вас не подвела в том же хабре полно статей для той же музыки о том как по простому настроить ее так чтобы она держала хорошие нагрузки ладно кстати а хабре если у вас большой проект то у вас уже наверняка есть маркетологи который любит дать рекламную кампанию и либо разместить рекламный ссылку на том же хабре например и как правило выясняется что когда приходит новый поток пользователей инфраструктура бывает к этому не готова избежать всего этого можно было бы если бы маркетолог предупредил команда администраторов и те произвели какой не погрузочное тестирование и либо под настроили все под новые условия либо открыто говорили майка маркетологов давать такую нагрузку и соответственно сохранить деньги очень больной для нас кейс а также больной для нас кейс связан с проектом в которых есть свои команды программистов дело в том что те любят делать себе не дельные планы и выкатывать свои по деле по пятницам и причем как правило это происходит вечером они это все дело выкатывают быстренько проверяют и довольный собой убегает домой но тут выясняется что программиста внесли какие-то изменения из-за которых мы больше не держим нагрузки и нам админом напоминаю это пятница вечер приходится инфраструктуру под новые условия подстраивать и хорошо если мы справимся но возможность ситуация когда нам понадобится помощь того самого программиста который внес эти изменения им его в трезвом уме и просто не найдем поэтому старайтесь перенести свои выход и с пятницы куда-нибудь только не в пятницу пожалуйста итак мы с вами за закончили разбор кейсов сейчас я подниму вопрос о самых необходимых задачах которые надо решить в абсолютно каждом проекте и я думаю никто со мной спорить не будет что в первую очередь это быка по объяснять тут я думаю надо без мониторинга и статистике вы никогда не дадите гарантию что с вашим проектом в данный момент все в порядке а еще если что-то пойдет не так вы замочите с ними разбираться это слово статистики и мониторинга ну и если вы деплоить из пасти пески то вы рискуете своим аптайма это же я думаю многие это понимают но как думаете много ли проектов которые пришли к нам на обслуживание хотя бы попытались как хоть как-то решить вопрос сбора backup как оказалось 40 процентов проектов настолько уверены в себе что в решении вопроса бэкапов у них просто не стоит с статистикой им и мониторе нам все хуже дело в том что у нас есть все таки проекты которые позаботились и поставили хотя бы базовое инсталляцию zabbix а либо настроили мониторе к марии мониторинг в том же в той же в яндекс метрике но таковых всего 30 процентов и по поводу последнего последней задаче есть небольшая завершающая история связана она с клиентом которых до недавних пор тепло и усы по ftp есть у него программист который однажды уехал в отпуск и купил там местную симкарту и тут как-то вечерком под настроение он решил похудеть и вы хотите это все на сервак но в момент вы кота что-то произошло и симка перестала не работать по какой причине и все что он успел это залить файлик нулевого размера и заяц соответственно умер и с нашей страны все выглядело совсем странно программиста в отпуске и беды ждать не от кого и соответственно разбор этой ситуации занял ну достаточно серьезный объем времени но мы все-таки разобрались и достались cryptokeys backup так вот много ли считайте таких клиентов которые в принципе не не позаботились хотя было cappy стране в своем проекте оказалось только один только пять прошить простите процентов наших клиентов понимают необходимость грамотному тепло и самостоятельно остальные не палец и того мы рассмотрели с вами массу кейсов которые я надеюсь найдут применение в ваших проектах и найдут применение в ваших будущих проектов подписывайтесь на наш блог на хабре там он активно сейчас развивается и я думаю вы тоже том чего не почерпнете интересно спасибо я думаю все было настолько очевидно что спориться на никто не станет верный человек хочет у нас есть 3 кружечки я думаю за вопрос по 1 не больше трех вопрос передумал доклад а вопрос такой один всего вы да вот вы говорите что давайте ставить перед apache и nginx а зачем тогда apache apache это веб-сервер который рендерит страничке рендерит код фиксирует реверсивный прокси-сервер он может выполнять функции вчера он курить или он может выполнять функцию веб-сервера а rendering она будет освещаться каким-то бэкон там например печь пить мы можем использовать in джинс в качестве веб-сервера а rendering страниц будет оставлять петь ppm например я понял вопрос под веб-сервером в данном в рамках данного доклада я имею виду ту штуковину которая непосредственно занимается рендером страниц индексу умеет отдать файлик с файловой системы engine сумеет забрать страничку у веб-сервера упасть . fpm у apache gunicorn а у вашего любимого веб-сервера и передать ее пользователь соответственно в качестве веб-сервера тут выступает юникорн в качестве реверсивного прокси выступают яндекс просить кружки так вот на добрый день спасибо за доклад а вот у меня вопрос вы упоминали о системах тепло и ну понятно все просто интересен технологический стек которым вы пользуетесь для автоматизации сбора бэкапов и развертывание этих бэкапов в обратно и как все это происходит в ваших кейсах бронебойно что вопрос про то как мы реализуем вопрос быков фактически да замечательно ну в двух словах если прям на пальцах мы автоматизирован и настраиваем баку и достаем файлики из бокал и безо всяких изысков случае чего но в батле у нас всегда все что под рукой на тайский базы данных там же конфигурации и все про и база данных в мы в отдельном случае разные базы данных богатым по-разному и заставляем пишем какую-то программу или но который достает бэкапы с базы данных и забираем в баку ну то есть вы использовать какие-то свои самописные решения ну как если скриптик можно написать самописцем решение ну да да очень интересно было услышать про ошибки что мешают такой момент были ошибки которые помогали неожиданно хай-лоу да но это выяснилось пост-фактум уже той что-то сделали да думали что ошибка неожиданно это как-то могу выделить нагрузку которые пришла неожиданно ну например бывали случаи когда мы там оперативки больше виртуальных виртуалке давали хотя и не надо было ну на самом деле когда такие ситуации происходили мы они просто не знаю постфактум офисов сходу но вопрос интересный я не обращал внимание хорошо и тут не знаю что далось пекине что вот так достаточно в разделяете понятие там грубая программистов и админов то есть я момент и devops это как-то осознанное решение ли вы их не используете ли это такой подход ну мы на самом деле на junior и сейчас находимся и и кейсы соответствующий но тут я имею виду программистов как команду которая относится к клиенту которая может преподнести нам добра то что наши как устроена наша инфраструктура при этом я не упоминаем ну хотя в принципе возьму возможно имелось ну я в общем не вижу способа как воткнуть в этот доклад то как уместно сказать в этом докладе что наша инфраструктура так и замечательно на все найди обсе просто это речь не об этом сейчас теперь бесплатный вопрос я же обещал ой ребята вот вы привели пример с выставлением на каширование на одну минуту а использовать или вы в своих приложениях заголовки http кэш control там и так например то есть приложение ваша знает ли о том что надо кэшировать его данные или все вода на нотку фронтэнда виден джинкс на чем того что приложение не наша о приложении нашего клиента ну проекта который мы обслуживаем его не развиваем и кеш control это то о чем надо подумать на это вид проектирование вашего приложения если вы делаете приложение которое будет когда нить использует испытывать нагрузки и вы захотите выкинуть рекомендации но тут тут обстоятельств универсального совета я вам не дам когда использовать когда не использовать это отдельная история можем обсудить на докладе ой на стенде а который часто не за но да очень часто это уместно господи добрый день а подскажите почему вы не рекомендовали использовать infos в качестве распределенных хранил ки на всех трех серверах а использовать тот же ис-3 ну у нас возможно субъективное мнение но мы считаем что это небольшой костыль несколько ну в общем нфс в данном случае это сложно сделать достаточно отказу случаем и ну как правило это поле выручал чаще слова как правило ис-3 опять же как правило решение на ис-3 удобнее бэкапить удобнее разворачивать субъективное и имя удобно удобнее пользоваться из приложений с точки зрения программиста то есть сплошные плюсы ну да но как временное решение вполне себе solution нфс пожалуйста только потом переделаете на острие ты гораздо удобнее с точки зрения админ был подольше доклад сделать это спасибо за доклад в продолжение вопроса коллеги про бэкап и а такой вопрос вот вы бэкап собрали вот все хорошо а как вы проверяете чтобы cup собрался верно что он полный что из них можно установить проект как часто вы эти бэкап и разворачивайте и какие среды используйте для этого сразу про среды скажу честно говоря толком не какие среды ними не используем мы используем регламенты и дежурных которые регулярно ходят по проектам и убеждаются что все хорошо у нас есть много людей и много рук здравствуйте а вот вы рассказывали про про таймвайз стойки тогда сказали что linux устроен так наверное было бы более справедливо сказать что это 10 до устроен так высоки то не все таки везде существует насколько я знаю да вы правы и почему вы рассказывает ага об этом да не упомянули про times buy time out и и хотя бы выбрал блок олпорт раньше например я пожалел мозги слушателей и и опять же если кому любопытно потом вы послушать немножко правда его этикета подходить вам расскажу как они работают на стенд понятно спасибо за доклад очень приятно

