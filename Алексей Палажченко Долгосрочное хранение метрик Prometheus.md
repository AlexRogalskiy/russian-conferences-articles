![](https://habrastorage.org/webt/nc/xy/yx/ncxyyxbouopsyyobm4rhgfrjxn0.png)

Друзья! Всем привет! Меня зовут Алексей Палажченко. Я работаю в компании Percona. Я хотел бы вам рассказать про долгосрочное хранение метрик в Prometheus.

![](https://habrastorage.org/webt/rw/vv/4v/rwvv4v4zpjhn5tlmrclgeii9mkq.png)

Я работаю в компании Percona и делаю продукт, который называется percona monitoring and management. Это коробочное решение, которое наши клиенты ставит себе. Это полностью open source, который состоит из prometheus, grafana для рисования графиков, custom софта query analytics и нашей собственной обертки, которая позволяет вам делать некоторое управление. Вы можете добавить scrape target в prometheus. Это новые цели, откуда он будет брать метрики без того, чтобы руками заходить в контейнер или в виртуальную машину и руками править файл конфигурации.

Важно понимать, что это не SaaS. У нас нет production'а. Наш production находится у наших клиентов. На нем экспериментировать не очень хорошо. У нас есть ближайшая вещь, которую можно бы назвать production этот pmmdemo.percona.com. Cейчас он не работает. Кто может предположить почему pmmdemo.percona.com не работает? Из-за GDPR: сейчас нам пришлось его выключить. 

Мы ставим PMM клиентам - коробочное решение: docker-контейнер или виртуальная машина. Им всем нравится prometheus. Некоторые люди, которые первый раз смотрят на prometheus, сталкиваются с pull моделью. Для новичков это неудобно. Вообще отдельный большой разговор. Можно спорить о pull или push методах. В среднем это примерно одно и то же.

Некоторые вещи в prometheus очень крутые. 

- Prometheus query language - это действительно крутая вещь, которой нет аналога практически негде.

- Второе, что нравится, - это service discovery. Если у вас какая-то динамическая инфраструктура, kubernetes, то автоматически не нужно добавлять руками все цели для мониторинга. Если статическое - тоже это можно сделать довольно просто. Нужно использовать файл конфигурации.

Клиентам prometheus нравится. Они хотят хранить метрики дольше и больше. Кто-то использует prometheus только для оперативного мониторинга. Но кто-то хочет хранить  дольше, смотреть динамику, сравнивать с графиками год назад. При этом цель долгосрочного хранения метрик не является целью для проекта prometheus. Изначально он создавался для того чтобы хранить метрики недолго. Soundcloud хранит метрики буквально несколько дней. В prometheus есть механизмы, которые позволяют это делать дольше, но они устроены немножко сбоку. Поэтому мы можем сделать решение для экосистемы prometheus не меняя само ядро системы. Мы на основе них можем сделать свое собственное решение в рамках этой же экосистемы. 

![](https://habrastorage.org/webt/ws/1n/7k/ws1n7kpa7ohpkxwpxuli5dcpwuc.png)

Это не доклад про готовые решения. Это доклад про наш опыт, про нашу боль, про наши попытки. Если вы рассчитывали что после этого доклада, вы скачаете репозиторий или docker-контейнер, запустите и все заработает, то это не так. Но при этом это достаточно близко к тому, чтобы быть так. У нас есть наработки. Они все opensource. Вы можете взять попробовать. Они не готовы к production пока еще. Но с той информацией, которая есть в этом докладе, вы сможете понять почему так, что можно сделать лучше. Вы можете сделать свое решение, которое будет хорошо подходить вам.

![](https://habrastorage.org/webt/ej/4j/sm/ej4jsmldkwk-bsme40kqehzilqc.png)

Как метрики хранится в prometheus? Есть локальный storage. Есть remote storage. Это фактически два разных мира. Они слабо пересекаются. Поэтому и доклад тоже разделен на 2 части.

![](https://habrastorage.org/webt/jm/ic/81/jmic81mrsu49j-zxv6spn9aopac.png)

Если вы были на предыдущем докладе в главном зале, где как раз была хорошее интро в prometheus, вы знаете что локальный storage это отдельная библиотека, которая называется TSDB. TSDB не имеет ничего общего с OpenTSDB. TSDB это отдельный Go пакет, который можно использовать из своей программы на Go. На уровне библиотеки TSDB нет никакого клиента и сервера.

Эта библиотека оптимизирована для работы именно с time series данными. Например, в TSDB есть delta encoding, который позволяет вам хранить не сами числа, а именно изменения между этими числами. Это позволяет вам вместо того чтобы хранить 16 байт - хранить 8 байт. 8 байт под время и 8 байт под значение. То есть вы храните в среднем 1 или 2 байта именно за счет этого хорошего сжатия. 

TSDB оптимизирован для pull модели. Данные туда только добавляется. В prometheus нельзя запихать исторические данные. Для этого нет API. Максимальная дельта примерно 5 минут. Если данные более старые, они не будут приниматься. 

В TSDB нет никакого встроенного downsampling [tsdb#313](https://github.com/prometheus/tsdb/issues/313). Есть открытый issue, в котором была дискуссия на тему того, что в целом есть проекты, которые вокруг prometheus что-то делают и там есть downsampling. Пока что решение такое, что в TSDB не будут добавлять downsampling.

![](https://habrastorage.org/webt/5q/pb/vt/5qpbvtptau3gz7ygcxb9cl3nmzg.png)

Как бы нам получить данные с TSDB. TSDB - это база данных на диске. Работать с ней можно, если вы пишете Go программу. Но если вы не пишите программу на Go, то есть JSON API, который позволяет вам сделать query запросы. Если вы хоть раз пользовались prometheus и хоть раз строили какой-нибудь график, вы знаете стандартный Query API, в котором есть параметр query, в котором можно выполнить любой PromQL запрос и опционально время. Если время отсутствует, то берется текущее время.

На слайде выделено специфическое query, которое в реальной жизни вы редко увидите. Это хак. Это позволяет нам вытащить все метрики, которые есть в prometheus. Как это работает? На уровне PromQL говорится что нельзя написать такое выражение, которое бы заматчила все time seriers. Это прямо в правилах написано. Еще одно правило говорит о том, что нельзя сделать такой matcher, в котором все значения пустые. Если вы напишете просто фигурные скобочки это не будет работать. Если вы напишите name не равно чему-нибудь (не пустое значение), то не будет работать. А вот это реальный хак, который позволяет это сделать. При этом он даже не освобо документирован. В самом коде есть комментарии о том, что это работает.

Второй запрос - это query_range, который делает то же самое, но возращает вам данные в диапазоне и с неким шагом. Он по сути делает query несколько раз каждая step начиная с начала и до конца. Это тот API, который используется для того чтобы рисовать графики. Первый API использует для получения моментальных значений.

![](https://habrastorage.org/webt/nc/cm/cs/nccmcsyofzxubtca8yoyas7p6ag.png)

У нас есть API для получения метаданных. Если мы хотим получить все названия метрик, мы делаем вот такой запрос, где match это массив метрик. Их может быть несколько аргументов, но в данном случае мы передаем тот же самый match, который нам возвращает все.

Второй мета API, который возвращает нам значение всех лейблов. Если мы хотим увидеть список всех job, мы ее вместо label_name пишем job и получаем этот список. Эти API возвращают нам JSON API. 

![](https://habrastorage.org/webt/qe/ku/j4/qekuj4lgm4zp-x07kvhoorux_w0.png)

Есть еще один API, который возвращает нам все метрики самого prometheus в формате, который является нативным для экспортеров. Формат называется expfmt. Это то что вот метрики фигурных скобках пара K/V. В самом prometheus есть Federation API, который вам позволяет сделать такой запрос. Для чего это нужно? Самый простой вариант, если у вас есть какой-то код, который уже работает с expfmt, то вам не нужно его переучивать на то чтобы работать его с каким-то custom JSON API. Этот формат гораздо проще стримится, потому что если у вас JSON где-то на верхнем уровне объекта, чаще всего вам нужно этот объект распарсить целиком. Здесь это можно делать по строчке.

Самое главное это то что это отдельный API. Он работает именно как настоящий export. Вы можете взять и другим prometheus его заскрейпить. Это обычный job с обычными параметрами. Вам нужно передать параметр - query url. Если вы сделаете запрос curl, вы получите здесь тоже самое. Мы получаем все метрики для текущего значения времени. Единственный нюанс: необходимо установить honor_labels для того чтобы prometheus, который будет скрейпить другой prometheus через этот API не перетирал значение job и instance label. Используя этот Federation API вы можете загрузить все данные из одного prometheus в другой. 

![](https://habrastorage.org/webt/64/lc/yy/64lcyynloe47gbkjlelzyddss60.png)

Как это можно использовать? 

Во-первых, надо самое главное сказать что так делать не надо. TSDB оптимизирован для другого режимы работы. Если у вас есть prometheus, которой скрейпит много данных, то он делает большое количество ввода-вывода. Если вы используете Federation API, то количество ввода вывода увеличивется примерно в 2 раза. Есть нюансы. В зависимости от того как часто вы делаете скрейпинг на federate и как часто вы скрейпите таргеты. Если время не меняли, то это действительно увеличивает нагрузку в два раза. Поэтому если вы хотите соскейлить ваш prometheus и включить федерейшн, то вы его убьёте. Нагрузка увеличится два раза.

Второй момент. Вы будете пропускать данные. Вы получите конфликт данных. Почему так? Этот API как почти любой API в prometheus не атомарный. Если придут новые данные, закончится новый скрайп в тот момент когда ваш federate запрос еще идет, вы можете получить для одной time series одни данные, для другой уже новые. Если это не связанные time series, то это в целом не страшно. Но если у вас summary или гистограмма, которые на уровне expfmt представляется нескольким базовым метриками, то будет между ними несогласованность.

![](https://habrastorage.org/webt/_0/5h/lk/_05hlkpn57b8klhjwborhup4bds.png)

Как мы можем решить эту проблему атомарности? В prometheus есть recording rules, который позволяет создать новую time series из существующей time series. Это можно делать реже. Это один из способов сделать downsampling. Например, скрейпите target каждую секунду, но дальше мы хотим сделать агрегацию node_cpu за одну минуту. Группировка в prometheus 2.0 позволяет вам делать эти агрегации последовательно. Правила, которые находятся в одной группе выполняется строго последовательно. В этот момент нет проблемы атомарности, нет проблемы что данные поменяются в процессе. **Но это не решает проблему того что это если допустим какие-то другие данные, которые связаны логически с этими, но они связаны с точки зрения модели данных.** Чистой атомарности пока нет. Есть открытый issue на эту тему. Можно делать снапшоты. Можно сделать запрос PromQL к базе данных TSDB и из полученных значений отбрасываем все сэмплы, которые меньше какого-то значения времени, в которое началось в evaluation. Это был бы самый простой способ, но пока его не сделали.

Важно понимать что recording rules нужно делать на нижнем prometheus, а не на том, который делает federation. Иначе вы будете пропускать пики, у вас неправильно будет работать мониторинг.

![](https://habrastorage.org/webt/kp/jf/hd/kpjfhdz8boamndunerhcx2vgebq.png)

Как мы можем использовать эту комбинацию этих вещей для того чтобы сделать downsampling и долговременное хранение. 

Первое. Мы просто ставим federation и загружаем все данные с того prometheus. Это странное регулярное выражение похожее на зойдберга - это на самом деле просто двоеточие. Слева и справа от двоеточия звездочка. Мы используем стандартное название для recording rules, которое добавляет двоеточие в середину. При делении оригинального имени слева будет уровень агрегации, а справа функция. В нормальный метрики двоеточия нет. Если есть двоеточие, то это признак того что это агрегация. После этого мы используем это название метрики в нашем графике. Если мы хотим чтобы наш график, наш дашборд в grafana работал и c главным prometheus и c тем кто стоит выше, мы можем использовать выражение **or**. Мы берем либо одну метрику, либо другую, в зависимости которая есть. Мы можем схитрить и при помощи relabeling переименовать новую в метрику старое имя. Это довольно опасный подход. Можно неправильно написать регулярные вложения и у вас будет конфликт time series. Prometheus будет писать много warning в лог. Вы это увидите, но найти причину может быть довольно сложно. Но если сделать аккуратно, например сгенерировать эти регулярные выражения программно, то это будет работать. Дальше у вас будет обычный дашборд, где используется только node_cpu. В зависимости от того какой prometheus используется, вы будете получать либо исходные данные либо же агрегированные.

![](https://habrastorage.org/webt/hd/ft/1x/hdft1xwgw_61j7tab_3feehhsgy.png)

Как я уже сказал, recording rules можно генерировать довольно просто. Мы просто получаем все  time series через api, которые я уже показывал. Мы создаем правила и эти правила должны использовать правильные функции и операторы. Не нужно использовать там рейд с gauge. Это будет не правильно работать. Нужно использовали только с count. На том уровне где вы работаете у вас может быть не быть информации о типах данных. Например, если вы используете expfmt. Там информация о типах есть. Если JSON API, там этого нет. Как следствие, выражение, которые вы автоматом сгенерируете, может не иметь никакого физического смысла. Поэтому, можно использовать там либо белый список либо черный список. В зависимости от этого генерировать либо нужное вам правило либо выкидывайте те правила, которые не имеют смысла. Есть инструмент promtool, который позволяет вам проверить что те правила, которые вы сгенерировали, тот конфиг, который вы сгенерировали, он имеет смысл. Он имеет корректный синтаксис.

![](https://habrastorage.org/webt/om/wc/fv/omwcfvvh7mc8bky3zkble7vimqm.png)

Если у нас есть grafana и там несколько prometheus, нам нужно знать на какой prometheus отсылать запрос. Как бы нам это сделать?

Один из способов это поставить специальный прокси, который будет смотреть на время в запросе и в зависимости от этого выбирать prometheus. В запросах есть время начала и время конца. В зависимости от этого можно руками делать роутинг. Можно было бы написать какую-то программу, которая это делает. На практике это делается nginx с модулем lua или небольшой программой.

![](https://habrastorage.org/webt/ff/ve/vz/ffvevzimxzpnrjrqirbkuqssiqm.png)

А нужен ли нам вообще API? Можем ли мы работать с TSDB напрямую? Есть нюанс. Во-первых, если мы пытаемся использовать TSDB, который используется prometheus сейчас, мы этого сделать не сможем. Там есть специальный lock файл, который предотвращает это. Если мы напишем код, который будет игнорировать это и будем пытаеться данные читать или писать это, мы гарантированно их повредим. При этом даже чтением. Что можно сделать? Можем читать данные через API и создавать TSDB рядом. Дальше prometheus остановить и его TSDB подменить. Но при этом мы можем просадить производительность, если будем читать все данные черех API. Я об этом немного позже скажу.

Второй вариант. Можно скопировать (сделать hot backup) этих файлов, то есть скопировать как есть. Да они будут поврежденные. Когда вы откроете у вас будет warning о том что данные повреждены. Их нужно починить. Вы можете потерять новые данные. Но нам это не важно. Мы хотим downsampling старых данных. Downsampling можно сделать используя PromQL. Но есть нюанс. Его оторвать от prometheus гораздо сложнее, чем TSDB. Если вы немного знакомы с Go и c управлением зависимостями, то вендоринг (vendor) PromQL это большая боль. Я бы вам не советовал. По возможности избегайте этого.

![](https://habrastorage.org/webt/2z/ii/fs/2ziifscme6pqm1ppf1n9ripipuq.png)

Переходим к Remote Storage. Кто-нибудь работал с Remote Storage в prometheus? Несколько рук. Remote Storage - это API, которое давно уже существует. Сейчас в версии 2.2 Remote Storage -  помечен как экспериментальный. Более того известно, что API Remote Storage точно поменяется. 

Remote Storage позволяет вам работать только с сырыми данными. Там нет никакого PromQL ни на входе, ни на выходе. Когда вы читаете, вы не можете использовать всю мощь PromQL. Он по сути выкачивает все данные из Remote Storage, которые соответствуют условию. Дальше PromQL работает уже с ними. Это имеет довольно большой overhead. Вам нужно много данных прокачивать по сети. Поэтому в prometheus 2.3, который пока не вышел, но уже это вмержили, будут read hint. Мы чуть позже об этом поговорим.

API для metadata пока что отстутствует. Вы не можете сделать API, которое возвращает все time series из Remote Storage. Если вы сделаете запрос в API у prometheus, то он в Remote Storage не пойдет. Он вернет вам  time series, которые есть в его локальной базе данных. Если у вас локальная база данных отключена, он вернет вам 0. Что может быть немного неожиданно. Сейчас этот API использует ProtoBuf и точно его поменяем на gRPC в будущем. Cейчас это пока что не сделали потому что gRPC требует HTTP2. А у них на практике с ним были проблемы.

![](https://habrastorage.org/webt/lc/7v/ij/lc7vijvha-gtzs_oj74xszwk488.png)

API для записи выглядит вот так. В запросе есть набор лейблов. Набор лейблов как раз уникально индефицирует time series. Name это на самом деле просто лейбл со специальным именем. А сэмплы это набор времени и значения - два float64. При записи порядок неважен. Предполагается что база данных, которая это пишет в себя сама все сделает правильно. Prometheus сможет сделать некоторую оптимизацию и не сортировать это лишний раз. Соответственно запрос на запись это просто несколько time series.

![](https://habrastorage.org/webt/xd/qr/ud/xdqrudjh5lpomcepkdmkjcfegt0.png)

У конфигурации на запись довольно гибкая большая конфигурация. Там много параметров для конфигурации параллелизма записи. То что prometheus шардингом - это по сути конкурентные запросы. Можно ограничить максимальное количество сэмплов в одном запросе, максимум параллельных запросов, timeout, как повторять, какой backoff. Для многих баз данных 100 сэмплов за раз это может быть очень мало. Если вы используем clickhouse как используем мы, то конечно значение надо сильно увеличивать. Иначе это будет очень неэфективно.

![](https://habrastorage.org/webt/eb/gk/ew/ebgkewr7k-i2yho9mh7dbogcipm.png)

Remote read API выглядит вот так. Это просто диапазон по времени от начала до конца и набор match.

![](https://habrastorage.org/webt/hv/kn/jo/hvknjowgf6h9pebjvvhbspe7jac.png)

Match это по сути набор пар name и value - обычный лейбл и тип значений. В сравнении есть равенства, неравенства или регулярное выражение. Тип значений это обычный match, который вместе видите в PromQL. Никаких функций здесь нет.

![](https://habrastorage.org/webt/ri/hu/ap/rihuap_py_s_hrp0oywqnyx6yee.png)

Ответ это несколько time series, которые соответствуют этому запросу. Здесь сэмплы должны быть отсортированы по времени. опять же это помогает prometheus немного сэкономить cpu - не нужно сортировать. Но предполагается что ваша база данных должна это делать. В большинстве случаев и так будет, потому что скорее всего там будет индекс по времени.

![](https://habrastorage.org/webt/zu/yd/fx/zuydfxti6mozpsz5v60f_i1laic.png)

В prometheus 2.3 появились read hint. Что это такое? Это возможность подсказать prometheus какая внутренняя функция, которая работает с time series, которая запрашивается будет преминина. Это может быть либо функция либо оператор агрегации. Это может быть rate. То есть это назыается func, но на самом деле это может быть sum, который с точки зрения PromQL на самом деле совсем не функция. Это оператор. И шаг. На предыдущем примере там был rate 1 минута. Здесь rate это будет функция и одна минута в миллисекундах как шаг. Этот hint он может игнорироваться ремонт базой данных. При этом в ответе нет никакого признака игнорировался или нет.

![](https://habrastorage.org/webt/6_/ms/9_/6_ms9_zh9txqwdafxjoenbdn8so.png)

Какая конфигурация у read? 

Во-первых, есть такая конфигурация required_matchers. Это позволяет вам отсылать запрос на Remote Storage, которые соответствуют выражению. Чтобы читать агрегированные данные из Remote Storage, необходимо использовать запрос, в составе которого присутстует двоеточие. 

Есть опция, которая позволяет вам читать или не читать недавние данные из Remote Storage, которые есть в TSDB. Обычно в стандартной конфигурации есть небольшая локальная TSDB, которая пишется на локальный диск. Она там хранить несколько часов или несколько дней. Данные, которые используете сейчас, которые используется для оповещения, которые используются для построения dashboard, читаются только из локального TSDB. Он быстрый, не позволяет нам хранить очень много данных.

Старые исторические данные будут читаться из Remote Storage. Это дает понять как локальный Storage и Remote Storage между собой связываются. Отсутствует какая-либо дедупликация.

По сути что происходит. Данные берутся из локального Storage, данные берутся из Remote Storage, если read_recent включен. Они просто сливаются вместе. Казалось бы это не проблема. Если предполагается что мы недавние данные никак не downsamping, это точно те же данные, они полностью совпадают с локальными данными, у нас будет в два раза больше семплов, но ни какие функции не должны влиять. На самом деле нет. Есть функция irate() и парная ей для gauge, которая возвращает нам разницу между двумя последними значениями. Она заглядывает на указанный диапазон назад во времени, но при этом использует только два последних значения. Если у нас два последних значения имеют одинаковое время, то разница будет ноль. Это баг и практически невозможно найти это. Это починили буквально четыре дня назад. Bот [ticket](https://github.com/prometheus/prometheus/issues/4184) кому интересно.

![](https://habrastorage.org/webt/-q/3w/dw/-q3wdw3czygpvkk009lrnhumska.png)

Интересно что remote read реализуется самим prometheus начиная с версии 1.8. Именно тот способ, который позволяет вычитывать данные старого prometheus, когда вы делаете миграцию на версию 2.x. Официальный способ советует подключать его как remote read. Данные будут вычитываться по мере необходимости.

Remote read можно использовать для того чтобы делать query роутинг без прокси. На одном из предыдущих слайдов я показывал что в зависимости от времени, мы можем делать роутинг на один prometheus или другой. Точно так же можем этого избежать. Просто подключаем тот prometheus, который стоит ниже как remote read и данные будут читаться оттуда. Но есть поправка на то что конечно много данных будет перекачиваться. Особенно если вы не используете query hint.

![](https://habrastorage.org/webt/gq/op/fz/gqopfzpgoe3kidpqufnedn5gfrk.png)

Почему Clickhouse?

- Для нашего исследовательского решения мы выбрали привлекли clickhouse, потому что мы на него уже давно смотрели. У нас есть люди, которые постоянно занимается перфомансом баз данных, постоянно проверяют новые базы данных. Наша компания занимается opensource базами данных.
- Нам очень нравится его сырая производительность. Его мощность в пересчете на CPU, время очень хорошее. Большинство подобных систем говорят про бесконечную машстабируемость, но мало говорят про эффективность для 1 сервера. Многих наши клиенты хранят метрики на паре серверов.
- Встроенная репликация, шардирование.

- GraphiteMergeTree - это специальный движок для хранения данных графита. Нас он в начале очень сильно заинтересовал.


![](https://habrastorage.org/webt/ot/nk/sn/otnksno5uhhcgn7j5-fp5xnxneq.png)

Движок предназначен для rollup (прореживания и агрегирования/усреднения) данных Graphite. 

Graphite хранит в ClickHouse полные данные, а получать их может и дальше там написано что с прореживанием используется GraphiteMergeTree, без прореживания используеться MergeTree. Ощущение такое что данные хранятся всегда полные, они не переписываются, это просто оптимизация чтения. Но в целом это неплохо. Когда мы делаем чтение, мы не выкачиваем данные, они автоматически аггрегируются, мы получаем мало данных - это хорошо. Минус для нас что данные хранятся все.

Я готовлюсь в начале месяца к докладу. Кто-то заходит телеграмм чат и спрашивает GraphiteMergeTree данные downsamping? Я уже пишу нет. В документации написано что нет. Но другой человек из чата отвечает "да, нужно вызвать optimize". Запускаю, проверяю - да правда. В документации по сути баг. Потом прочитал исходный код, проверил, оказывется там есть optimize, optimize final. Optimize final как раз изначально создавался именно для GraphiteMergeTree. На самом деле downsamping он делает. Но его надо вызвать руками.

У GraphiteMergeTree другая модель данных. Нет у него лейблов. Эффективно запихать это все в названии метрик не очень хорошо получается.

Название метрик хранятся в одной таблице. Название метрик имеет разную длину. Это приведет к тому что, если мы делаем поиск index по названию метрики, из-за того что длина разная, этот индекс не будет так эффективен как, если бы этот индекс имел значение фиксированной длины. Потому что вам нужно делать поиск по файлу. Нельзя точно указать куда должен приземлиться для того чтобы бинарный поиск делать. 

![](https://habrastorage.org/webt/c3/v4/zf/c3v4zfriducmhoahjwujmp1zdga.png)

Поэтому сделали свою собственную схему. На слайде показывается как у нас хранятся time series в базе данных. Date, который нужен к clickhouse это fingerprint. Если вы смотрели исходники prometheus или TSDB, то вы знаете что fingerprint по сути короткая быстрая checksum полного названия time series. fingerprint - комбинация всех лейблов, ключей и значений. Имя это обычный лейбл. Мы использует тот же самый алгоритм для совместимости. Если что-то дебажить, то это может быть удобно. Fingerprint совпадает и его можно проверить в TSDB и в нашем storage что они одинаковые. Лейблы хранятся в специальном JSON, который позволяет clickhouse работать с ним его стандартными функциями. Это компактный JSON без пробелов, с немного упрощенным скальпингом. Эта таблица во время работы не используется. Она всегда хранится в памяти нашего собственно решения, которой называется promhouse. Она используется только, когда мы запускаем сервер для того чтобы узнать какие time series есть. Она вычитывается. По мере того как новые time series приходят, мы их туда записываем. Все несколько инстансов promhouse могут читать одну и ту же таблицу. ReplacingMergeTree говорит нам о том что эти time series - есть несколько разных инстансов пишут одну и ту же time series. Они смержаться и никакой проблемы здесь не будет.

![](https://habrastorage.org/webt/ms/lg/1t/mslg1tnbc97nrlauwcr9ekj-p3k.png)

Cэмплы мы храним в отдельной таблице очень эффективно. При значении фиксированной длины этот fingerprint тот же самый, время и значения. У нас получается 24 байта на sample. Оно имеет строго фиксирую длину. Каждая колонка хранится отдельно. Поиск по fingerprint эффективен, потому что мы знаем что размер фиксированный. Нет такой проблемы как с GraphitmergeTree, когда это строка. Мы используем кастомный(custom) partitioning. Первичный индекс fingerprint и по времени.

24 байта это в упрощенном варианте. На самом деле он хорошо сжимается. По факту использует меньше места. В наших последних тестах степень компрессии примерно 1 к 42.

![](https://habrastorage.org/webt/wu/5y/24/wu5y2499vjvrcm37ct1gudfrpym.png)

Как можем сделать ручной downsampling, если у нас GraphiteMergeTree есть, но не такой как хотелось бы. По сути мы можем сделать это руками. Как раньше делали шардирование, партицирование, когда ничего встроенного не было. Делаем руками новую таблицу. Когда к нам приходит сэмпл по времени, определяем какую таблицу пишем.

Выбираем по времени из запроса из какой таблицы читать. Если чтение происходит на границе, читаем несколько таблиц. Дальше мержим эти данные. Можно было бы использовать view для этого. Например, сделать view для несколько таблиц, который позволяет это читать одним запросом. Но в clickhouse есть баг: предикат из view не подставляются запросы. Поэтому если вы делаете запрос в view, то он идет на все таблицы. View мы не можем использовать.

Как мы делаем downsampling? Мы создаем временную таблицу. Копируем из нее данные ensert into select, используя правильные функции.

Делаем rename, который атомарный под глобальным локом. Мы переименовываем существующую таблицу в старую. Новую в существующую. Дропаем старую таблицу. У нас данные за 148 день уже downsampling. Какая здесь проблема? Insert into красиво выглядит. На самом деле нам нужно применить правильные функции, правильную агрегацию сделать. На практике это не получается сделать одним большим запросом. Даже несколькими большими запросами е получается сделать. Это приходится делать из кода. Код посылает большое количество небольших запросов. Мы по-максимуму старались это сделать большими запросами, но это не очень эффективно получается. Downsampling данных одного дня пока что занимает меньше дня. В зависимости от количества данных может занимать долгое время.

![](https://habrastorage.org/webt/7c/94/h4/7c94h4t2bbvk5x-3acoftonomxa.png)

В clickhouse будут update/delete. Delete уже первую версию вмержили. Если будут работать update/delete, то наша схема downsampling данных может упростится.

Во-вторых в clickhouse есть задача сделать кастомное сжатие (дельта, дельта в дельта). Это то, что делает TSDB.Это хорошо подходит для time series данных. Это очень особенно полезно, если мы будем иметь возможность выбирать тип компрессии в зависимости от типов данных. Например, counter, который только растет - для этого подходит дельта компрессия. Gauge, который колеблится вокруг величины поэтому дальта в дельте хорошо работает.

![](https://habrastorage.org/webt/od/mv/hx/odmvhxcnnite5wum9k9gwfifbec.png)

Есть другие storage, которые работают. Есть InfluxDB, который работает из коробки. Его принято ругать за скорость, но то что работает из коробки и вам ничего не нужно делать это хорошо.

Есть OpenTSDB и Graphite, который только на запись. Стандартный адаптер из prometheus не особо работает.

Есть CrateDB. Есть timescaleDB, который fork PostgreSQL для time series баз данных. Говорят работает неплохо, но сами мы не пробовали.

Есть Cortex, который также был известен как проект франкенштейн. Это очень хорошо его описывает. Это ребята пытаются сделать решение на основе федерации prometheus. Они хранят данные в S3.

Есть Thanos. 

- У него очень интересная архитектура. Есть prometheus, который использует локальный TSDB. Между ними создается кластер. Рядом с каждым prometheus ставится специальный side-car, который по remote read и remote write API принимает запросы. Эти запросы перенаправляет их prometheus. Prometheus может использовать его remote read и remote write API. Все side-car соединенные между собой и между кастомным API мастера, который через gRPC доступна репликация, есть перешардирование.
- Сложная архитектура.
- Оно довольно сыровато. Пару месяцев назад оно разваливалась с полпинка, когда запускалось.

![](https://habrastorage.org/webt/a9/rc/zm/a9rczmkse4viit4vvr4hgqfcuts.png)

Используя Pull-модель много данных не записать. Нужно ждать целый год чтобы данных для заполения годичных данных. Можно пытаемся как-то их туда запихать.

В prometheus отсутствует remote write, поэтому в локальный TSDB записать много данных не получится.

Вторая проблема. Если мы генерируем данные для нагрузочного тестирования, то они часто хорошо жмутся. Например, если мы берем существующие данные и генерируем 100 инстансов, и это одинаковые данные, то там коэффициент сжатия будет такой прекрасный, что в реальности не случаются.

![](https://habrastorage.org/webt/fy/mc/uk/fymcukkdoo3hi78gkw1eb2ipvsk.png)

Мы написали fake экспортер, который выглядит как обычный экспортер, который prometheus может скрепить:

- Когда приходит скрейп, он идет на какой-то апстримовский экспортер. Берет с него данные. 
- Генерирует много инстансов. Допустим скрейпит 1, а на выходе получаем 100. 
- Немного меняет данные: плюс минус 10 % для counter и gauge. 
- Не меняет простые значения 0 или 1. Потому что если есть метрика UP, которая ответчает показывает запущен ли сервис: да - 1 или нет - 0. И не очень понятно что означает 098 UP.
- Не меняем целые числа на вещественные и наоборот. 
- Просто отдает данные в обычном формате expfmt.

![](https://habrastorage.org/webt/c0/ja/hc/c0jahc5ryn-oxhwxnke_vaj1mia.png)

Инструмент promload, который грузит данные. Чтение данных:

- Может читать из файлов своем формате
- Может из remote read
- Может из-за какого-то экспорта читать

Пишет в разные форматы. В том числе в /dev/null, если мы хотим протестировать именно как чтение быстро работает. 

Сейчас это инструмент нагрузочного тестирования не только для promhouse, но и для любого решения, который использует remote read или prometheus. 

![](https://habrastorage.org/webt/qr/xa/-2/qrxa-2wg58troaskuqhqowwicq4.png)

Мы хотим добавить кеширование чтения, потому что в наших тестах часто узким местом был именно fake экспортер, который долго генерировал данные. Мы могли бы их кэшировать. Пусть они будут нереально хорошие. Зато мы не будем тормозить. Нам не нужно быть днями ждать наглузочного тестирования.

Какая-то фильтрация на лету. какая-то модификация на лету.

Нативная поддержка TSDB. Для того чтобы именно работать с базой данных на диске, а не через API.

Фокус на аккуратность для миграционных. Я один раз pmmdemo.percona.com положил: подключился, получил все метрики. Если вы делаете это нативным способом, то prometheus открывает TSDB, поднимает все time series с диска, поднимает индексы, дальше лезет в chunk файлы, понимает что они реально есть. В этот момент все может просто лечь. 

Найвный подход это взять все time series и читать начиная со старых данных до новых. В этот момент он ляжет. Вам нужно сделать наоборот. Нужно сначала получить список time series несколькими запросами с регулярными выражениями. Например, time series, которые начинаются на A. Потом дай мне time series, которые начинаются на B. Дальше грузить их именно по метрикам, а не по времени. Это нелогично, но так это работает. Это нюанс, если вы будете делать что-то такое подобно. Если увидите что там OOM Killer случился, то вы будете знать что это из-за вас.

![](https://habrastorage.org/webt/mz/z9/kh/mzz9khnykox-3r2wlp_lpgphil4.png)

вот внезапно ключ на тестирование самое главное графики и так далее их не будет вот потому что как я уже говорил накручены тестера не занимает много времени и к сожалению из-за ошибки конфигурации в насоса крошилась и поэтому результаты не получился 

вот в блоге перк он и мы напишем когда это все будет 

но если так псевдо научно да без графиков так далее как она была запись была линейно что странно ну окей ладно ни странно но поначалу было неожиданно когда данных нет запись была довольно медленно откуда много данных скорость записи практически не изменилась очищение вот довольно неплохо скакала вот и в целом было не очень быстрое устройство на мне очень важно и чтение текущих данных до которые можно там через кенты можно ускорить или trees and тоже включить все будет хорошо а для старых данных это нормально работает

![](https://habrastorage.org/webt/b6/7f/4w/b67f4wmgkuzi6zyqnitxlwuv2t8.png) 

выводы люди хотят долговременны хранилища с такой спрос есть мы делали доклад программ house на пром кони там это прямо было очень горячие темы это нас тоже там активно развивается поэтому видно что все этого хотят

 это уже возможно сейчас то есть если это решение есть теперь есть какие-то интеграции но все это нужно дорабатывать напильником вот пока ничего такого к сожалению production соединить нету 

![](https://habrastorage.org/webt/ms/qk/ec/msqkechijgscjucb7sx8knkzwx0.png)

ссылки где посмотреть это смотри по истории нашего прав хаоса это тон откуда она скорее все приедет вот но там любом случае будет интеллект потом почему потому сейчас в одном репозиторий несколько разных вещей не очень тесно связанных между собой поэтому нужно будет их поносить 

вот и соответственно в нашем блоге будет информация про performance но вообще какие-то новости все спасибо

вопросам

раз-два-три спасибо спасибо леса доклад мне вопрос есть по поводу рефлюкс baby не проверяли вы вот эти знаменитые слухи про то что friends говно если китайцев ты 

но царей он был действительно очень хороший он сильно силу лучше стал то есть все эти байки про то что influx там медленные разваливать стали они все просто рвемся не знаете подняли денег подняли людей которые умеют писать баз данных и в целом текущая версия работает стабильно я бы не сказал что она прям супер супер быстро работать стабильно плюс influx baby на мой взгляд 

во первых то что не нужно делать что-то рядом потому что она работает из коробки во вторых как и не знаю как река у сада как какие-то других решений на основе базу данных но нет сдпр вы можете использовать язык запросов когда вам более знаком то есть influx кий язык запросу похож на сквере достаточно для того чтобы на нем можно было делать аналитику который на промке ель делал сложно вот а если вы там используя томский где пятна вообще настоящий стиль вот нос перфоманса но последних чисел меня к сожалению нет я знаю что по стабильности лучше стал не могу сказать 

еще вопрос графический движок только на запись получается получать если мы хотим пока графики показывать нужно графону настраивать на графит что показывают и долговременное хранилище 

да да то есть то интеграция тот не про графит mach3 а именно про интеграция которая есть сам управитель зато такой на запись соответственно он только пишется дальше либо из grafana выходите в графит либо еще факты

он теряет по моему лейбл на при этом куда пишут там есть конфигурация которая говорит как бы что с ними делаете либо с как и вставляете либо куда вставлять либо кидай да но в общем это настраивается но на самом деле там очень мало коды по большому счету если нужно там это как-то память от легко steel 

но выявит еще рассказывал недавно что они планируют перед свое решение для записей с правительством графит ну я могу добавить что чатик это церковь метрик скорее 

да telegramе да это было неожиданно

спасибо вообщем спасибо за доклад немножко не тот слайд ну суть какая вопроса там был вывод что записи все хорошо вот на сервер долговременного хранения хотелось бы спросить насколько хорошо есть у вас такая информация может быть вы работали с вашими клиентами там да да вот вот запись там линейно примеру там миллион метрик летят там пятиминутки там или 15 минут и что нам хватит ли нам там raid 6 sata дисков ленты как 

сколько вы храните ходить по времени 

примеру там год 

смотрите то есть у нас если три да я понимаю м м у нас основной интервал скрейпинг это на секунду то есть мы больше часть метрик никак 30 секундах было в докладе в главном зале у нас каждую секунду вот при этом был сэм link мы делаем там начиная помощи 14 дня и делаем там до 1 минуты и второй шаг мы пока ещё ни разу не делали то есть мы не агрегирует данные по одной минуте еще меньше вот соответственно это занимало там загрузим тестирует максимум сколько мы находились сотни гигабайт не было колебания скорости записи 

ну то есть я данных погиб сам там нет 

я говорил то есть это вот нижняя часть да это такая псевдонаучная почему потому что поэтому и спрашиваю жопу 

да да вот наш опыт пока ничего плохого и не заметил но конечно нам бы хотелось завести над нормально тестируем до конца и патологию описать результаты сделать графики оформить уже спасибо

спасибо а мне еще быть небольшой вопрос возник если мы пишем вин flux то мы тогда запрашиваем tool к дому долговременных данные за не флюкса 

кроме понимаешь что очень хочет fx зайдешь где не да но это зависит от 30 см на самом деле то есть это точно так же как и с любым другим ремонт ничего уникального для инструкций от зависимости от настройки если или trees and включен тогда будем читать

 потому что вот мы берем допустим для оперативных данных prometheus и долговременно пишем в influx мы тогда граф она тоже самое настраиваем на prometheus и prometheus может вытаскивать и то что оперативно это что записал винкс так провести то и другое то но и он будет попробовали вытаскивать до править уже выходить в includes вытаскивать данному протоколу и рисовать 

да и при этом в текущей релизной версии не будет делать дедупликации у вас будет проблема которые я вот сайтом
