Друзья! Всем привет! Меня зовут Алексей Палажченко. Я работаю в компании Percona. Я хотел бы вам рассказать про долгосрочное хранение метрик в Prometheus.

Я работаю в компании Percona и делаю продукт это называется percona monitoring and management. Это коробочное решение, которое наши клиенты ставит себе. Это полностью open source, который состоит из prometheus, grafana для рисования графиков, custom софта Query analytics и нашей собственной обертки, которая позволяет вам делать некоторое управление. Вы можете добавить scrape target в prometheus. Это новые цели откуда он будет брать метрики без того чтобы руками заходить в контейнер или в виртуальную машину и руками править файл конфигурации.

Важно понимать что это не SaaS. У нас нет продакшена в том плане что наш production находится у наших клиентов. На нем экспериментировать не очень хорошо. У нас есть ближайшая вещь, которую можно бы назвать production этот pmmdemo.percona.com. Cейчас он не работает. Кто может предположить почему pmmdemo.percona.com не работает? Из-за GDPR сейчас нам пришлось его выключить. 

Мы ставим PMM клиентам - коробочное решение docker-контейнер или виртуальная машина. Им всем нравится prometheus. Некоторые люди, которые первый раз смотрять на prometheus сталкиваются с pull моделью. Для новичков это неудобно. Вообще отдельный большой разговор. Можно спорить о pull или push методах. В среднем это примерно одно и то же.

Некоторые вещи в prometheus очень крутые. 

Например, prometheus query language это действительно крутая вещь, которой нет аналога практически негде.

Второе что нравится это service discovery. Если у вас какая-то динамическая инфраструктура, kubernetes, то автоматически не нужно добавлять руками все цели для мониторинга. Если статическое тоже это можно сделать довольно просто. Нужно использовать файл конфигурации.

Клиентам prometheus нравится. Они хотят хранить метрики дольше и больше. Кто-то использует prometheus только для оперативного мониторинга. Но кто-то хочет хранить  дольше, смотреть динамику, сравнивать со графиками год назад. При этом цель долгосрочное хранение метрик не является целью для проекта prometheus. Изначально он создавался для того чтобы хранить метрики недолго. Soundcloud хранит метрики буквально несколько дней. В prometheus есть механизмы, которые за это делать дольше, но они устроены немножко сбоку. Поэтому мы можем сделать решение для экосистемы prometheus не меняя само ядро системы. Мы на основе них можем сделать свое собственное решение в рамках этой же экосистемы. 

Это не доклад про готовые решения. это доклад про наш опыт, про нашу боль, про наши попытки. Если вы рассчитывали что после этого доклада вы там скачайте репозиторий с докер-контейнером, запустить и все заработает, то это не так. Но при этом это достаточно близко к тому чтобы быть так. У нас есть наработки. Они всего opensource. Вы можете взять попробовать. Они не готовы к production пока еще. Но с той информацией, которая есть в этом докладе, вы сможете понять почему так, что можно сделать лучше. Вы можете сделать свое решение, которое будет хорошо подходить вам.

Как метрики хранится в prometheus? Есть локальный storage. Есть remote storage. Это фактически два разных мира. Они слабо пересекаются. Поэтому и доклад тоже разделен на 2 части.

Если вы были на предыдущем докладе в главном зале где как раз была хорошее интро в prometheus, вы знаете что локальный storage это отдельная библиотека, который называется TSDB. TSDB не имеет ничего общего с OpenTSDB. Это отдельный Go пакет, который можно использовать из своей программы на Go. На уровне библиотеки TSDB нет никакого клиента и сервера.

Эта библиотека оптимизирована для работы именно с time series данными. Например, в TSDB есть дельта encoding, который позволяет вам хранить не сами числа, а именно изменения между этими числами. Это позволяет вам вместо того чтобы хранить 16 байт - хранить 8 байт. 8 байт под время и 8 байт под значение. То есть вы храните в среднем 1 или 2 байта именно за счет этого хорошего сжатия. 

TSDB оптимизирован для pull модели. Данные туда только добавляется. В prometheus нельзя запихать исторические данные. Для этого нет API. Максимальная дельта примерно 5 минут. Если данные более старые, они не будут приниматься. 

В TSDB нет никакого встроенного downsamping [tsdb#313](https://github.com/prometheus/tsdb/issues/313). Есть открытый issue, в котором была дискуссия на тему того что в целом есть проекты, которые вокруг prometheus что-то делают и там есть downsamping. Пока что решение такое что в TSDB не будут добавлять downsamping.

Как бы нам получить данные с TSDB. TSDB это база данных на диске. Работать с ней можно, если вы пишете Go программу. Но если вы не пишите программу на Go, то есть JSON API, который позволяет вам сделать query запросы. Если вы хоть раз пользовались prometheus и хоть раз строили какой-нибудь график, вы знаете стандартный Query API, в котором есть параметр query, в котором можно выполнить любой PromQL запрос и опционально время. Если время отсутствует, то берется текущее время.

На слайде выделено специфическое query, которое в реальной жизни вы редко увидите. Это хак. Это позволяет нам вытащить все метрики, которые есть в prometheus. Как это работает? На уровне PromQL говорится что нельзя написать такое выражение, которое бы заматчила все time seriers. Это прямо в правилах написано. Еще одно правило говорит о том, что нельзя сделать такой matcher, в котором все значения пустые. Если вы напишете просто фигурные скобочки это не будет работать. Если вы напишите name не равно чему-нибудь (не пустое значение), то не будет работать. А вот это реальный хак, который позволяет это сделать. при этом он даже не освобо документирован. В самом коде есть комментарии о том что это работает.

Второй запрос это query_range, который делает то же самое, но возращает вам данные в диапазоне и с неким шагом. Он по сути делает query несколько раз каждая степ начиная с начала и до конца это тот appia которого используется для того чтобы рисовать графики на 1 это использует для того что получить какие то моментально и значений это опять для данных да 

у нас есть еще опять это получение мета-данных даже если мы хотим получить все названия метров семь там sellers мы делаем вот такой запрос где матче это массив их может быть несколько аргументов но в данном случае мы придем тот же самый mature который нам возвращает все вот и 2 метра пик который возвращает нам значение всех лейбов то есть если мы хотим увидеть список всех джебов мы ее делаем место лейбл name job и получаем этот список вот но и теперь они возвращают нам джейсон api 

есть еще один и пять который возвращает нам метрики самого prometheus а все которые там есть именно формате который на и тивные для экспортеров так называемый x формата dx позиция форматы то есть это то что вот метрики дальше фигурных скобках порой cave вот в самом приметесь есть такое и кейси героично который вам позволяет сделать такой запрос плечо это нужно ну как бы самый простой если у вас есть какой-то код уже работает здесь что форматом вам не нужно его переучивать на то чтобы работать его с каким-то кастом джесси лампе этот формат гораздо проще стремится потому что если у вас джейсон то-то на верхнем уровне объекта чаще всего вам нужно это объекта расспросить целиком сначала ведь это можно делать по строчке так далее 

но самое главное это отдельные пей он работают именно как настоящие export а то есть вы можете взять и другим про митю с моего за скрепить это обычный job с обычными параметрами есть ничего не есть и вам нужно передать параметр то есть отправиться на самом деле это часть в коридоре url вот если вы дергаете то руками кром вы это получится здесь тоже самое мы получаем все метрики для текущего значения времени и десны нюансы надо поставить и хонор у лейблов для того чтобы ремедиос который будет скрепить другой parameters через и т.п. не перетирал значение job in словил таким образом использовать этот период для фетида что вы по сути можете загрузить все данные загружать все данные и снова prometheus у трубы 

для чего это нужно как это можно использовать ну во первых надо самое главное сказать что так делать не надо а вот этот пример с комментарием да то что вот этот хак addict реаль там написано почему не надо стб оптимизирован для другого режимы работы самое главное если у вас есть prometheus которой скрипит много данных в нем делаю довольно большое количество ввода-вывода если вы делаете федерейшн вы это конечно воду воду по сути удваиваешь там есть нюансы зайдите того как часто вы делаете скрип на фидер аид и как часто вы скрепите таргет и но в среднем если это время там не на если во время вообще не меня ли она у вас по умолчанию то это действительно увеличить два раза и поэтому если вы хотите со скейте ваш prometheus и учить федерейшн то вы его убьёте потому что если он уже вам нужно застелите в нем уже есть какая-то нагрузка то она просто учиться два раза

второй момент вы будете пропускать данные вы получите конфликты в данных почему так этапе и вообще как почти любой пеев приметесь он не атомарный это означает что если придут новые данные закончится новый скрипт в тот момент когда ваш фидера это запрос еще идет вы можете получить для одной там серии одни данные для друга и уже новые если это не связано там сервис это в целом не страшно представьте что если у вас самаре или гистограммы которые на уровне кайфом это я представляется нескольким базовым метриками да там несколько ударов мне сколько годжи будет между ними несогласованность

как мы можем решить эту проблему от омар ность вы наверно знаете те кто использовали про мюсли кто был на предыдущем докладе что в промыть еще есть такая вещь как regarding rules который он позволяет создать новую там серы из существующей там сели при этом это можно делать и реже это один из способов сделал down сэмплинг то есть вы допустим скрепите отторгает какой-то каждую секунду как делаем и в пмм потому что нам важно очень высокая точность но дальше мы хотим сделать допустим агрегацию водить мотоцикл в данном примере по за одну минуту группировка в prometheus 20 это новый в 20 позволяет вам делать эти агрегации последовательно то есть я провела который в одной группе они выполняется строго последовательно и в этот момент уже нету проблема-то мордасти вот именно того что данные по меняются в процессе но это не решает проблему того что это если допустим какие-то другие данные которые связаны логически с этими но они связаны с точки зрения модели данных то есть такой чистая тамар насти пока нет есть открыты еще на эту тему там сделать какие-то снапшоты или самое простое когда мы делаем запрос пленки любой данных тсд б ты мы можем отбрасывать все сэмплы которые меньше какого-то значения времени в которое началось в женщин да собственно это был бы самый простой способ но пока его не сделали вот важно понимать что вот этот вот рик орден трусов нужно делать на нижнем уровне на нижнем прометее все они на том которые делают лидеры вот иначе вы будете пропускать пике у вас неправильно будет работать мониторинг тогда

как мы можем использовать эту комбинацию этих вещей для того чтобы сделать долл 7 линк и долговременных ранений поэтому мы просто ставим федерейшн и загружаем все данные с того prometheus а то вот это вот странно регулярное выражение похоже на зойдберга это на самом деле просто : и слева справа звездочка да то есть мы используем стандартное название для record and rules до который добавляется в это очень середину то есть при делении оригинальное имя слева слева уровень агрегация справа функции кажется примерно так вот соответственно в нормальный метрики к : нет поэтому если есть : это признак того что это агрегация который мы едим берем и поэтому и все загружаем после этого мы используем вот это название метрики в нашем графике если мы хотим чтобы наш график нас дашбордов графа не например элементом еще что ты работал из главным громить его сам из тем кто стоит выше мы можем использовать выражение оу да то есть мы берем либо одними только либо другую зайти с того которой есть или мы можем схитрить и при помощи ребенка переименовать новую в метрику старое имя этот довольно опасный подход почему потому что можно не правильно написать регулярные вложения и выпрямите что-нибудь не то что нибудь не то у вас будет конфликтом сириус prometheus будет писать кучу вардинга флаг вы это увидите ног найти причину может быть довольно сложно это сделать аккуратно разминировать эти регулярно выражении программные то это будет работать дальше вас будет обычный дашборд где используется только not циpкa и зависимость того какой parameters используется либо 1 либо другое вы будете получать либо исходные данные либо же агрегированные

как искал эти рекорды нкр усах можно генерировать довольно просто мы просто получаем все там сейчас через api через 15 а хопи который я уже показывал мы создаем правила и эти правила должны использовать правильные функции и оператора что и между и между что ну вы знаете наверное что не нужно использовать там рейд с гаузами да это будет не правильно работать нужно использовали каско утром на том уровне где вы работаете вас может быть нибудь информация тип данных например если вы используете экспозиция формат там информация типах есть если безусловно питом этого нет как следствие ваш как бы выражение которые вы автоматом сгорите может не иметь никакого физического смысла поэтому можно использовать там либо белый список либо черный список вот и в зависит от the gate либо нужные вам правило либо пород выкидывать те которые вы знаете что не имеет смысла и есть инструменты парам tool которые позволяют вам проверить что те правила которым взгляд от конфликта разберу и он имеет смысл то есть он имеет корректность яндекс но как я уже сказал если у нас есть графа на и там несколько parameters нам нужно как-то знать на какой кормить из отсылает запрос вот и как бы нам это сделать

один из способов это поставить специальный прокси который будет смотреть на время в запросе зависит от а выбирать prometheus да как я уже показывал раньше там есть время начала и время конца за этим сюда то можно руками делать роутинг вот можно было бы взять какую-то программу к такого это делается на практике это делается там ценник с модулем на простейшем одну строчку или очень-очень маленькое программы поэтому мы даже выпуска с не выложили то любой может сделать 

вот но а нужна ли она вообще 5 дату семейный смысл так заморачиваться выкачивать из данной языке и можем ли работать теста б напрямую до можем вот есть какой нюанс opel их если мы пытаемся использовать тсд который используется уже подметил сам сейчас мы этого сделать не сможем там я специально лог файл который превращает это если мы каким-то образом проигнорируем там под хочу код или что то еще вам и пытаемся данные читать или писать это мы гарантируем их повредим при этом даже чтение вот что можно сделать это можем читать данный через теперь и создавать новую тсд по рядам дальше промыть и установить ему то есть db подменить вот но при этом мы можем за и производительность если будем читать сюда на часы и я об этом немножко позже скажу 

второй вариант можно просто скопировать сделать ход backup этих файлов то скопировать как есть да они будут поврежденные когда вы откроете вас там будет воронка том что данные повреждены их нужно починить вы можете потерять какие-то самые новые данные но нам это не важно потому что мы хотим донца представлены данные как правило да то есть новые данные если они хорошее завершение нам это отлично вот и dancing можно сделать вы можете просто взять prom queen и дальше там вот как раз кромка или выражение писать кто-то вам сделаю там поджидает за одну минуту все будет работать на из нюанс его оторвать от prometheus гораздо сложнее чем тест д.б. то есть просто если вы немного знакомы с go из управлению зависимости он там винды ринг пранки или это боль это большая боль я бы вам не советовал по возможности избегайте

вот с локальным стражем все давайте переходить к крему в том же вообще что это так как только нити работал с ним вот сторожем в prometheus еще несколько рук я скажу это интересно на самом деле ремонт старый штамм этапе он довольно давно уже существует там старой версии сейчас даже сейчас версии 2 2 которые последние она помечена как экспериментальный более того примерно известность что нас точно поменяется 

вот она позволяет вам работать только с этими данными вот в том плане что там нет никакого пранки или на входе и на выходе он понятно вы пишете его пишется только сам путин вопросов нет но когда вы читаете вы не можете использовать всю мощь compile есть он по сути заканчивать все данные зримо восторге которые соответствуют условия дальше пром келли работать уже с ними вот это имея довольно большой вверх от и вам нужно много данных прокачивать посетит поэтому в prometheus 23 который пока не вышел но уже это в мире будет называем варить кенты мы чуть позже об этом поговорим вот опять для metadata пока что нет то есть вы не можете сделать теперь который вам защищает все там sillies из ремоут столь же если вы держите atpl parameters а он в ремонт сторож не пойдет он вернет вам так этом селе сказал есть его локальной базе данных если вас локальная база данных отключена он вернет вам 0 что может быть немножко неожиданно вот сейчас этот это использовать потапов довольно такой простой хотя не само удобно для работы с ним но и точно его поменяем герпесе в будущем сейчас это пока что не сделали потому что джордж 5 требует ищите по 2 у них на практике с ним были проблемы

так вот опять для записи выглядит вот так но там просто берем насчет в запросе у нас есть набор лебофф набор лейбл в как раз уникальное дефицитом сириус то есть мы им это на самом деле просто лейбл со специальным именем вот сэмпла это набор времени и значения то есть два float 64 вот при записи порядок неважно предполагается что база данных которые это пишут в себя сама все сделает правильно поймите сможет сделать на которой оптимизацию и не сортировать это лишний раз вот соответственно запрос на запись это просто несколько m-series

вот у конфигурации на запись довольно гибкая большая конфигурация в тот лично для меня было неожиданностью и только маленький кусочек там очень очень много параметров для конфигурации параллелизма запись а то есть то что правительство от чар лингам это по сути конкурентные запросы и можно ограничить максимальное количество сэмплов одном запросе сколько максимум параллельных запросов какой-то mode как повторяйте какой быков он там экспоненциально растёт и так далее вот это дефолта вы и значение и для многих баз данных например у тпа стол сэмплов за раз это может быть очень мало то есть если вы используем только us как используем и то конечно значение надо сильно увеличивает иначе это будет очень не хотим соответственно

ремонт элит выглядит вот так это просто диапазон по времени начала до конца и набор mature mature и это по сути как раз набор пар знаем его то есть обычный лейблы и типа значений но сравнение да то есть равенство неравенства или регулярное выражение то есть то что либо тот обычный мальчик который вместе видите в кромке никаких функций здесь нет вот как я уже сказал при этом предполагается что ремонт швырнет все сэмплы которые есть соответственно в запросе это запрос результат это несколько м-сервис которые соответствуют этому запросу при этом здесь сэмплу за должны быть отсортированы по времени опять же это вызывает prometheus и немного сэкономить нам циpкa не нужно сортировать но предполагается что ваша база данных должна это делать но что почти случай в общем то и так будет потому что скорее всего там будет яндекс по времени

вот в за track of scale появились элит финты что это такое это возможность подсказать prometheus какая внутренняя функция вот именно самое внутреннее до которая работает там сидя с которой запрашивается будет пленена то есть это либо функция либо оператор агрегация то есть это может быть ну то есть отмазаться фанк на самом деле это может быть в том числе и сам который с точки зрения пранки ли на самом деле совсем не функция дает оператор вот и шаг то есть как на предыдущем примере там был рейд и одна минута вектор здесь вот как раз раид это будет функция и одна минута в миллисекундах как шаг совместно этот hand он может игнорироваться ремонт борьба на при этом в ответе нет никакого признака как она вобще игнорировал селенит как же это работает но сейчас об этом скажу то есть 

какая конфигурация вреда во первых есть такая консультация за liquid matures это позволяет вам отсылает запрос на ремонт сторону только те которые которые соответствуют выражению да то есть мэр вы можете читайте займут столь же только те в том как я же правил есть : то чтобы читать оттуда только уже агрегированные данные среда не читать есть опция которая позволяет вам читать или не читать недавние данные и заливал стран же которые есть тсд б обычные стандартные поставки стандартном конфигурации как это мечта людей использовать есть небольшая тсд б локальная которая пишется на локальный диск и она там охране допустим несколько часов или несколько дней и данные которые используете сейчас который используется для лифтинг которые использовал существа зажмет love они читаются только из из локального столь же который быстрый который не падает нам хранить очень много данных пусть искрится но при этом это будет быстро и только старые исторические данные будут читаться за ремонт вотже это типичная нормально ситуация как это как хороший опрос как локально сторож или могут 8 с тобой связываются да то есть подходит ли какая-то дедупликации нет ответ нет то есть по сути что происходит данные берутся из локального стран же данные берутся из ему удар уже если у нас 33 сент заключен ну точнее оборот включен да то есть мы их данные читаем эту дату да они просто сливаются вместе не какой-то дупликация казалось бы это не проблема на самом деле да то есть если предполагается что мы недавние данные никак не дал сэм блюм это не точно те же они полностью совпадают с тем данных тросе с локальными у нас будет два раза больше sample of но не какие функции от не влияет казалось бы на самом деле нет есть функция рейд такая и соответственно порно ей не помню название для годжи которая возвращает нам разницу между двумя обижаешь между двумя последними значений заглядывает на указанный диапазон назад во времени но при этом при этом используя только два значение последней если у нас два последних значение одинаковая имеют одинаковое время то разница будет ноль это ломается этот баг и практически невозможно найти то это просто вы не можете плюс этих это боль вот это починили буквально четыре дня назад вот но до этого конечно это было так ломало мозг вот ticket кому интересно

вот так что еще проверим о вытрет интересно что ремонт 33 лизу это самим prometheus то есть причем начиная даже сверх 18 уже там версий 180 астана старая там ремонт лиц стабильный ну просто потому что никакого нового релиза ветки 1 x больше не быть это именно тот способ которым позволяет учитывать данные старого provides a когда вы делаете миграцию на 2x официальный способ если вы читали там документация и tutorial или блокпост он кроссовер подключать его как ремоут ride вот и соответственно данные будут вычитаться только по мере необходимости

вот еще можно использовать его для того чтобы делать кго и роутинг с прокси помнить о следующем слайде я показывал что зависимости от времени мы можем делать роутинг на один превысить или другой точно так же можем этого избежать и собстна почему мы это ничего не выложили вот у нас потому что в общем-то часто не нужно просто подключаем тот примите с которой стоит ниже как я мудреца данный будет читаться оттуда вот но есть поправка на то что конечно много данных будет скачиваться котел заговорил особенно если у вас релизной версии где никаких к варе финтов и ничего такого нет вот 

мы для нашего питания которое мы скорее за на такое не знаю пол экспериментально исследовательской а вы привлекли к ос почему потому что мы на него уже давно смотрели у нас есть люди которые постоянно занимается перфомансом баз данных постоянно проверять новые базы данных как они это вот так далее наша компания занимается около 40 базами данных поэтому неудивительно нам очень нравится его сырая производительности в том плане что его мощность по в пересчете на циpкa время и так далее она очень хорошее существо подобных систем они говорят больше найти там по бесконечному масштабируемость и так далее да но мало говорят про эффективность когда там допустим один сервер для многих наших клиентов это не так что некоторым десятки кластеров с хаосом где они хранят метрики чаще всего это там 123 хотя клиента который вообще использует а решение конечно их пока не очень бы 

вот и встроенные репликации родирование многие заз это знает

и график творчестве этот социальный движок для крайне данных графикой и это был один из тех моментов на котором хотел бы остановиться на сон начали очень сильно заинтересовал отлично есть какое-то решение должен хранить и метрики 

идем читаем открываем документацию смотрим буквально прочитаю назначена для лап прорезывания и агрегации усреднения данных графит графит хранит в crack house полные данные и получать их может и дальше там написано что с прореживанием используется графит мышцы без поражений использоваться мар 4 обычно то есть все не такое что данные хранятся всегда полный на место они не переписываются это просто оптимизация чтение но в целом это неплохо да то есть как бы когда мы делаем числе не ем и не вы качаемся данные они автоматически корректируется он получаем мало это хорошо - для нас тоже данных нет со всех я готовлюсь в начале месяца к докладу вот кто то заходите грамм чатик спрашивает графит марсе данный дом запрет нет я уже пишу станет цветным документации написано что нет то другой отвечает да да он сам придти по нужно optima использовать отлично короче запускаю проверяю да правда здорово там документации по сути пока потом слазил в год проверил доказать совместимая с есть а прямо из файлов office file как раз изначально создавался именно для графе творчестве то есть на самом деле dancing он делает но его надо вызвать руками то есть автоматом или нет или у людей не работать и не знаю 

но к сожалению мы все-таки даже в этот момент когда мы это уже обнаружили ну во-первых был уже поздновато конечно ты начала месяца то есть это был месяц назад но как бы графит хранит у нее другая модель данных то есть по сути название метрики там нет у него лейблов и эффективно запихать вот это все в названии метрик не очень хорошо получается такая проблема то что название только у него хранится одна таблица название метрик имеет разную длину это полет потому что если мы делаем поиск как contain экспо название метрики из того что длина разные этот индекс ним будет так эффективен как если бы это был и значение фиксированной длины ну потому что вам нужно делать поиск по файлу да и дальше нельзя точно указать q должна приземлиться для того чтоб на pastel что здесь получили чтобы такой 

вот поэтому сделала свою собственную схему вот так это показывается как у нас хранятся там селес в базе данных дейт которая нужна к хаосу просто всегда есть некий fingerprint вот если вы когда нибудь смотрели исходники prometheus или тесты бы вы знаете что fingerprint это по сути короткое быстро чик сумма полного названия time series то есть комбинация всех лейблов ключей и значений и опять же им это просто-напросто обычный лейбл вот это checksum она быстро мы использует тот же сам алгоритм для совместимости никакого особого смысла в этом не было но если что-то де бо жить так далее то это может быть удобно совпадает можно принять в тсд быв нашему ставлю же что они одинаково вот лыбу все хранятся в таком специальном g sonic который позволяет к хаусу работать с ним вот его с нашими функциями то есть это компактный джейсон без пробелов там с немножко упрощенного скальпингом и так далее на самом деле это таблица реально во время работа она не используется она она всегда хранится в памяти нашего собственно решения которой оказаться house вот и она использовать только в тот момент когда мы запускаем сервер для того чтобы узнать у нас там series есть она учитывается и потом по мере того как новый там сели с приходит мы их туда записываем и всей несколько месяцев про хауса могут читать одну и ту же таблицу и соответственно для place and на 4 и говорит нам о том что эти там heroes есть несколько разных и став пишет одну и ту же там сервиса не с манджи циника вы проблемы здесь не будет 

вот сэмплы мы храним в отдельной таблице очень эффективны при значении эффективной длины это fingerprint тот же самый время и значения а то у вас получается как бы двадцать четыре байта на sample но на ином режиме да и она имеет строго фиксирую длину каждая колонка хранится отдельно при этом поиск по fingerprint у эффективен и потому что мы точно знаем что размер фиксированный да нет нет такой проблемы как скрипит на 4 когда эта строка вот мы используем красный противника на это в общем-то не очень важный и первичный индекс нас по fingerprint у и по времени 

вот но до двадцать четыре байта это такой наивный на самом деле вам довольно хорошо сжимается и поэтому по факту сильно сильный меньше места есть наших последних тестах там примерно степень компрессии 1 к 40 2 и 2 4 байта сильно сильно меньше

вот соответственно как можем сделать ручной дал сэмберг если у нас график март 4 как бы вроде есть коктейли выяснилось новыми не совсем то что нам хочется так мы сделали когда еще не знали что он вообще есть по сути мы можем сделать эту руками да то есть как раньше делать родирование проецирование тогда когда то ничего странного не был просто берем делаем руками новую таблица заранее выбираем таблицу заранее судом и когда к нам приходит сэмпл по времени определяем какую таблицу пишем 

дальше соответственно выбираем по времени и запроса из какой таблицы читай при этом если это происходит на границе читаем несколько таблиц и дальше можем эти данные вот казалось бы можно было бы использовать для этого до сделать какой-то view для несколько таблиц которые позволяют это читаете просто одним запросом не отделаться руками нов кликов есть бак о том что предикат ice view не подставляются запросы поэтому если делается в русскую он где-то на все таблицы что нам не хотелось поэтому даже view ним не можем использовать

вот соответственно на практике это как просто ну и как мы делаем но у самок мы задаем временно таблицу копируем из нее данные просто по сути entered in the select да опять же используя правильные функцию что важно потому что если опять же чтобы имела физический смысл и так далее

дальше делаем марина им который атомарный под глобальным лаком то есть мы переименовываем существующая в таблицу старую новую существующие дальше драпаем старую таблицу все тем самым у нас данные за сто сорок восьмой день для примеру да это типа день года это сегодня кстати вот то есть данные у нас в эту таблицу уже за дом , здесь проблема на свои очень большая вода тут insert into это так красиво выглядит на самом деле нам нужно же применить правильные функции потом тайна агрегации сделал так далее на практике это не получается сделать там под ним большим запрос или даже несколькими большими запросами это приходится делать из кода . посылает довольно большое количество небольших запросов мы по-максимуму старались это сделать нашими запросами комбинирует тогда митя но это не очень эффективно получается сожалению тамблинг данных одного дня ну пока что грублю занимает меньше дня и на чем вообще смысл не был но в зависимость это качество данных может занимать до говорю 

что будет лучше сегодня утром был митап папе хаосу который продлился вместо часа ника что достойный даже три и народ потом выгнал нас всех из ком-то докладчиков и там сидели вот соответственно там будет апдейты делита дели ты уже в менеджере как говорят вот только что первую версию уже в мир джоли и соответственно там дели ты будут как пообещали до конца недели сделаны что прекрасно соответственно если будет работать обретут роба 1019 схемами да он самый данных может довольно сильно упростится это приятно от 

во вторых есть задача про то что сделать кастомные сжатие от типа дельта дельта v дельта как раз то что делает sdb то что хорошо подходит для time сидя с данных да то есть необычное и там не знаю активация когда и универсально работы для всего одинаково хорошо или одинаково плохо а именно специально это очень полезно потому что там особенно если мы будем иметь возможность выбирать тип компрессии зависимости от типов данных типа то есть аккаунт автору только растет для этого удалите компрессии или галч который колеблется вокруг причины поэтому соответственно в дельте хороший работает 

вот и соответственно будут другие доклада про клика установите в частности завтра будет доклад алексея он как раз расскажет про планы кать-кать что еще там будет такого хороший много из этого мы конечно будем рады использовать 

вот есть другие стороны джейн которые работу это видимо буду уже ускоряться немного вот есть яндекс baby который работает из коробки его принято ругать за скорость но то что работая с коробки вам ничего не нужно делать это сабли хорошо

есть опыт тест db и графит каору только на запись стандартный адаптер из prometheus а у меня слабо работают

есть крае тебе который я так моя приторный баз данных а может есть time scale деби который ford под колеса для темпе лес баз данных говорят работает неплохо но сами мы не пробовали 

есть cortex который также был здесь как проект франкенштейн вот это очень хорошо его описывать это ребята пытаются сделать решение на основе федерации пролечился при этом они хранят данные vs3 ну может быть я не знаю то

 есть вполне может весь то нас точно кто-нибудь спросил поэтому я решил не ждать этого вопроса сразу добавил слайд у него очень интересная архитектура то есть есть prometheus который использует локальный тест db делается между ними кластер и рядом с каждым play prometheus он ставится специальный сайт карл который по риму три терема утра этапе принимает запросы и соответственно продает их prometheus и parameters можете использовать его ремоут риски могут райт дальше эти все свои карты соединенные между собой и между мастером кастомным пиаре которые через записи там есть репликация есть перетрудил не таяли так если вам кажется что это сложно это сложно это правда сложно то есть там сложной архитектуры я так говорю но вот то что я описал это реально вот она довольно сыровато то есть пока когда это запускал где-то там не знаю пару месяцев назад она разваливалась у пинка когда запускалась пока что ну пока сыру но как как мы знаем до нас вернется и как бы в девятнадцатом году следующем году вместе с новыми стилями да можно будет на нас попробовать а пока просыпаемся в пыль 

нагрузочное тестирование в чем проблем по модель много данных не записать нам либо просто запустили и и ждем и ждем и год ждем пока количество данных наберем или пытаемся как-то их туда запихивать

вот в прометее все есть ли могут ли встроенный но нет remove the right поэтому локальный тсд б взять то записать много не получится вот 

вторая проблема если мы генерим какие-то данные нагрузочные да не так что просто ждать то они часто могут быть слишком хорош слишком хорошо жмутся здесь например если мы берем существующие данные простыни рим там сотни 100 совфед одинаковые данные там коэффициент сжатия будет такой прекрасный что в реальности они случаются и метрики будут числа будет нереально

написали fake экспорт который выглядит как обычный exports который проведет сможет скрепить когда приходится crate он идет на какой-то апстримом ский экспорта какого мы используем нотекс паттернов это не очень важно пойдёт с ним даны видите тут много инстансов то есть ну там допустим 100 это делам и на выходе получаем 100 и немножко данные меняет плюс минус 10 процентов для контуров и гоу джей гистограммы и сам или мы к сожалению пока с вами работать нормально не можем потому что он не очень понятно как и вот не меняет простые значение тип 01 почему потому что если есть метрика об которые или да или нет и очень понятно что означает 098 вот так немножко работает вот и не меняем целые числа на вещественной наоборот но в общем по такой же логике если у нас есть часть запросов и это не рейд какой-то несёт такой то вряд ли имеет смысл его делает в честно вот мы просто дает данные вас в обычном спасёшь формате вот 1 ст метро инструментов 

инструмент пара mode который грузит данные там либо из там ну из разных мест да то есть он может читать из файлов своем формате можете зримого 3d может из-за какого-то экспорта рассчитай и соответственно пишет в разных форматов там в том числе вдохнул если мы хотим погрузить постить именно как чтение быстро работает вот и сейчас это фокус на скорость инструмент нагрузочного тестирования для не только для пром хаоса вообще для любого решения кто-то использует ему три ты ли использовать parameters 

вот но мы хотим сделать немножко расшили да мы хотим добавить кошерные чтения потому что в наших тестах часто узким местом был им нафиг экспортер который но довольно долгий данные и в целом мы могли бы их кэшировать пусть они будут там не реально хорошие дома зато вам мы не будем тормозить нам не нужно быть днями ждать на глубину тестируем какая-то фильтрация на лету к это модификация на лету то что делает треках спортом и видимо это придется скопировать фронту потому from out потому что иначе слишком долго получается и найденные поддержка тсд b для того чтобы именно работать с файлами с баз данных на диске не через api через api да и 

фокус на аккуратность для миграционных такой история я дерусь премиум дима положил просто как я взял подключился и запивал чо получил все метрики если вы делаете это на нем способом то есть дайте мне список всех метрик приведешь что делает он открывает sdb поднимаю все там сели с диска поднимает индексы дальше лезет в чат файлы по евро что они реальны и так далее поэтому он все может просто лечь вот и как бы на южный подход туда просто взять как бы все time series и начинает там со старых данных до новых читать до в этом он там лежит вам нужно сделать наоборот нужно сначала получить список аккуратно как-то вот там не за этом допустим несколькими запрос мысль являются выражением там да не считаем сирийскую получается на а потом дай мне считаем сервис означается на b и так далее и дальше грузить их именно по метрикам не по времени что нелогично но так это работает вот но это просто от нюанс если вы будете делать что-то такое подобно если увидите что вас там он случился вы будете значит этой за вас я вот так узнал 

вот внезапно ключ на тестирование самое главное графики и так далее их не будет вот потому что как я уже говорил накручены тестера не занимает много времени и к сожалению из-за ошибки конфигурации в насоса крошилась и поэтому результаты не получился 

вот в блоге перк он и мы напишем когда это все будет 

но если так псевдо научно да без графиков так далее как она была запись была линейно что странно ну окей ладно ни странно но поначалу было неожиданно когда данных нет запись была довольно медленно откуда много данных скорость записи практически не изменилась очищение вот довольно неплохо скакала вот и в целом было не очень быстрое устройство на мне очень важно и чтение текущих данных до которые можно там через кенты можно ускорить или trees and тоже включить все будет хорошо а для старых данных это нормально работает 

выводы люди хотят долговременны хранилища с такой спрос есть мы делали доклад программ house на пром кони там это прямо было очень горячие темы это нас тоже там активно развивается поэтому видно что все этого хотят

 это уже возможно сейчас то есть если это решение есть теперь есть какие-то интеграции но все это нужно дорабатывать напильником вот пока ничего такого к сожалению production соединить нету 

ссылки где посмотреть это смотри по истории нашего прав хаоса это тон откуда она скорее все приедет вот но там любом случае будет интеллект потом почему потому сейчас в одном репозиторий несколько разных вещей не очень тесно связанных между собой поэтому нужно будет их поносить 

вот и соответственно в нашем блоге будет информация про performance но вообще какие-то новости все спасибо

вопросам

раз-два-три спасибо спасибо леса доклад мне вопрос есть по поводу рефлюкс baby не проверяли вы вот эти знаменитые слухи про то что friends говно если китайцев ты 

но царей он был действительно очень хороший он сильно силу лучше стал то есть все эти байки про то что influx там медленные разваливать стали они все просто рвемся не знаете подняли денег подняли людей которые умеют писать баз данных и в целом текущая версия работает стабильно я бы не сказал что она прям супер супер быстро работать стабильно плюс influx baby на мой взгляд 

во первых то что не нужно делать что-то рядом потому что она работает из коробки во вторых как и не знаю как река у сада как какие-то других решений на основе базу данных но нет сдпр вы можете использовать язык запросов когда вам более знаком то есть influx кий язык запросу похож на сквере достаточно для того чтобы на нем можно было делать аналитику который на промке ель делал сложно вот а если вы там используя томский где пятна вообще настоящий стиль вот нос перфоманса но последних чисел меня к сожалению нет я знаю что по стабильности лучше стал не могу сказать 

еще вопрос графический движок только на запись получается получать если мы хотим пока графики показывать нужно графону настраивать на графит что показывают и долговременное хранилище 

да да то есть то интеграция тот не про графит mach3 а именно про интеграция которая есть сам управитель зато такой на запись соответственно он только пишется дальше либо из grafana выходите в графит либо еще факты

он теряет по моему лейбл на при этом куда пишут там есть конфигурация которая говорит как бы что с ними делаете либо с как и вставляете либо куда вставлять либо кидай да но в общем это настраивается но на самом деле там очень мало коды по большому счету если нужно там это как-то память от легко steel 

но выявит еще рассказывал недавно что они планируют перед свое решение для записей с правительством графит ну я могу добавить что чатик это церковь метрик скорее 

да telegramе да это было неожиданно

спасибо вообщем спасибо за доклад немножко не тот слайд ну суть какая вопроса там был вывод что записи все хорошо вот на сервер долговременного хранения хотелось бы спросить насколько хорошо есть у вас такая информация может быть вы работали с вашими клиентами там да да вот вот запись там линейно примеру там миллион метрик летят там пятиминутки там или 15 минут и что нам хватит ли нам там raid 6 sata дисков ленты как 

сколько вы храните ходить по времени 

примеру там год 

смотрите то есть у нас если три да я понимаю м м у нас основной интервал скрейпинг это на секунду то есть мы больше часть метрик никак 30 секундах было в докладе в главном зале у нас каждую секунду вот при этом был сэм link мы делаем там начиная помощи 14 дня и делаем там до 1 минуты и второй шаг мы пока ещё ни разу не делали то есть мы не агрегирует данные по одной минуте еще меньше вот соответственно это занимало там загрузим тестирует максимум сколько мы находились сотни гигабайт не было колебания скорости записи 

ну то есть я данных погиб сам там нет 

я говорил то есть это вот нижняя часть да это такая псевдонаучная почему потому что поэтому и спрашиваю жопу 

да да вот наш опыт пока ничего плохого и не заметил но конечно нам бы хотелось завести над нормально тестируем до конца и патологию описать результаты сделать графики оформить уже спасибо

спасибо а мне еще быть небольшой вопрос возник если мы пишем вин flux то мы тогда запрашиваем tool к дому долговременных данные за не флюкса 

кроме понимаешь что очень хочет fx зайдешь где не да но это зависит от 30 см на самом деле то есть это точно так же как и с любым другим ремонт ничего уникального для инструкций от зависимости от настройки если или trees and включен тогда будем читать

 потому что вот мы берем допустим для оперативных данных prometheus и долговременно пишем в influx мы тогда граф она тоже самое настраиваем на prometheus и prometheus может вытаскивать и то что оперативно это что записал винкс так провести то и другое то но и он будет попробовали вытаскивать до править уже выходить в includes вытаскивать данному протоколу и рисовать 

да и при этом в текущей релизной версии не будет делать дедупликации у вас будет проблема которые я вот сайтом