

**ТОП ошибок в инфраструктуре, мешающих высоким нагрузкам ⁄ Андрей Половов (Флант)**

Здравствуйте, друзья! Меня зовут Андрей. И я работаю в компании Флант в качестве руководителя и архитектора проектов. В зале сидит коллега, который помогал мне делать этот доклад. Его зовут Андрей Колаштов. И в случае чего, он мне посодействует. 

Флант

Наша компания занимается технической поддержкой и девопсом линуксовых проектов. И обычно это выглядит следующим образом. Мы берем на обслуживание некий проект. Доводим его до ума. И продолжаем обслуживать, но теперь уже с круглосуточными дежурными и с гарантией по SLA.

Наши клиенты

Среди наших клиентов немало проектов, которые можно назвать высоконагруженными. Это Первый канал, Forbes.ru, Лепра и Dirty, Ситимобил.

О чем доклад?

На этапе доведения до ума мы обнаружили, что многие ошибки или кейсы кочуют из проекта в проект, а иногда имеют общие корни. Мы эти кейсы решили собрать, систематизировать и поделиться с вами. В течение доклада мы затронем кейсы, которые связаны с базами, с кодом, с архитектурой, с сетью и не обойдется без человеческого фактора. 

Многие проблемы покажутся вам примитивными и очевидными. И вы будете правы, но несмотря на это, мы продолжаем с ними сталкиваться из проекта в проект. И поэтому есть смысл о них говорить.

1. ​	Проблемы с базами

Начнем мы наш обзор с проблем, которые связаны с базой. И начнем с приема, которые игнорируют очень многие программисты. Речь идет о транзакциях. 

Проблемы с базами / Транзакции

Я думаю, вы все знаете, что это такое. И я же их раскрою с точки зрения производительности. Предположим, у нас есть некий сайт, который платит авторам деньги за просмотры их статей. И нам для того чтобы показать одну страничку, потребуется выполнить 4 запроса в некую базу данных.

Что за запросы? Это текст. Обновляем счетчик запросов. Начисляем автору денег. А потом эти же деньги списываем из бюджета проекта. 

И в данном случае мы получим, если мы эти запросы выполним напрямую в базу без транзакций, 4 абстрактные дисковые операции. В то же время, если мы завернем эти 4 запроса в одну транзакцию, то все изменения от всех апдейтов прилетят на диск только в том случае, если мы выполним коммит. И таким образом, вместо 4-х абстрактных операций, мы получим 2 дисковые операции. И мы заметно сократим нагрузку на систему.

Особенный серьезный прирост производительности вы заметите на операциях загрузки больших объемов данных. Например, если у вас есть интернет-магазин, вам наверняка приходится парсить прайс-листы поставщиков и заливать эти данные в свою базу. И если вы все свои запросы, все свои инсерты и апдейты делаете по одиночке, то наверняка ваша база справляется, но реализует эти задачи достаточно долго. Но если вы разобьете свои запросы на пачки по тысячу штук и завернете их в транзакцию, то дело пойдет гораздо быстрее, и база вам за это скажет спасибо. 

Особенно часто, исходя из нашей практики, игнорируют этот прием программисты на голом php. Дело в том, что в MySQL из коробки включен автокоммит. И все запросы в данном случае прозрачны для пользователя и заворачиваются в отдельные транзакции. И программист об этом не думает, и лепит запросы так, как ему удобно. 

Если бы программист пользовался фреймворком, то он бы незаметно для себя этой проблемы избежал бы, потому что многие фреймворки все запросы, которые генерирует программист, как правило, заворачивают в отдельные большие транзакции. И данная проблема для таких проектов неактуальна. 

Как быть, если под вашей ответственностью оказалась база данных, а вы при этом админ, которая генерирует большую нагрузку на диск и при этом не так уж много запросов обрабатывает?

Алгоритм тут достаточно простой. Вам потребуется вытащить из базы лог запросов. В случае MySQL вы можете посмотреть в binlog или в general.log. И если вы увидите, что количество апдейтов примерно равно количеству коммитов, то, скорее всего, где-то что-то можно оптимизировать. 

Если вы админ и в вашем хозяйстве вдруг оказалась база данных, которая вдруг ни с того ни сего стала медленно выполнять, казалось бы, простые запросы, даже без join, то для вас алгоритм тоже достаточно простой. Вам потребуется выяснить жирные запросы. В случае MySQL вам поможет slow_log, либо какой-нибудь профайлер. А если у вас PostgreSQL, да еще и настроенный okmeter, то вам здорово повезло – у вас есть замечательная табличка, где все эти запросы отранжированы. Далее вы берете вычисленный жирный запрос. Скармливаете его explain вашей базы данных и добавляете недостающий индекс, о котором вам explain скажет.

Проблемы с базами / Индексы

Следующий кейс часто игнорируют многие программисты, особенно на этапах, когда проект молодой. Дело в том, что если проект маленький, то и база данных у него, скорее всего, маленькая и с легкостью влезает в оперативку. В таком случае любые запросы выполняются достаточно быстро, несмотря на то, что не настроена никакая индексация. Связано это с тем, что в оперативке перебирать всякие таблички не так уж и накладно. 

Но как только база подрастает, то в этом случае таблички перестают влезать в оперативку. И базе приходится все чаще за ними ходить на диск. И выгружать, соответственно, полностью, потому что индексация не настроена. И из-за этого диск начинает проседать, а вместе с ним проседают ваши запросы. 

Избежать всего этого можно было бы, если программист уже на этапе создания таблички хорошенько продумал индексы, которые могут пригодиться. Но я понимаю, что это не всегда возможно. И поэтому правильным решением будет держать эти индексы в актуальном состоянии. Т. е. если вы добавляете в свой проект некий запрос, то актуализируйте индекс, который у вас есть и все у вас будет хорошо. 

Проблема с базами / Жадные запросы

Следующий кейс встречается достаточно редко. Но если встречается, то выглядит он следующим образом. Например, у нас проект на обслуживании, у которого между базой и приложением перманентно летит по 200 мегабит трафик. В то время как конечный пользователь получает всего 5 мегабит. Куда же делись все эти данные, которые база отправила в сторону приложения?

Дело в том, что программисты поленились и все запросы в проекте сделали через звездочку. И, в принципе, эта схема рабочая и не такая страшная. Но в данном случае они рискуют тем, что рано или поздно они просто упрутся в канал, что, кстати, однажды с этим проектом и произошло. И плюс в этом случае запросы будут выполняться несколько медленней за счет того, что придется по сети гонять лишние данные.

Проблемы с базами / Итоги

Немножко подытожу. Рассмотрели два кейса, мораль которых такова, что делайте свои запросы более однозначно, чтобы базе не приходилось слать лишние данные. И держите ваши индексы в актуальном состоянии, когда вы добавляете новый запрос в свой проект. А также транзакции вам помогут в том случае, если у вас нет каких-то особых требований к консестивности хранения данных, то транзакции вам, скорее всего, помогут, с точки зрения производительности.

1. ​	Проблемы с кодом

В следующем разделе мы собрали пару кейсов, которые связаны с кодом. И так как мы в первую очередь все-таки админы, а не программисты, то кейсы подобрали более системные. 

Проблемы с кодом / HTTP-api

И начнем мы с нашего любимого, связанного с внешними запросами. Он актуален тогда, когда перед программистом встает задача обратиться к какой-то внешней айпишке. Например, он хочет где-нибудь в уголке разместить последнюю новость с какого-нибудь стороннего сайта. Он добавляет в код нечто подобное и радуется. У него все хорошо. Но только до тех пор, пока этот внешний сайт не начнет тормозить. И вместе с ним начнут тормозить и ваши странички. А в конечном итоге с очень большой долей вероятностью ваш сайт просто ляжет. 

Почему так происходит? Дело в том, что любой веб-сервер (мы для примера возьмем apache) для обработки каждого отдельного запроса выделяет воркера. Т. е. выделяет отдельный процесс для обработки конкретно этого запроса. И в нашем случае эти воркеры будут заниматься тем, что будут висеть и ожидать ответа от стороннего сайта. И, соответственно, будут висеть. А запросы тем временем будут все прилетать и прилетать, и apache будет вынужден плодить и плодить эти воркеры. А бесконечно он этого делать не может, потому что у любого веб-сервера есть лимит. В случае apache – это MaxClients.

И в конечном итоге, когда воркеры кончаются, то тот перестает принимать соединения и ваш сайт упал. Фишка этого кейса в том, что его не так-то и просто продиагностировать. Т. е. когда у вас упал сайт, вы заходите на сервер и видите, что спрос особо не нагружен, оперативки полно, база данных выполняет ваши запросы, а сайт все равно не работает. 

Тут вам в диагностике поможет профайлер. Например, в случае newrelic есть замечательная вкладочка web external, в которой все внешние запросы отражены и отражены результаты их выполнения. 

Если у вас нет возможности поставить профайлер, то хотя бы посмотрите в netstat и, возможно, вы что-нибудь обнаружите. 

Как же правильно поступать с этими запросами? Обязательно с этими запросами что-то делать нужно с особой осторожностью. 

Если вам требуется забрать с какой-нибудь сторонней айпишки какие-то данные, то обязательно кэшируйте ответы, которые она генерирует. 

Если вам данные нужно отправлять через айпишку, например, вы хотите отправить смс-ку или почтовое сообщение, то используйте какой-нибудь менеджер очередей. 

Если совсем приперло, и вы уже столкнулись с этой проблемой, то хотя бы поставьте тайм-аут в 1 секундочку. И в этом случае критичность будет снята. 

Проблемы с кодом / cron

Следующий кейс актуален тогда, когда перед программистом встает задача реализовать какую-нибудь фоновую процедуру. И наша практика говорит о том, что проще всего сделать это программисту на движке сайта. 

Почему? Потому что он так привык. У него под рукой все необходимые объекты уже инициализированы, уже есть все настройки баз данных. Остается только написать процедуру, спрятать ее в какой-то секретный URL. Выключить лимитное выполнение, php-ное, например. И все это дело уложить в cron.

Но у этого метода есть подводные камни. Дело в том, что фоновая процедура – это достаточно ресурсоемкая задача, как правило. И этой задачей вы заставляете пошевелиться apache, чтобы тот выделил лишний воркер. 

И если кроновых процедур таких у вас будет достаточно много, то у вас перманентно в памяти будут висеть какие-то воркеры, которые будут заниматься тем, что будут рендерить ваши фоновые процедуры. 

Но самое страшное произойдет в тот момент, когда какая-нибудь из этих процедур подвиснет из-за ошибки программиста. И если в этом случае cron будет продолжать тикать и вызывать все новые и новые процедуры, то apache будет все плодиться и плодиться, пока не упрется в лимит. 

Правильно поступать здесь следующим образом. Старайтесь использовать консольную версию для своего движка. Следите обязательно за временем выполнения ваших фоновых процедур. И обязательно ставьте соответствующие тайм-ауты. И также совершенно не повредит ставить блокировки на случай, если одна и та же фоновая процедура решит запуститься несколько раз. 

Проблемы с кодом / Итого

Будьте осторожны с cron-заданиями. И всегда делайте ваши внешние HTTP-запросы с осторожностью и не делайте их напрямую.

1. ​	Архитектурные проблемы

Следующий раздел посвящен тем или иным архитектурным проблемам.

Архитектурные проблемы / Одинокий apache

И начнем мы с кейса, с которым устали бороться. Дело в том, что многие админы и программисты любят организовывать сайт таким образом, чтобы его веб-сервер висел 80-ым портом в интернет и обслуживал запросы пользователей напрямую. 

Побочные эффекты здесь вполне очевидны. Apache – это штука тяжелая. И вы заставляете его заниматься не интеллектуальным трудом по рендеру страниц, а отдачей файликов с вашей файловой системы. 

Но реальная проблема наступит в тот момент, когда к вам придет клиент, у которого очень медленный интернет. И тогда он будет выгружать ваши файлики очень долго. И из-за этого воркеры будут очень долго висеть. И если таких клиентов к вам придет десяток, то apache, скорее всего, умрет.

Решение тут элементарное. Никогда не оставляйте apache одного. И ставьте перед ним nginx. Он с радостью возьмет на себя задачу по отдаче статичных файликов. И возьмет на себя медленных клиентов без проблем.

Доля веб-серверов, апрель 2017

Я вам приведу небольшую статистику, которую собрал Netcraft. Судя по ней, 46 % серверов в интернете представляются как apache. И, в принципе, можно считать, что все эти сервера находятся в группе риска по данному кейсу. 

Архитектурные проблемы / PHP-сессии

Следующий кейс я взял из нашего чек-листа по обслуживаю php-шных проектов. Дело в том, что php из коробки хранит сессии пользователей в файловой системе. И в этом случае чем больше к вам приходят пользователей, тем больше php вынуждено ворочать файликами. И, соответственно, вы рискуете тем, что ваш диск просядет. 

Но самое страшное произойдет в тот момент, когда у вас кончатся inode и сайт ваш гарантированно ляжет. 

А мы в этом случае поступаем следующим образом. Если нет особых требований по надежному хранению сессий пользователей, то мы используем либо redis, либо memcached по обстоятельствам. 

Архитектурные проблемы / stateful-код

Следующий кейс актуален в случае, если у вас есть сервер, на котором крутится бэкенд высоконагруженного приложения. И вы уже произвели все возможные манипуляции по его оптимизации, но ресурсов вам все равно не хватает. 

Какое здесь может быть логичное решение для того, чтобы снять нагрузку с такого бэкенда? Я имел в виду масштабирование. Вы покупаете еще один или несколько серверов. Копируете на них приложение. И балансируете между ними нагрузку. Таким образом вы не только снизите среднюю нагрузку, но и получите некую отказоустойчивость. 

Но, скорее всего, это сделать у вас не получится просто так. Наверняка у вас есть какая-нибудь админка, через которую вы загружаете картинки. Или вы генерируете какие-то документы, например, PDF. И храните их в локальной файловой системе. И в таком случае, если вы решите скопировать приложение на другой сервер, то вам придется еще решить задачу по синхронизации файликов, которые вы нагенерировали. А это нормальная головная боль. 

Еще, не дай бог, вы связались с какой-нибудь экзотической базой данных. Например, с SQLite. В этом случае вы ее не то что отреплицировать между серверами не сможете, вы не сможете ее вынести в отдельный сервер. И, соответственно, финт с масштабированием не пройдет. 

Решение такое. Если вы проектируете приложение и чувствуете, что рано или поздно его придется масштабировать, то организуйте его таким образом, чтобы файлики хранились в S3. Речь тут идет не о конкретно о Amazon S3, как многие могли подумать, а о любом собственном сервере, который имеет протокол S3.

И не завязывайтесь ни на каких сомнительных базах данных. Это вам не раз спасет ситуацию. 

Архитектурные проблемы / HTTP-кэш

И следующий кейс – это буквально неотъемлемая часть любого нагруженного проекта. Дело в том, что самый надежный способ снять нагрузку с бэкенда – это не слать эту нагрузку на него, а закэшировать ответы, которые он сгенерировал. Потому что далеко не всегда есть смысл генерировать для каждого отдельного пользователя страничку заново, потому что они банально не меняются. Или даже если они меняются, то всегда есть возможность воспользоваться каким-нибудь Varnish.

Но сейчас о самом простом случае. За примером далеко ходить не надо. Если вы были на highload в прошлую осень, то могли заметить, что страничка с расписанием в первый день изрядно тормозила. Дело в том, что она генерировала десятки запросов, из-за которых бэкенд захлебнулся. 

И решение было очень простым. Мы взяли и закэшировали их на одну минутку. И вопрос был решен. И достаточно было закэшировать на одну секунду, на десять секунд – все равно бэкенд сказал бы нам спасибо. 

Архитектурные проблемы / Итого

Если вы проектируете приложение и чувствуете, что оно когда-нибудь будет испытывать нагрузки, то проектируйте его таким образом, чтобы в будущем вы без проблем могли эти странички закэшировать. 

И ни в коем случае не заставляйте apache обрабатывать запросы пользователей напрямую. 

Если у вас php-шный проект, то рассмотрите возможность перенести сессии в redis или в memcached.

Пишите приложения так, чтобы их без проблем можно было масштабировать. 

1. ​	Сетевые проблемы

В следующем разделе мы собрали кейсы, которые так или иначе связаны с сетью. И сеть – это достаточно штука объемная. И в ней куча нюансов. Но мы собрали кейсы, которые более-менее применимы для нагруженных проектов. 

Сетевые проблемы / persistent connect

И начнем мы с самого распространенного. Во многих проектах так сложилось, что TCP-шные сессии между разными узлами, например, между фронтендом и бэкендом, между приложением и базой, живут очень недолго и открываются на каждый внешний http-шный запрос. 

И тут есть подводные камни. И начнем с очевидного. Линуксу для того, чтобы создать новый сокет, приходится немножко пошевелить процессором. И при этом по вашей сети будут гулять лишние TCP-шные пакетики. Но это зачастую копейки. 

Настоящая проблема наступает в тот момент, когда вы заставляете на каждый новый внешний запрос приложение отрывать соединения с базой данных. И в этом случае базе приходится не только создать сокет. Ей приходится еще реализовать кучу всяких служебных процедур. Например, проверить права пользователей, выделить какое-нибудь окружение или какие-нибудь блокировки поставить. Это зависит от базы данных, но в любом случае что-то придется поделать. 

И еще одна проблема есть у коротких соединений. Связана она с тем, что если у вас в системе мрет много сокетов, то, скорее всего, она у вас переполнена сокетами в режиме TIME-WAIT. О них я расскажу попозже. 

Из всего этого реальную настоящую угрозу несут короткие соединения между базой и приложением. И если вы решите с ними бороться, то, скорее всего, вам придется лезть в логи приложения, что не всегда возможно. 

Но если у вас PostgreSQL, то вам здорово повезло. Для PostgreSQL есть специальная прокся, которая создана буквально для этой задачи. Ставите перед PostgreSQL PGBouncer и снимаете с него лишнюю нагрузку. Это хороший метод. 

Также в случае nginx в отдельных случаях имеет смысл установить с бэкендом перманентное соединение. Но будьте осторожны! Не все веб-сервера такое умеют. 

Сетевые проблемы / TIME_WAIT-сокеты

Как и обещал расскажу немножко о TIME_WAIT-сокетах. Суть в том, что Линукс устроен таким образом, что когда закрывает сокет, то он не стремится удалить его из системы бесследно, а оставляет его еще повисеть минутку в режиме TIME_WAIT.

И это несет одну небольшую угрозу. Дело в том, что Линуксу приходится на каждый входящий пакетик искать соответствие среди всех сокетов, которые у него есть в наличии. А так как среди сокетов полно мертвых душ в виде TIME_WAIT, то ему приходится перебирать этот массив несколько дольше. Но это не такая уж серьезная проблема. Да и по другим параметрам эти сокеты толком на вашу систему не влияют. 

Почему я о них говорю? Дело в том, что админы любят с ними бороться. И когда они заходят на сервак, чтобы решить какую-то очередную проблему, и видят, что их система переполнена подобными сокетами, они сразу начинают во всем винить их. И идут в интернет за советом. И первое, что они видят, это совет – включить два параметра в ядре. Речь идет о tw_reuse и tw_recycle.

Если первый параметр вам не навредит и, в принципе, можно считать его полезным, то из-за второго вы замучаетесь дебажить, почему отдельные пользователи, которые ничем не отличаются от других, не могут подключиться к вашему сайту. Причем таких будет процентов 3. И вы об этом не сразу узнаете при этом.

Проблема в том, что эти два параметра толком никак не задокументированы. И чтобы разобраться, как они работают, придется немножко попотеть. И если вам любопытно, как они работают, подходите на наш стенд, я вам обрисую. Сейчас не будем. 

Итогом правильное решение для борьбы с TIME_WAIT-сокетами будет: первое – не паниковать. И комплекс из двух еще мер. Включите все-таки tw_reuse. Он вам не повредит. И старайтесь в вашей системе свести к минимуму короткие TCP-шные соединения, т. е. старайтесь как можно больше использовать persistent connections, они полезны. 

Сетевые проблемы / Плохой канал

Следующий кейс на самом деле единичный. Но несет мораль, которая подойдет для любого более-менее серьезного проекта. Есть у нас проект на обслуживании, у которого есть такая специфика. Он состоит из двух виртуалок, которые хостились до недавнего времени в DigitalOcean, и эти виртуалки перманентно испытывали одинаковую нагрузку в течение дня, т. е. специфика такая. И как-то раз совершенно неожиданно этот проект начал тормозить. Причем ночью работает хорошо, а днем тормозит. 

Когда мы зашли в профайлер, мы увидели, что запросы к базе данных выполняются в течение дня очень долго, в то время как ночью все хорошо. И эти же самые запросы в это же самое время по версии базы данных выполняются быстро. 

Немножко поразобравшись, мы выяснили, что в DigitalOcean между виртуалками начала проседать сеть. Причем днем тормозит, а ночью все хорошо. И мы не стали разбираться, а уехали на собственный гипервизор. 

Мораль такова, что если у вас более-менее серьезный проект, то старайтесь свести к минимуму использование коммунальных инфраструктур, чтобы не нарваться на какие-то неожиданные сюрпризы. Или пристально следите за ними, чтобы опять же быть готовыми в случае чего. 

Сетевые проблемы / Итоги

Постарайтесь использовать как можно меньше коротких соединений между вашими компонентами. Не перестарайтесь в борьбе с TIME_WAIT.

1. ​	Человеческий фактор

В следующем разделе мы собрали ошибки, которые могут помешать вашему проекту. 

Человеческий фактор / Базовая настройка

И начнем мы с совершенно банальной и самой очевидной ситуацией. Почему-то многие программисты или админы уверены, что если они добавят в проект какую-то новую технологию, то настройки из коробки им обязательно хватит. 

И выясняется, что это не так, как правило, уже на этапе первых нагрузок. И решение тут тоже простое и очевидное. Если добавляете в свой проект какую-то новую технологию, то обязательно разберитесь с ней и настройте превентивно, чтобы она вас не подвела. В том же хабре полно статей для MySQL о том, как по-простому настроить ее так, чтобы она держала хорошую нагрузку. 

Человеческий фактор / Хабраэффект

Кстати, о хабре. Если у вас большой проект, то у вас наверняка есть маркетологи, которые любят дать рекламную компанию, либо разместить где-нибудь рекламную ссылку, например, на том же хабре. И, как правило, когда приходит новый поток пользователей, инфраструктура бывает к этому не готова.

А избежать всего этого можно было бы, если маркетолог предупредил команду администраторов, и те произвели какое-нибудь нагрузочное тестирование. И либо поднастроили все под новые условия, либо они отговорили маркетологов давать такую нагрузку, тем самым сохранив деньги. Это очень больной для нас кейс. 

Человеческий фактор / Пятничный выкат

А также больной для нас кейс связан с проектами, в которых есть свои команды программистов. Те любят делать себе недельные планы и выкатывать свои разработки по пятницам. И, как правило, это происходит вечером.

Они это дело выкатывают. Быстренько все проверяют. И довольные собой, убегают домой. Но тут выясняется, что программисты внесли какие-то изменения, из-за которых мы больше не держим нагрузки. И нам, админам (напоминаю, что это вечер пятницы) приходится инфраструктуру под новые условия подстраивать. И хорошо, если мы справимся.

Но возможны ситуации, когда нам понадобится помощь того самого программиста, который внес эти изменения. И мы его в трезвом уме просто не найдем. Поэтому старайтесь перенести свои выкаты с пятницы куда-нибудь. Только не в пятницу, пожалуйста!

Must have

Мы с вами закончили разборы кейсов. Сейчас я подниму вопрос о самых необходимых задачах, которые надо решить в абсолютно каждом проекте.

Must have / Наша статистика

 И я думаю, никто со мной спорить не будет, что в первую очередь – это бэкапы. Объяснять, я думаю, тут не надо. 

Без мониторинга и статистики вы никогда не дадите гарантии, что с вашим проектом в данный момент все в порядке. И еще, если что-то пойдет не так, вы замучаетесь с ним разбираться. 

И если вы деплоетесь по ftp, то вы рискуете своим аптаймом. И тоже, я думаю, многие это понимают. 

Но, как вы думаете, много ли проектов, которые пришли к нам на обслуживание, хотя бы попытались хоть как-то решить вопрос со сбором бэкапов? Как оказалось, 40 % проектов, настолько уверены в себе, что решения о вопросах о бэкапах у них просто не стоят. 

Со статистикой и мониторингом все хуже. У нас есть все-таки проекты, которые позаботились и поставили хотя бы базовую инсталляцию Zabbix, либо настроили мониторинг в том же Яндекс.Метрике. Но таковых всего 30 %. 

И по поводу последней задачи есть небольшая завершающая история. Связана она с клиентом, который до недавних пор совершал деплой по ftp. Есть у него программист, который однажды уехал в отпуск и купил там местную сим-карту. И тут как-то вечерком он решил покодить и выкатить это все на сервак. Но в момент выката что-то произошло, и сим-ка перестала у него работать по какой-то причине. И все, что он успел, это залить файлик нулевого размера. И …, соответственно, умер. И с нашей стороны все выглядело совсем странно. Программист в отпуске. И беды ждать не от кого. И разбор этой ситуации занял серьезный объем времени. Но мы все-таки разобрались и достали скрипт из бэкапа. 

Как вы считаете, много ли таких клиентов, которые не позаботились хотя бы о Capistrano в своем проекте? Как оказалось, только 5 % наших клиентов понимают необходимость грамотного деплоя самостоятельно, а остальные не парятся. 

Итого

Мы рассмотрели с вами массу кейсов, которые, я надеюсь, найдут применение в ваших проектах и найдут применение в ваших будущих проектах. 

Всем спасибо!

Подписывайтесь на наш блог на Хабре https://habr.com/ru/company/flant/, там он активно сейчас развивается. И я думаю, вы там тоже что-нибудь подчеркнете интересное. Спасибо!

Вопросы

Я думаю, что все было настолько очевидно, что спорить со мной никто не станет, верно?

*Спасибо за доклад! Вопрос всего один будет. Вы говорите, что давайте ставить перед* *apache* *nginx**. А зачем тогда* *apache**?*

Apache – это веб-сервер, который рендерит странички, рендерит код.

*Nginx* *– это веб-сервер, который рендерит код* *php**.*

Nginx – это не совсем веб-сервер. Это реверсивный прокси-сервер. 

*Ок, он может выполнять функцию веб-сервера. А рендеринг кода будет осуществляться каким-то бэкендом, например,* *php**-fpm.*

Я понял вопрос. Под веб-сервером в рамках данного доклада я имею в виду ту штуковину, которая непосредственно занимается рендером страниц. Nginx умеет отдать файлик с файловой системы. Nginx умеет забрать страничку у веб-сервера, у php-fpm, у apache, unicorn, у вашего любимого веб-сервера и передать ее пользователю. Соответственно, в качестве веб-сервера тут выступает unicorn. В качестве реверсивного прокси выступает nginx.

*Добрый день! Спасибо за доклад! У меня вопрос. Вы упоминали о системах деплоя. Интересен технологический стек, который вы пользуетесь для автоматизации сбора бэкапов и развертывания этих бекапов в обратную сторону. И как это все происходит в ваших кейсах?*

Я правильно понял, что вопрос про то, как мы реализуем вопрос с бэкапом?

*Да.*

Замечательно. В двух словах, если говорить на пальцах, то мы автоматизируем и настраиваем bacula. И достаем файлики из bacula безо всяких изысков. В bacula у нас всегда все под рукой. 

*Т. е. и база данных там же, и различные конфигурации, и все прочее?*

И база данных. В отдельных случаях разные базы данных бэкапим по-разному. И пишем какую-то программу, которая достает бэкап из базы данных и забираем его bacula.

*Т. е. вы используете какие-то свои самописные решения, да?*

Если скрипт можно назвать самописным решением, то да. 

*Очень было интересно услышать про ошибки, которые мешают. А были ли ошибки, которые помогали неожиданно* *highload**, но это выяснялось постфактум уже? Т. е. что-то сделали и думали, что это ошибка, но это помогло выдержать нагрузку, которая пришла неожиданно?*

Например, бывали случаи, когда мы оперативки больше виртуалке давали, хотя и не надо было. Когда такие ситуации происходили, мы о них просто не знаем. Честно говоря, не припомню таких кейсов с ходу. Но вопрос интересный, я не обращал внимание.

*Хорошо. Создалось впечатление, что вы разделяете понятия «программисты» и «админы», т. е. моменты девопса – это осознанное решение или вы их не используете или это такой подход?*

Мы на Junior находимся. И кейсы соответствующие. Но под программистами я имею команду, которая относится к клиенту, которая может преподнести нам «добра». Как устроена наша инфраструктура при этом я не упоминаю. Я не вижу способа, как уместно в этом докладе сказать, что наша инфраструктура такая замечательная на девопсе. Речь не об этом сейчас. 

*Вы привели пример с выставлением кэширования на одну минуту. А используете ли вы в своих приложениях заго**л**овки* *http* *кэш-контроль? Т. е. приложение ваше знает ли о том, что надо кэшировать его данные или все отдано на откуп фронтенду в виде* *nginx**?*

Начнем с того, что приложение не наше, а приложение нашего клиента. Проект, который мы обслуживаем, мы его не развиваем. И кэш-контроль – это то, о чем надо подумать на этапе проектирования вашего приложения, если вы делаете приложение, которое будет когда-нибудь испытывать нагрузки, и вы захотите его кэшировать. Рекомендации? Тут по обстоятельствам. Универсального совета я вам не дам – когда использовать, а когда не использовать. Это отдельная история. Можем обсудить на стенде. 

*Добрый день! Почему вы не рекомендовали использовать* *NFS* *в качестве распределенного хранилища на всех трех серверах, а использовать* *S**3?*

У нас, возможно, субъективное мнение. Но мы считаем, что это небольшой костыль. NFS в данном случае – это сложно сделать достаточно отказоустойчивым, как правило. И S3, как правило, удобнее бэкапить, удобнее разворачивать. И субъективно ими удобнее пользоваться из приложения, с точки зрения программиста, т. е. сплошные плюсы. Но как временное решение NFS вполне подходит, только потом переделайте на S3. Это гораздо удобнее, с точки зрения админа. 

*Спасибо за доклад! В продолжении вопроса про бэкап такой вопрос. Вы бэкап собрали. Все хорошо. Как вы проверяете, что бэкап собрался верно, что он полный, что из него можно восстановить проект? Как часто вы эти бэкапы разворачиваете и какие среды используете для этого?*

Сразу про среды скажу. Честно говоря, толком никакие среды мы не используем, ми используем регламенты и дежурных, которые регулярно ходят по проектам и убеждаются, что все хорошо. У нас есть много людей и много рук.

*Здравствуйте! Вы рассказывали про* *TIME**_**WAIT**-сокеты. Сказали, что Линукс устроен так. Наверное, было бы более справедливо сказать, что это* *TCP* *устроен так?* *TIME**_**WAIT**-сокеты везде все-таки существуют, насколько я знаю.* 

Да, вы правы.

*И почему вы, рассказывая об этом, не упомянули про* *TIME**_**WAIT* *тайм-ауты и хотя бы* *local* *port**…**, например?*

Я пожалел мозги слушателей. И если кому-то любопытно про TIME_WAIT-сокеты послушать, подходите на стенд, я вам расскажу, как они работают. 

*Понятно. Спасибо за доклад!*


 