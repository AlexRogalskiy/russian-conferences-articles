**Предлагаю ознакомиться с расшифровкой доклада 2017 года Андрея Половова "ТОП ошибок в инфраструктуре, мешающих высоким нагрузкам"**

Наша специализация — запуск и обслуживание высоконагруженных сервисов. За все время у нас не было ни одного проекта, в котором бы при запуске или эксплуатации сервиса не проявились нагрузочные проблемы, заложенные программистами или архитекторами. Цель доклада — структурировать типовые проблемы нагруженных проектов и дать практические советы по их урегулированию.

Решив, что большинство проблем имеют общие корни, мы решили систематизировать их и поделиться с коллегами. В данном докладе представляем собственный рейтинг типовых highload-проблем и даём практические советы по их решению.

Доклад затронет следующие области:

- базы данных,
- код,
- архитектура,
- сеть,
- деплой,
- и самое неизбежное — человеческий фактор.

<oembed>https://www.youtube.com/watch?v=3fJ5ptx5g7M</oembed>

<cut />

![](https://habrastorage.org/webt/es/px/_f/espx_fojjckrgkbaee7fxfkrlee.png)

Здравствуйте, друзья! Меня зовут Андрей. И я работаю в компании Флант в качестве руководителя и архитектора проектов. В зале сидит коллега, который помогал мне делать этот доклад. Его зовут Андрей Колаштов. И в случае чего, он мне посодействует. 

![](https://habrastorage.org/webt/zw/fe/hk/zwfehk4hytzlcrhmx3iqi5abgr4.png)

Наша компания занимается технической поддержкой и DevOps Linux проектов. И обычно это выглядит следующим образом. Мы берем на обслуживание некий проект. Доводим его до ума. И продолжаем обслуживать, но теперь уже с круглосуточными дежурными и с гарантией по SLA.

![](https://habrastorage.org/webt/oo/sd/-k/oosd-kpyerhrppwws-dg1gb6iby.png)

Среди наших клиентов немало проектов, которые можно назвать высоконагруженными. Это Первый канал, Forbes.ru, Лепра и Dirty, Ситимобил.

![](https://habrastorage.org/webt/_-/5t/o6/_-5to69aohtnkcqk961potjc7fk.png)

На этапе доведения до ума мы обнаружили, что многие ошибки или кейсы кочуют из проекта в проект, а иногда имеют общие корни. Мы эти кейсы решили собрать, систематизировать и поделиться с вами. В течение доклада мы затронем кейсы, которые связаны с базами, с кодом, с архитектурой, с сетью и не обойдется без человеческого фактора. 

![](https://habrastorage.org/webt/2r/yl/8l/2ryl8lloojqsdvdiwzibknq_wpi.png)

Многие проблемы покажутся вам примитивными и очевидными. И вы будете правы, но несмотря на это, мы продолжаем с ними сталкиваться из проекта в проект. И поэтому есть смысл о них говорить.

![](https://habrastorage.org/webt/_u/ty/f8/_utyf8xcriqymbp7anfm0in8phy.png)

Начнем мы наш обзор с проблем, которые связаны с базой. И начнем с приема, которые игнорируют очень многие программисты. Речь идет о транзакциях. 

![](https://habrastorage.org/webt/_b/ua/nm/_buanmrl4nzevyp5mru6kylr7j8.png)

Я думаю, вы все знаете, что это такое. И я же их раскрою с точки зрения производительности.

![](https://habrastorage.org/webt/sk/mg/jl/skmgjlopzh7mb5zlk4wlvkzddpu.png)

Предположим, у нас есть некий сайт, который платит авторам деньги за просмотры их статей. И нам для того чтобы показать одну страничку, потребуется выполнить 4 запроса в некую базу данных.

Что за запросы? Это текст. Обновляем счетчик запросов. Начисляем автору денег. А потом эти же деньги списываем из бюджета проекта. 

И в данном случае мы получим, если мы эти запросы выполним напрямую в базу без транзакций, 4 абстрактные дисковые операции. 

![](https://habrastorage.org/webt/k7/kr/j9/k7krj9ndps1txat-4fdumwznkfs.png)

В то же время, если мы завернем эти 4 запроса в одну транзакцию, то все изменения от всех апдейтов прилетят на диск только в том случае, если мы выполним коммит. И таким образом, вместо 4-х абстрактных операций, мы получим 2 дисковые операции. И мы заметно сократим нагрузку на систему.

![](https://habrastorage.org/webt/-4/gz/wz/-4gzwzqly3j3lrsyt9qhci_mpgu.png)

Особенный серьезный прирост производительности вы заметите на операциях загрузки больших объемов данных. Например, если у вас есть интернет-магазин, вам наверняка приходится парсить прайс-листы поставщиков и заливать эти данные в свою базу. И если вы все свои запросы, все свои инсерты и апдейты делаете по одиночке, то наверняка ваша база справляется, но реализует эти задачи достаточно долго. Но если вы разобьете свои запросы на пачки по тысячу штук и завернете их в транзакцию, то дело пойдет гораздо быстрее, и база вам за это скажет спасибо.

![](https://habrastorage.org/webt/jj/ak/8p/jjak8pdv_f2yunuasxf8_ep2x6u.png)

Особенно часто, исходя из нашей практики, игнорируют этот прием программисты на голом php. Дело в том, что в MySQL из коробки включен автокоммит. И все запросы в данном случае прозрачны для пользователя и заворачиваются в отдельные транзакции. И программист об этом не думает, и лепит запросы так, как ему удобно. 

Если бы программист пользовался фреймворком, то он бы незаметно для себя этой проблемы избежал бы, потому что многие фреймворки все запросы, которые генерирует программист, как правило, заворачивают в отдельные большие транзакции. И данная проблема для таких проектов неактуальна. 

![](https://habrastorage.org/webt/dp/42/0m/dp420mi4_9pbpqrsfffly0duqcy.png)

Как быть, если под вашей ответственностью оказалась база данных, а вы при этом админ, которая генерирует большую нагрузку на диск и при этом не так уж много запросов обрабатывает?

Алгоритм тут достаточно простой. Вам потребуется вытащить из базы лог запросов. В случае MySQL вы можете посмотреть в binlog или в general.log.

![](https://habrastorage.org/webt/tc/z5/ls/tcz5lsvikphrak6zxtvqdmnvlra.png)

 **И если вы увидите, что количество апдейтов примерно равно количеству коммитов, то, скорее всего, где-то что-то можно оптимизировать.** 

![](https://habrastorage.org/webt/ev/l_/yr/evl_yrvcwfkdrnx2xqj-5adlew0.png)

Следующий кейс часто игнорируют многие программисты, особенно на этапах, когда проект молодой.

![](https://habrastorage.org/webt/0p/a9/8l/0pa98lysltia6c30dz8coemkexc.png)

Дело в том, что если проект маленький, то и база данных у него, скорее всего, маленькая и с легкостью влезает в оперативку. В таком случае любые запросы выполняются достаточно быстро, несмотря на то, что не настроена никакая индексация. Связано это с тем, что в оперативке перебирать всякие таблички не так уж и накладно. 

![](https://habrastorage.org/webt/mg/jc/fq/mgjcfqgeimwmhkw33ze7ogpge1k.png)

Но как только база подрастает, то в этом случае таблички перестают влезать в оперативку. И базе приходится все чаще за ними ходить на диск. И выгружать, соответственно, полностью, потому что индексация не настроена. И из-за этого диск начинает проседать, а вместе с ним проседают ваши запросы. 

![](https://habrastorage.org/webt/vz/lu/z1/vzluz1yyj_z6atpzmsqbf5tvbni.png)

Избежать всего этого можно было бы, если программист уже на этапе создания таблички хорошенько продумал индексы, которые могут пригодиться. Но я понимаю, что это не всегда возможно. 

![](https://habrastorage.org/webt/qm/hy/qd/qmhyqdo038mqslv_dlih-g-9hfm.png)

И поэтому правильным решением будет держать эти индексы в актуальном состоянии. Т. е. если вы добавляете в свой проект некий запрос, то актуализируйте индекс, который у вас есть и все у вас будет хорошо. 

![](https://habrastorage.org/webt/1r/lg/ne/1rlgnel23qfbvufbba2mwlafyq8.png)

Если вы админ и в вашем хозяйстве вдруг оказалась база данных, которая вдруг ни с того ни сего стала медленно выполнять, казалось бы, простые запросы, даже без join, то для вас алгоритм тоже достаточно простой. Вам потребуется выяснить жирные запросы. В случае MySQL вам поможет slow_log, либо какой-нибудь профайлер. А если у вас PostgreSQL, да еще и настроенный okmeter, то вам здорово повезло – у вас есть замечательная табличка, где все эти запросы отранжированы. 

![](https://habrastorage.org/webt/uz/dp/jt/uzdpjtovrihiwhr7xh9jwywdgdy.png)

Далее вы берете вычисленный жирный запрос. Скармливаете его explain вашей базы данных и добавляете недостающий индекс, о котором вам explain скажет.

![](https://habrastorage.org/webt/nx/fk/_v/nxfk_vzk3jjma_qos7exeqj4vla.png)

Следующий кейс встречается достаточно редко. Но если встречается, то выглядит он следующим образом. 

![](https://habrastorage.org/webt/ps/na/3t/psna3t_la2yghhwpw-nfwn2h0w8.png)

Например, у нас проект на обслуживании, у которого между базой и приложением перманентно летит по 200 мегабит трафик. В то время как конечный пользователь получает всего 5 мегабит. Куда же делись все эти данные, которые база отправила в сторону приложения?

![](https://habrastorage.org/webt/_z/ns/io/_znsio_76suwcam9drdf71edpmg.png)

Дело в том, что программисты поленились и все запросы в проекте сделали через звездочку. И, в принципе, эта схема рабочая и не такая страшная. Но в данном случае они рискуют тем, что рано или поздно они просто упрутся в канал, что, кстати, однажды с этим проектом и произошло. И плюс в этом случае запросы будут выполняться несколько медленней за счет того, что придется по сети гонять лишние данные.

![](https://habrastorage.org/webt/xe/vn/n8/xevnn87lixvwlqu_61kh5nyinpc.png)

Немножко подытожу. Рассмотрели два кейса, мораль которых такова, что делайте свои запросы более однозначно, чтобы базе не приходилось слать лишние данные. И держите ваши индексы в актуальном состоянии, когда вы добавляете новый запрос в свой проект. А также транзакции вам помогут в том случае, если у вас нет каких-то особых требований к консестивности хранения данных, то транзакции вам, скорее всего, помогут, с точки зрения производительности.

![](https://habrastorage.org/webt/g-/ot/dl/g-otdlsntoopqxvehc6o57lkzb4.png)

В следующем разделе мы собрали пару кейсов, которые связаны с кодом. И так как мы в первую очередь все-таки админы, а не программисты, то кейсы подобрали более системные. 

![](https://habrastorage.org/webt/dj/hg/zs/djhgzssmpntswjipsuqrtzjo6c4.png)

И начнем мы с нашего любимого, связанного с внешними запросами. 

![](https://habrastorage.org/webt/y6/vi/dr/y6vidrojgxuxwkvf5xjg7rxmhwu.png)

Он актуален тогда, когда перед программистом встает задача обратиться к какой-то внешней айпишке. Например, он хочет где-нибудь в уголке разместить последнюю новость с какого-нибудь стороннего сайта. Он добавляет в код нечто подобное и радуется. У него все хорошо. Но только до тех пор, пока этот внешний сайт не начнет тормозить. И вместе с ним начнут тормозить и ваши странички. А в конечном итоге с очень большой долей вероятностью ваш сайт просто ляжет. 

![](https://habrastorage.org/webt/ek/1q/62/ek1q62satw2l52err3oczuqnbas.png)

Почему так происходит? Дело в том, что любой веб-сервер (мы для примера возьмем apache (но не nginx)) для обработки каждого отдельного запроса выделяет воркера. Т. е. выделяет отдельный процесс для обработки конкретно этого запроса. 

![](https://habrastorage.org/webt/qw/ep/s5/qweps5brpn4t7x-0vkty7lgwdc0.png)

И в нашем случае эти воркеры будут заниматься тем, что будут висеть и ожидать ответа от стороннего сайта. И, соответственно, будут висеть. А запросы тем временем будут все прилетать и прилетать, и apache будет вынужден плодить и плодить эти воркеры. 

![](https://habrastorage.org/webt/ms/6k/3b/ms6k3biqsbutzhnd2a9xfmmedvc.png)

А бесконечно он этого делать не может, потому что у любого веб-сервера есть лимит. В случае apache – это MaxClients.

![](https://habrastorage.org/webt/ov/da/ug/ovdaugnp4mlgo7dkfb568mgifbk.png)

И в конечном итоге, когда воркеры кончаются, то тот перестает принимать соединения и ваш сайт упал. 

![](https://habrastorage.org/webt/qa/o_/ha/qao_ha6cl1tdg3opdgm8wstao-i.png)

Фишка этого кейса в том, что его не так-то и просто продиагностировать. Т. е. когда у вас упал сайт, вы заходите на сервер и видите, что спрос особо не нагружен, оперативки полно, база данных выполняет ваши запросы, а сайт все равно не работает. 

Тут вам в диагностике поможет профайлер. Например, в случае newrelic есть замечательная вкладочка web external, в которой все внешние запросы отражены и отражены результаты их выполнения. 

Если у вас нет возможности поставить профайлер, то хотя бы посмотрите в netstat и, возможно, вы что-нибудь обнаружите. 

![](https://habrastorage.org/webt/rj/pu/ps/rjpupss0za4ukipe_n46yepdv30.png)

Как же правильно поступать с этими запросами? Обязательно с этими запросами что-то делать нужно с особой осторожностью.

![](https://habrastorage.org/webt/pu/ak/do/puakdogdzirzitpbyrr1yqbbikm.png)

Если вам требуется забрать с какой-нибудь сторонней айпишки какие-то данные, то обязательно кэшируйте ответы, которые она генерирует. 

![](https://habrastorage.org/webt/4v/qe/jp/4vqejpuaqagklp_rluq7kcmts5i.png)

Если вам данные нужно отправлять через айпишку, например, вы хотите отправить смс-ку или почтовое сообщение, то используйте какой-нибудь менеджер очередей. 

![](https://habrastorage.org/webt/ft/bq/oo/ftbqoonw0wsqtdslpmncfq_7-b4.png)

Если совсем приперло, и вы уже столкнулись с этой проблемой, то хотя бы поставьте тайм-аут в 1 секунду. И в этом случае критичность будет снята. 

![](https://habrastorage.org/webt/ku/ng/x1/kungx1pwqg7y4j_6fnslewymf00.png)

Следующий кейс актуален тогда, когда перед программистом встает задача реализовать какую-нибудь фоновую процедуру. 

![](https://habrastorage.org/webt/ny/fb/bx/nyfbbxggodg_vg3xg6vlxtcjf_i.png)

И наша практика говорит о том, что проще всего сделать это программисту на движке сайта. Почему? Потому что он так привык. У него под рукой все необходимые объекты уже инициализированы, уже есть все настройки баз данных. Остается только написать процедуру, спрятать ее в какой-то секретный URL. Выключить лимитное выполнение, php-ное, например. И все это дело уложить в cron.

![](https://habrastorage.org/webt/uv/j8/gx/uvj8gxsej9cdmsxucmtqjgyqwgk.png)

Но у этого метода есть подводные камни. Дело в том, что фоновая процедура – это достаточно ресурсоемкая задача, как правило. И этой задачей вы заставляете пошевелиться apache, чтобы тот выделил лишний воркер. 

И если кроновых процедур таких у вас будет достаточно много, то у вас перманентно в памяти будут висеть какие-то воркеры, которые будут заниматься тем, что будут рендерить ваши фоновые процедуры. 

Но самое страшное произойдет в тот момент, когда какая-нибудь из этих процедур подвиснет из-за ошибки программиста. И если в этом случае cron будет продолжать тикать и вызывать все новые и новые процедуры, то apache будет все плодиться и плодиться, пока не упрется в лимит. 

![](https://habrastorage.org/webt/_4/_z/od/_4_zodmcl7lgs1z5gl2vmgo2lsm.png)

Правильно поступать здесь следующим образом. Старайтесь использовать консольную версию для своего движка. Следите обязательно за временем выполнения ваших фоновых процедур. И обязательно ставьте соответствующие тайм-ауты. И также совершенно не повредит ставить блокировки на случай, если одна и та же фоновая процедура решит запуститься несколько раз. 

![](https://habrastorage.org/webt/t9/jo/ly/t9jolyrb-q9b9c8o9ngnmkxit3m.png)

Будьте осторожны с cron-заданиями. И всегда делайте ваши внешние HTTP-запросы с осторожностью и не делайте их напрямую.

![](https://habrastorage.org/webt/1-/m_/ny/1-m_nyhfkalkxn6u7wlgzmo2vr0.png)

Следующий раздел посвящен тем или иным архитектурным проблемам.

![](https://habrastorage.org/webt/m9/rk/da/m9rkdactnrel4vycmlyhpb90p3s.png)

И начнем мы с кейса, с которым устали бороться. Дело в том, что многие админы и программисты любят организовывать сайт таким образом, чтобы его веб-сервер висел 80-ым портом в интернет и обслуживал запросы пользователей напрямую. 

![](https://habrastorage.org/webt/aq/8k/xi/aq8kxifs15r0lj2lwgbttjh5oec.png)

Побочные эффекты здесь вполне очевидны. Apache – это штука тяжелая. И вы заставляете его заниматься не интеллектуальным трудом по рендеру страниц, а отдачей файликов с вашей файловой системы. 

Но реальная проблема наступит в тот момент, когда к вам придет клиент, у которого очень медленный интернет. И тогда он будет выгружать ваши файлы очень долго. И из-за этого воркеры будут очень долго висеть. И если таких клиентов к вам придет десяток, то apache, скорее всего, умрет.

![](https://habrastorage.org/webt/ac/eo/nv/aceonv9ynupkten-47ixds17utg.png)

Решение тут элементарное. Никогда не оставляйте apache одного. И ставьте перед ним nginx. Он с радостью возьмет на себя задачу по отдаче статичных файликов. И возьмет на себя медленных клиентов без проблем.

![](https://habrastorage.org/webt/o_/8c/z-/o_8cz-cxcpp5_zw_ggihz_g-0g8.png)

Я вам приведу небольшую статистику, которую собрал Netcraft. Судя по ней, 46 % серверов в интернете представляются как apache. И, в принципе, можно считать, что все эти сервера находятся в группе риска по данному кейсу. 

![](https://habrastorage.org/webt/tw/de/ni/twdenipvjvh4bmbgcft7gnveldy.png)

Следующий кейс я взял из нашего чек-листа по обслуживаю php-шных проектов. 

![](https://habrastorage.org/webt/m6/vl/xe/m6vlxem5o8ukdw8hpzktwz5etl0.png)

Дело в том, что php из коробки хранит сессии пользователей в файловой системе. И в этом случае чем больше к вам приходят пользователей, тем больше php вынуждено ворочать файликами. И, соответственно, вы рискуете тем, что ваш диск просядет. 

Но самое страшное произойдет в тот момент, когда у вас кончатся inode и сайт ваш гарантированно ляжет. 

![](https://habrastorage.org/webt/jm/vu/em/jmvuemwbbz-ra7tbvanpmff7rvm.png)

А мы в этом случае поступаем следующим образом. Если нет особых требований по надежному хранению сессий пользователей, то мы используем либо redis, либо memcached по обстоятельствам. 

![](https://habrastorage.org/webt/vt/k5/j-/vtk5j-xdyyam6jmbgytpdhd2dbk.png)

Следующий кейс актуален в случае, если у вас есть сервер, на котором крутится бэкенд высоконагруженного приложения. 

![](https://habrastorage.org/webt/sv/mq/wh/svmqwhdn-o9wf85oh1uvt0eojza.png)

И вы уже произвели все возможные манипуляции по его оптимизации, но ресурсов вам все равно не хватает. 

Какое здесь может быть логичное решение для того, чтобы снять нагрузку с такого бэкенда? 

![](https://habrastorage.org/webt/sm/wi/i1/smwii1k1qrm-okhvgnlgecz2bpg.png)

Я имел в виду масштабирование. Вы покупаете еще один или несколько серверов. Копируете на них приложение. И балансируете между ними нагрузку. Таким образом вы не только снизите среднюю нагрузку, но и получите некую отказоустойчивость. 

![](https://habrastorage.org/webt/np/tg/bu/nptgbunuieay7ubvt17_9d9yaim.png)

Но, скорее всего, это сделать у вас не получится просто так. Наверняка у вас есть какая-нибудь админка, через которую вы загружаете картинки. Или вы генерируете какие-то документы, например, PDF. И храните их в локальной файловой системе. И в таком случае, если вы решите скопировать приложение на другой сервер, то вам придется еще решить задачу по синхронизации файликов, которые вы нагенерировали. А это нормальная головная боль. 

Еще, не дай бог, вы связались с какой-нибудь экзотической базой данных. Например, с SQLite. В этом случае вы ее не то что отреплицировать между серверами не сможете, вы не сможете ее вынести в отдельный сервер. И, соответственно, финт с масштабированием не пройдет. 

![](https://habrastorage.org/webt/7i/fy/bh/7ifybhd8paxveighbl5gn-bevli.png)

Решение такое. Если вы проектируете приложение и чувствуете, что рано или поздно его придется масштабировать, то организуйте его таким образом, чтобы файлики хранились в S3. Речь тут идет не о конкретно о Amazon S3, как многие могли подумать, а о любом собственном сервисе, который имеет протокол S3.

И не завязывайтесь ни на каких сомнительных базах данных. Это вам не раз спасет ситуацию. 

![](https://habrastorage.org/webt/_0/wt/ls/_0wtlsevnewcsp_rxqdctzhm5i8.png)

И следующий кейс – это буквально неотъемлемая часть любого нагруженного проекта. 

![](https://habrastorage.org/webt/ln/w_/nq/lnw_nqlikmb5w64cam3fvck8gy8.png)

Дело в том, что **самый надежный способ снять нагрузку с бэкенда – это не слать эту нагрузку на него, а закэшировать ответы, которые он сгенерировал.** Потому что далеко не всегда есть смысл генерировать для каждого отдельного пользователя страничку заново, потому что они банально не меняются. Или даже если они меняются, то всегда есть возможность воспользоваться каким-нибудь Varnish.

![](https://habrastorage.org/webt/k1/ev/1u/k1ev1uehvvlv9biwvbchtnrjqac.png)

Но сейчас о самом простом случае. За примером далеко ходить не надо. Если вы были на highload осенью 2016 года, то могли заметить, что страничка с расписанием в первый день изрядно тормозила. 

![](https://habrastorage.org/webt/j5/j8/sd/j5j8sdepekbwawlnq4y4ircfkzo.png)

Дело в том, что она генерировала десятки запросов, из-за которых бэкенд захлебнулся. 

![](https://habrastorage.org/webt/jf/uf/6_/jfuf6_t0gymy18cwjbts65hihxe.png)

И решение было очень простым. Мы взяли и закэшировали их на одну минутку. И вопрос был решен. И достаточно было закэшировать на одну секунду, на десять секунд – все равно бэкенд сказал бы нам спасибо. 

![](https://habrastorage.org/webt/uc/cy/nw/uccynw3-e-ryrdaqy-dbqybfmcc.png)

Если вы проектируете приложение и чувствуете, что оно когда-нибудь будет испытывать нагрузки, то проектируйте его таким образом, чтобы в будущем вы без проблем могли эти странички закэшировать. 

И ни в коем случае не заставляйте apache обрабатывать запросы пользователей напрямую. 

Если у вас php-шный проект, то рассмотрите возможность перенести сессии в redis или в memcached.

Пишите приложения так, чтобы их без проблем можно было масштабировать. 

![](https://habrastorage.org/webt/5w/4r/hs/5w4rhsuzhihcq9z4cdc0hm2j_fo.png)

В следующем разделе мы собрали кейсы, которые так или иначе связаны с сетью. И сеть – это достаточно штука объемная. И в ней куча нюансов. Но мы собрали кейсы, которые более-менее применимы для нагруженных проектов. 

![](https://habrastorage.org/webt/gm/mf/lv/gmmflvqi4lpxxjh2ktctpqmmqkw.png)

И начнем мы с самого распространенного. 

![](https://habrastorage.org/webt/_6/or/p4/_6orp4w_eqergy6fxjf3zo2tbx4.png)

Во многих проектах так сложилось, что TCP-шные сессии между разными узлами, например, между фронтендом и бэкендом, между приложением и базой, живут очень недолго и открываются на каждый внешний http запрос. 

![](https://habrastorage.org/webt/z8/vs/nt/z8vsntulcjsdspwzusz0yjtygfk.png)

И тут есть подводные камни. И начнем с очевидного. Линуксу для того, чтобы создать новый сокет, приходится немножко пошевелить процессором. И при этом по вашей сети будут гулять лишние TCP-шные пакетики. Но это зачастую копейки. 

**Настоящая проблема наступает в тот момент, когда вы заставляете на каждый новый внешний запрос приложение отрывать соединения с базой данных. И в этом случае базе приходится не только создать сокет. Ей приходится еще реализовать кучу всяких служебных процедур.** Например, проверить права пользователей, выделить какое-нибудь окружение или какие-нибудь блокировки поставить. Это зависит от базы данных, но в любом случае что-то придется поделать. 

И еще одна проблема есть у коротких соединений. Связана она с тем, что если у вас **в системе мрет много сокетов, то, скорее всего, она у вас переполнена сокетами в режиме TIME_WAIT.** О них я расскажу попозже. 

![](https://habrastorage.org/webt/u7/uj/7f/u7uj7fowowlqj0ej9xqgep6hqc0.png)

**Из всего этого реальную настоящую угрозу несут короткие соединения между базой и приложением.** И если вы решите с ними бороться, то, скорее всего, вам придется лезть в логи приложения, что не всегда возможно. 

Но если у вас PostgreSQL, то вам здорово повезло. Для PostgreSQL есть специальная прокся, которая создана буквально для этой задачи. Ставите перед PostgreSQL PgBouncer и снимаете с него лишнюю нагрузку. Это хороший метод (Дополнение: PgBouncer не поддерживает prepared statement).

![](https://habrastorage.org/webt/pg/nw/gx/pgnwgxaj2g3-rrdp82cmup3dosi.png)

Также в случае nginx в отдельных случаях имеет смысл установить с бэкендом перманентное соединение. Но будьте осторожны! Не все веб-сервера такое умеют. 

![](https://habrastorage.org/webt/gy/xi/ac/gyxiacgbz12tdgf4ud7_nefobfw.png)

Как и обещал расскажу немножко о TIME_WAIT-сокетах. Суть в том, что Linux устроен таким образом, что когда закрывает сокет, то он не стремится удалить его из системы бесследно, а оставляет его еще повисеть минутку в режиме TIME_WAIT.

![](https://habrastorage.org/webt/uc/j-/3w/ucj-3wsofv3frq7h5fqcz84yoc4.png)

И это несет одну небольшую угрозу. Дело в том, что Linux приходится на каждый входящий пакетик искать соответствие среди всех сокетов, которые у него есть в наличии. А так как среди сокетов полно мертвых душ в виде TIME_WAIT, то ему приходится перебирать этот массив несколько дольше. Но это не такая уж серьезная проблема. Да и по другим параметрам эти сокеты толком на вашу систему не влияют. 

![](https://habrastorage.org/webt/a0/h_/eb/a0h_eb3ngvyj1nkxdxpittmnozi.png)

Почему я о них говорю? Дело в том, что админы любят с ними бороться. И когда они заходят на сервак, чтобы решить какую-то очередную проблему, и видят, что их система переполнена подобными сокетами, они сразу начинают во всем винить их. И идут в интернет за советом. 

![](https://habrastorage.org/webt/r5/ew/fz/r5ewfzjevagv6su5p1egzz9xpu8.png)

И первое, что они видят, это совет – включить два параметра в ядре. Речь идет о tcp_tw_reuse и tcp_tw_recycle.

![](https://habrastorage.org/webt/kx/g9/ok/kxg9okkefxvrp6py4khkk_q_tio.png)

Если первый параметр вам не навредит и, в принципе, можно считать его полезным, то из-за второго вы замучаетесь дебажить, почему отдельные пользователи, которые ничем не отличаются от других, не могут подключиться к вашему сайту. Причем таких будет около 3%. И вы об этом не сразу узнаете при этом.

Проблема в том, что эти два параметра толком никак не задокументированы. И чтобы разобраться, как они работают, придется немножко попотеть.

![](https://habrastorage.org/webt/fg/it/k-/fgitk-gjvgycqn2crdnt6sbs8i0.png)

Итогом правильное решение для борьбы с TIME_WAIT-сокетами будет: первое – не паниковать. И комплекс из двух еще мер. Включите все-таки tcp_tw_reuse. Он вам не повредит. И старайтесь в вашей системе свести к минимуму короткие TCP-шные соединения, т. е. старайтесь как можно больше использовать persistent connections, они полезны. 

![](https://habrastorage.org/webt/on/tp/jl/ontpjlq0rszfdf7qgasy0hgkuuy.png)

Следующий кейс на самом деле единичный. Но несет мораль, которая подойдет для любого более-менее серьезного проекта. 

![](https://habrastorage.org/webt/ku/2v/cc/ku2vccw5ugp68dktshy7pwnd1ya.png)

Есть у нас проект на обслуживании, у которого есть такая специфика. Он состоит из двух виртуалок, которые хостились до недавнего времени в DigitalOcean, и эти виртуалки перманентно испытывали одинаковую нагрузку в течение дня, т. е. специфика такая. И как-то раз совершенно неожиданно этот проект начал тормозить. Причем ночью работает хорошо, а днем тормозит. 

![](https://habrastorage.org/webt/vq/ci/x0/vqcix0uxcpwqpxqoukuxkdanas0.png)

Когда мы зашли в профайлер, мы увидели, что запросы к базе данных выполняются в течение дня очень долго, в то время как ночью все хорошо. 

![](https://habrastorage.org/webt/it/qi/-i/itqi-iuom1ubzi84j-7j7iyismm.png)

И эти же самые запросы в это же самое время по версии базы данных выполняются быстро. 

![](https://habrastorage.org/webt/bi/t8/qw/bit8qwikaa7m-nybrkthw9rzl0y.png)

Немножко поразобравшись, мы выяснили, что в DigitalOcean между виртуалками начала проседать сеть. Причем днем тормозит, а ночью все хорошо. И мы не стали разбираться, а уехали на собственный гипервизор. 

Мораль такова, что если у вас более-менее серьезный проект, то старайтесь свести к минимуму использование коммунальных инфраструктур, чтобы не нарваться на какие-то неожиданные сюрпризы. Или пристально следите за ними, чтобы опять же быть готовыми в случае чего. 

![](https://habrastorage.org/webt/tz/jt/od/tzjtod2dcr-5oftuayzrhntggxo.png)

Постарайтесь использовать как можно меньше коротких соединений между вашими компонентами. Не перестарайтесь в борьбе с TIME_WAIT.

![](https://habrastorage.org/webt/vg/pg/nx/vgpgnxtema8k8uxkdcsslrfttyq.png)

В следующем разделе мы собрали ошибки, которые могут помешать вашему проекту. 

![](https://habrastorage.org/webt/gr/l0/di/grl0ditvrbsmkbysyc7u7eqyec4.png)

И начнем мы с совершенно банальной и самой очевидной ситуацией. Почему-то многие программисты или админы уверены, что если они добавят в проект какую-то новую технологию, то настройки из коробки им обязательно хватит. И выясняется, что это не так, как правило, уже на этапе первых нагрузок. 

![](https://habrastorage.org/webt/hd/gd/rq/hdgdrqhcwch8-g7r9vrbkgmbwsm.png)

И решение тут тоже простое и очевидное. Если добавляете в свой проект какую-то новую технологию, то обязательно разберитесь с ней и настройте превентивно, чтобы она вас не подвела.

![](https://habrastorage.org/webt/s0/jt/_f/s0jt_fkxgyvyucxcuxqnvr3fqoa.png)

В том же хабре полно статей для MySQL о том, как по-простому настроить ее так, чтобы она держала хорошую нагрузку. 

![](https://habrastorage.org/webt/t1/hs/u7/t1hsu7vt6s-ibko_nyfreeekwzc.png)

Кстати, о хабре. Если у вас большой проект, то у вас наверняка есть маркетологи, которые любят дать рекламную компанию, либо разместить где-нибудь рекламную ссылку, например, на том же хабре. И, как правило, когда приходит новый поток пользователей, инфраструктура бывает к этому не готова.

![](https://habrastorage.org/webt/zb/xz/lc/zbxzlc4ngrskfiez15tichg5dgw.png)

А избежать всего этого можно было бы, если маркетолог предупредил команду администраторов, и те произвели какое-нибудь нагрузочное тестирование. И либо поднастроили все под новые условия, либо они отговорили маркетологов давать такую нагрузку, тем самым сохранив деньги. Это очень больной для нас кейс. 

![](https://habrastorage.org/webt/3t/xe/ck/3txecktt00hxmafof3l3mdwnuuy.png)

А также больной для нас кейс связан с проектами, в которых есть свои команды программистов. 

![](https://habrastorage.org/webt/ig/pu/am/igpuam0steg5vmmblx9-pt7a-o4.png)

Те любят делать себе недельные планы и выкатывать свои разработки по пятницам. И, как правило, это происходит вечером.

Они это дело выкатывают. Быстренько все проверяют. И довольные собой, убегают домой. Но тут выясняется, что программисты внесли какие-то изменения, из-за которых мы больше не держим нагрузки. И нам, админам (напоминаю, что это вечер пятницы) приходится инфраструктуру под новые условия подстраивать. И хорошо, если мы справимся.

Но возможны ситуации, когда нам понадобится помощь того самого программиста, который внес эти изменения. И мы его в трезвом уме просто не найдем. Поэтому старайтесь перенести свои выкаты с пятницы куда-нибудь. Только не в пятницу, пожалуйста!

![](https://habrastorage.org/webt/-s/6h/gx/-s6hgx0vh8xdnf8kngatzw8c070.png)

Мы с вами закончили разборы кейсов. Сейчас я подниму вопрос о самых необходимых задачах, которые надо решить в абсолютно каждом проекте.

![](https://habrastorage.org/webt/od/qu/mk/odqumk0syw-_g8rhpuikdaxl3ny.png)

И я думаю, никто со мной спорить не будет, что в первую очередь – это бэкапы. Объяснять, я думаю, тут не надо.

Без мониторинга и статистики вы никогда не дадите гарантии, что с вашим проектом в данный момент все в порядке. И еще, если что-то пойдет не так, вы замучаетесь с ним разбираться. 

И если вы деплоетесь по ftp, то вы рискуете своим аптаймом. И тоже, я думаю, многие это понимают. 

![](https://habrastorage.org/webt/8_/us/eu/8_useu60zwkfkuweq0vtsatdbzg.png)

Но, как вы думаете, много ли проектов, которые пришли к нам на обслуживание, хотя бы попытались хоть как-то решить вопрос со сбором бэкапов? Как оказалось, 40 % проектов, настолько уверены в себе, что решения о вопросах о бэкапах у них просто не стоят. 

![](https://habrastorage.org/webt/iz/dd/so/izddsor5hbhvaw0msigxiujl2ou.png)

Со статистикой и мониторингом все хуже. У нас есть все-таки проекты, которые позаботились и поставили хотя бы базовую инсталляцию Zabbix, либо настроили мониторинг в том же Яндекс.Метрике. Но таковых всего 30 %. 

![](https://habrastorage.org/webt/hg/rz/yn/hgrzynitwqdhupx4rhejhu2cxi0.png)

И по поводу последней задачи есть небольшая завершающая история. Связана она с клиентом, который до недавних пор совершал деплой по ftp. Есть у него программист, который однажды уехал в отпуск и купил там местную сим-карту. И тут как-то вечерком он решил покодить и выкатить это все на сервак. Но в момент выката что-то произошло, и сим-ка перестала у него работать по какой-то причине. И все, что он успел, это залить файлик нулевого размера. И …, соответственно, умер. И с нашей стороны все выглядело совсем странно. Программист в отпуске. И беды ждать не от кого. И разбор этой ситуации занял серьезный объем времени. Но мы все-таки разобрались и достали скрипт из бэкапа. 

Как вы считаете, много ли таких клиентов, которые не позаботились хотя бы о Capistrano в своем проекте? Как оказалось, только 5 % наших клиентов понимают необходимость грамотного деплоя самостоятельно, а остальные не парятся. 

![](https://habrastorage.org/webt/qp/tk/qw/qptkqwwzegs40izsedewottighu.png)

Мы рассмотрели с вами массу кейсов, которые, я надеюсь, найдут применение в ваших проектах и найдут применение в ваших будущих проектах. 

Подписывайтесь на наш блог на Хабре https://habr.com/ru/company/flant/, там он активно сейчас развивается. И я думаю, вы там тоже что-нибудь подчеркнете интересное. Спасибо!

Вопросы:

*Вы говорите, что давайте ставить перед apache nginx. А зачем тогда apache?*

Apache – это веб-сервер, который рендерит странички, рендерит код.

*Nginx – это веб-сервер, который рендерит код php.*

Nginx – это не совсем веб-сервер. Это реверсивный прокси-сервер. 

*Ок, он может выполнять функцию веб-сервера. А рендеринг кода будет осуществляться каким-то бэкендом, например, php-fpm.*

Я понял вопрос. Под веб-сервером в рамках данного доклада я имею в виду ту штуковину, которая непосредственно занимается рендером страниц. Nginx умеет отдать файлик с файловой системы. Nginx умеет забрать страничку у веб-сервера, у php-fpm, у apache, unicorn, у вашего любимого веб-сервера и передать ее пользователю. Соответственно, в качестве веб-сервера тут выступает unicorn. В качестве реверсивного прокси выступает nginx.

*Вы упоминали о системах деплоя. Интересен технологический стек, который вы пользуетесь для автоматизации сбора бэкапов и развертывания этих бекапов в обратную сторону. И как это все происходит в ваших кейсах?*

Я правильно понял, что вопрос про то, как мы реализуем вопрос с бэкапом?

*Да.*

Замечательно. В двух словах, если говорить на пальцах, то мы автоматизируем и настраиваем bacula. И достаем файлики из bacula без всяких изысков. В bacula у нас всегда все под рукой. 

*Т. е. и база данных там же, и различные конфигурации, и все прочее?*

И база данных. В отдельных случаях разные базы данных бэкапим по-разному. И пишем какую-то программу, которая достает бэкап из базы данных и забираем его bacula.

*Т. е. вы используете какие-то свои самописные решения, да?*

Если скрипт можно назвать самописным решением, то да. 

*Очень было интересно услышать про ошибки, которые мешают. А были ли ошибки, которые помогали неожиданно highload, но это выяснялось постфактум уже? Т. е. что-то сделали и думали, что это ошибка, но это помогло выдержать нагрузку, которая пришла неожиданно?*

Например, бывали случаи, когда мы оперативки больше виртуалке давали, хотя и не надо было. Когда такие ситуации происходили, мы о них просто не знаем. Честно говоря, не припомню таких кейсов с ходу. Но вопрос интересный, я не обращал внимание.

*Хорошо. Создалось впечатление, что вы разделяете понятия «программисты» и «админы», т. е. моменты DevOps – это осознанное решение или вы их не используете или это такой подход?*

Мы на Junior находимся. И кейсы соответствующие. Но под программистами я имею команду, которая относится к клиенту, которая может преподнести нам «добра». Как устроена наша инфраструктура при этом я не упоминаю. Я не вижу способа, как уместно в этом докладе сказать, что наша инфраструктура такая замечательная на девопсе. Речь не об этом сейчас. 

*Вы привели пример с выставлением кэширования на одну минуту. А используете ли вы в своих приложениях заголовки Cache-Control? Т. е. приложение ваше знает ли о том, что надо кэшировать его данные или все отдано на откуп фронтенду в виде nginx?*

Начнем с того, что приложение не наше, а приложение нашего клиента. Проект, который мы обслуживаем, мы его не развиваем. И кэш-контроль – это то, о чем надо подумать на этапе проектирования вашего приложения, если вы делаете приложение, которое будет когда-нибудь испытывать нагрузки, и вы захотите его кэшировать. Рекомендации? Тут по обстоятельствам. Универсального совета я вам не дам – когда использовать, а когда не использовать. Это отдельная история.

*Добрый день! Почему вы не рекомендовали использовать NFS в качестве распределенного хранилища на всех трех серверах, а использовать S3?*

У нас, возможно, субъективное мнение. Но мы считаем, что это небольшой костыль. NFS в данном случае – это сложно сделать достаточно отказоустойчивым, как правило. И S3, как правило, удобнее бэкапить, удобнее разворачивать. И субъективно ими удобнее пользоваться из приложения, с точки зрения программиста, т. е. сплошные плюсы. Но как временное решение NFS вполне подходит, только потом переделайте на S3. Это гораздо удобнее, с точки зрения админа. 

*Спасибо за доклад! В продолжении вопроса про бэкап такой вопрос. Вы бэкап собрали. Все хорошо. Как вы проверяете, что бэкап собрался верно, что он полный, что из него можно восстановить проект? Как часто вы эти бэкапы разворачиваете и какие среды используете для этого?*

Сразу про среды скажу. Честно говоря, толком никакие среды мы не используем, ми используем регламенты и дежурных, которые регулярно ходят по проектам и убеждаются, что все хорошо. У нас есть много людей и много рук.

*Здравствуйте! Вы рассказывали про TIME_WAIT-сокеты. Сказали, что Линукс устроен так. Наверное, было бы более справедливо сказать, что это TCP устроен так? TIME_WAIT-сокеты везде все-таки существуют, насколько я знаю.*

Да, вы правы.

*И почему вы, рассказывая об этом, не упомянули про TIME_WAIT тайм-ауты и хотя бы local port, например?*

Я пожалел мозги слушателей.

![](https://habrastorage.org/webt/mm/7t/e2/mm7te2xhsvsmns6stpyuzl_o16g.png)

![](https://habrastorage.org/webt/an/bn/xn/anbnxnisxnx7zdf1axhwax43jru.png)