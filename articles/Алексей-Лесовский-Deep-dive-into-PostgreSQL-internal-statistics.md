**Deep dive into PostgreSQL internal statistics /** **Алексей** **Лесовский** **(PostgreSQL Consulting LLC)**

Добрый день! Меня зовут Алексей. Как Илья сказал, я буду рассказывать про статистику PostgreSQL.

О чем будет доклад

Статистика активности PostgreSQL. У PostgreSQL есть две статистики. Статистика активности, про которую будет речь. И статистика планировщика о распределении данных. Я буду рассказывать именно о статистике активности PostgreSQL, которая позволяет нам судить о производительности и как-то ее улучшать.

Расскажу, как эффективно использовать статистику для решения самых разных проблем, которые у вас возникают или могут возникнуть. 

Чего НЕ будет

Чего не будет в докладе? В докладе не будет статистики планировщика. Т. е. это очень большой пласт на отдельный доклад о том, как данные хранятся в базе, как идет распределение этих данных. 

И не будет обзоров инструментов. Т. е. я не буду сравнивать один продукт с другим. Никакой рекламы не будет. Отбросим это. 

Итоговая цель

Я хочу вам показать, что использовать статистику – это полезно. Это нужно. Использовать ее нестрашно. Нам понадобится всего лишь обычный SQL, базовые знания SQL.

И поговорим, какую статистику выбирать для решения проблем.

Черный ящик

Если мы посмотрим на PostgreSQL и в операционной системе запустим команду для просмотра процессов, то увидим черный ящик. Мы увидим какие-то процессы, которые что-то делают, и мы по названию можем примерно представить, что они там делают, чем занимаются. Но, по сути, это черный ящик, вовнутрь мы заглянуть не можем. 

Мы можем посмотреть нагрузку на процессор в том же топе, можем посмотреть утилизацию памяти какими-то системными утилитами, но заглянуть вовнутрь PostgreSQL мы не сможем. Для этого нам нужны другие инструменты. 

Как тратится время

И продолжая дальше я расскажу, куда тратится время. Если мы представим PostgreSQL в виде такой схемы, то можно будет ответить, куда тратится время. Это две вещи: это обработка клиентских запросов от приложений и фоновые задачи, которые выполняет PostgreSQL для поддержания своей работоспособности.

Если мы начнем рассматривать с правого верхнего угла, то мы можем проследить, как обрабатывается клиентские запросы. Запрос приходит от приложения. К нему открывается сессия. Запрос передается в планировщик. Планировщик строит план запроса. Отправляет его дальше на выполнение. Происходит какой-то ввод-вывод данных таблиц, индексов. Все это поднимается в shared buffers. Результаты запроса, если это updates, deletes, фиксируются в журнале транзакций в WAL. Потом значения какие-то попадают в логер, либо попадают в статистику. И результат запроса отдается уже клиенту обратно вверх по stack.

Что у нас с фоновыми задачами и с фоновыми процессами? У нас есть несколько процессов, которые обеспечивают работоспособность и поддерживают базу данных в нормальном рабочем режиме. Про эти процессы я буду говорить: это autovacuum, checkpointer, процессы, связанные с репликацией и background writer и checkpointer process. Я буду их всех затрагивать по мере доклада.

Проблемы

Какие проблемы есть со статистикой? 

- Информации много. От 9.4 предоставляет 109 метрик для просмотра всяких данных. Однако, если в базе данных хранятся много таблиц, схем, баз, то все эти метрики придется умножить на соответствующее количество таблиц, баз. Т. е. информации становится еще больше. И утонуть в ней очень легко.

- Следующая проблема – это то, что статистика представлена онлайн-счетчиками. Если мы посмотрим эту статистику, то мы увидим постоянно увеличивающиеся счетчики. И если с момента сброса статистики прошло очень много времени, мы увидим миллиардные значения. И они нам ничего не говорят.  

- Нет истории. Если у вас произошел какой-то факап, что-то у вас упало 15-30 минут назад, вы не сможете воспользоваться статистикой и посмотреть, что происходило 15-30 минут назад. Это проблема.

- Отсутствие native инструмента – это проблема. Разработчики ядра не предоставляют никакой утилиты. У них нет ничего такого. Они просто дают статистику в базе. Пользуйтесь, делайте к ней запрос, что хотите, то и делайте.  

- Native инструмента нет и это является следствием другой проблемы. Множество сторонних инструментов. Каждая компания, у которой есть более-менее прямые руки, пытается написать свою программу. И в итоге в community очень много инструментов, которыми можно пользоваться для работы со статистикой. И в одних инструментах есть одни возможности, в других инструментах нет других возможностей, либо есть какие-то новые возможности. И возникает ситуация, что нужно использовать два-три-четыре инструмента, которые друг друга перекрывают и обладают разными функциями. Это очень неприятно.  

Что из этого следует? Важно уметь брать статистику напрямую, чтобы не зависеть от программ, либо как-то самому улучшить эти программы: добавить какие-то функции, чтобы получить свою выгоду. 

И нужны базовые знания SQL. Чтобы получить какие-то данные из статистики, нужно составить запросы SQL, т. е. вам нужно знать, как составляются select, join.

Что предлагают?

 Статистика предлагает нам несколько вещей. Их можно разделить на категории.

- Первая категория – это события, происходящие в базе. Когда в базе происходит какое-то событие: запрос, обращение к таблице, автовакуум, коммиты, то это все события. Соответствующие счетчики инкрементируются. И мы можем отследить эти события.  

- Вторая категория – это свойства объектов такие, как таблицы, базы. У них есть свойства. Это размер таблиц. Мы можем отследить рост таблиц, рост индексов. Можем посмотреть изменения в динамике.  

- И третья категория – это время, затраченное на событие. Запрос – это событие. У него есть своя конкретная мера длительности. Здесь запустился, тут закончился. Мы можем это отследить. Либо время чтения блока с диска или записи. Такие вещи тоже отслеживаются.  

Источники статы

Источники статистики представлены следующим образом: 

- В шаредной памяти блок памяти, который отдан PostgreSQL для размещения там данных, там есть и счетчики, которые постоянно инкрементируются, когда происходит те или иные события, либо возникают какие-то моменты в работе базы.  

- Все эти счетчики не доступны пользователю, не доступны администратору. Это низкоуровневые вещи. Чтобы к ним обратиться PostgreSQL предоставляет функции. Мы можем выбрать select функцию и получить какую-то метрику.  

- Однако использовать эти функции не всегда удобно, поэтому функции представлены в виде представлений. Это виртуальные таблицы, которые предоставляют статистику по какой-то конкретной подсистеме, либо по какому-то набору событий в базе данных.  

- И есть встроенные представления. Вы PostgreSQL запустили и можете сразу ими пользоваться, смотреть, брать оттуда информацию. И есть contribs. Contribs есть официальные. Вы как пакет установили, подгрузили его в конфигурации, указали для него параметры, перезапустили PostgreSQL и можете пользоваться.

- И есть неофициальные contrib. Они не поставляются в стандартной поставке PostgreSQL. Их нужно либо скомпилировать, либо подсунуть в библиотеку. Варианты могут быть самые разные, в зависимости от того, что придумал разработчик этого неофициального contrib’а.  

Я вам показываю все те вьюхи и часть тех функций, которые доступны. Как мы видим, их очень много. И довольно легко запутаться, если вы столкнулись с этим в первый раз.

Однако, если мы возьмем предыдущую картинку «Как тратится время на PostgreSQL» и совместим с этим списком, то получим вот такую статистику. Каждую вьюху, либо каждую функцию мы можем использовать в тех или иных целях для получения соответствующей статистики, когда у нас работает PostgreSQL. И можем получить уже какую-то информацию о работе подсистемы. 

Картинка эта еще потом появится дальше.

Pg_stat_database

Первое, что мы рассмотрим, это pg_stat_database. Как мы видим, это вьюха. В ней очень много информации. Т. е. самая разнообразная информация. И она дает очень полезное знание, что у нас происходит в базе данных. 

Что мы можем полезное оттуда взять? Начнем c самых простых вещей. В начале презентации была короткая ссылка. Вы можете открыть эту ссылку. Там будет презентация. И можете из этой презентации копировать запросы и вставлять, и смотреть, что у вас в базе происходит. 

Cache hit ratio

Первое, что мы можем посмотреть – это процент попадания в кэш. Процент попадания в кэш – это полезная метрика. Она позволяет оценить, насколько у нас данные берутся из кэша из операционной памяти, либо они берутся с диска. 

Понятное дело, что чем большее у нас попадание в кэш, то тем лучше. Мы оценивает эту метрику как процент. И, соответственно, если у нас процентное отношение этих попаданий в кэш больше 90 %, то это хорошо. Если оно опускается ниже 90 %, значит, у нас памяти недостаточно для удержания горячей головы о данных в памяти. И чтобы эти данные как-то подтянуть PostgreSQL вынужден обращаться к диску и это замедляет работу. И нужно уже думать над увеличением памяти: либо shared buffers увеличивать, либо наращивать железную память. 

Аномалии

Что можно еще взять из этой вьюхи? Можно посмотреть там аномалии, происходящие в базе. Что здесь показано? Здесь есть commits, rollbacks, создание временных файлов, их объем, deadlocks и конфликты. 

Мы можем воспользоваться этим запросом. Это SQL довольно простой. И можем посмотреть вот эти данные у себя.

И вот сразу пороговое значение. Мы смотрим соотношение commits и rollbacks. Commits – это успешное подтверждение транзакции. Rollbacks – это откат, т. е. транзакция делала какую-то работу, напрягала базу, что-то считала, а потом произошел сбой, и результаты транзакции отбрасываются. Т. е. количество rollbacks, постоянно увеличивающихся, это плохо. И следует как-то избегать их, и править код, чтобы такого не происходило. 

Конфликты связаны с репликацией. И их тоже следует избегать. Если у вас какие-то запросы, которые выполняются на реплике и возникают конфликты, то нужно эти конфликты разбирать, смотреть, что происходит. Это обычно делается в логах. И устранять конфликтные ситуации, чтобы ошибок приложению не возвращалось. 

Deadlocks – это тоже плохая ситуация. Там, когда запросы борются за ресурсы, один запрос обратился, второй запрос обратился к одному ресурсу, и они друг друга заблокировали. Это тоже проблемная ситуация. Их нужно решать на уровне переписывания приложений. И если вы видите, что у вас deadlocks увеличиваются постоянно, нужно разбирать кейсы и смотреть в чем проблема. 

Темповые файлы (временные) – это тоже плохо. Когда postgres’овому connect’у не хватает памяти для оперативных временных данных, он создает на диске файл. И начинает все операции выполнять уже на диске. Это медленно. Это замедляет работу postgres’ового connect’а. И клиент, подключившийся к PostgreSQL получит более долгий ответ. Если эти все операции будут выполняться в памяти, он ответ получит гораздо быстрее, клиенту нужно будет меньше ждать. 

Pg_stat_bgwriter

Pg_stat_bgwriter – это представление описывает работу двух фоновых подсистем PostgreSQL: это checkpoints и фоновый писатель. 

Checkpoints

Для начала разберем checkpoints. Что такой checkpoints? Checkpoint – это сброс грязных страниц в шаредной памяти на диск. Для чего это нужно? Если бы PostgreSQL все время обращался к диску и брал оттуда данные, и записывал данные при каждом обращении, это было бы медленно. Поэтому у PostgreSQL есть большой объем памяти, так же это зависит от выставленных параметров в конфигурации. Он эту область использует для помещения туда данных. Потом как-то их меняет. И мы получаем две версии данных. Одна у нас в памяти, другая на диске. И периодически нам нужно эти данные синхронизировать. Нам нужно то, что изменено в памяти, синхронизировать на диск. Для этого нужны checkpoints.

Checkpoint проходит по shared buffers, помечает грязные страницы, что они нужны для checkpoint. Потом запускает второй проход по shared buffers. И страницы, которые помечены для checkpoint, он их уже синхронизирует. Таким образом выполняется синхронизация данных уже с диском. 

И checkpoint есть два. Один checkpoint выполняется по тайм-ауту. Это checkpoint полезный – checkpoint_timed. И есть checkpoints по принуждению – checkpoint required. Это когда у нас идет очень большая запись данных. Мы записали очень много журналов транзакций. И PostgreSQL считает, что ему нужно все это как можно быстрее синхронизировать, сделать контрольную точку и жить дальше. 

И если вы посмотрели статистику pgwriter и увидели, что у вас checkpoint required гораздо больше, чем timed, то это плохо. Почему плохо? Это значит, что PostgreSQL находится в постоянной стрессовой ситуации, когда ему нужно записывать данные. Checkpoint timed растянут по времени. У PostgreSQL есть возможность сделать паузы в работе и не напрягать дисковую подсистему. Это для PostgreSQL полезно. И запросы, которые выполняются во время checkpoint не будут испытывать стрессы от того, что дисковая подсистема занята. 

И для регулировки checkpoint есть три параметра:

- Checkpoint_segments.

- Checkpoint_timeout.

- Checkpoint_competion_target.  

Они позволяют регулировать работу checkpoint. Не буду на них задерживаться. Их влияние – это уже другая тема.

Background Writer

Следующая подсистема – это background writer. Что он делает? Он работает постоянно в бесконечном цикле. Сканирует шаредную память и странички грязные, которые он нашел, сбрасывает на диск. Т. е. он помогает checkpoint делать меньше работы. 

Для чего он еще нужен? Он обеспечивает бэкенды чистыми страницами. Когда клиентское подключение запросило новые данные, у него есть чистые страницы. Ему не надо самому ничего чистить, он берет эти страницы и пользуется. Если вы видите, что у вас параметр «maxwritten_clean» большой, это значит, что background writer не справляется со своей работой и нужно увеличивать параметры «lru_maxpages», чтобы он смог за один цикл сделать больше работы, больше очистить страничек. 

И другой очень вредный показатель – это buffers backend fsync. Бэкенды не делают fsync, потому что это медленно. Они передают fsync выше по stack checkpointer’у. У checkpointer есть своя очередь, он периодически fsync обрабатывает и файлы синхронизирует. Если очередь большая у checkpointer и заполнена, то бэкенд вынужден сам делать fsync и это замедляет работу бэкенда, т. е. клиент получит ответ позже, чем мог бы. Если вы видите, что у вас это значение больше нуля, то это уже больше и нужно оптимизировать дисковую подсистему. 

Pg_stat_replication

Тут тоже у нас много параметров. Но понадобятся нам всего лишь пункты, связанные с location. Если мы видим, что все значения равны, то это идеальный вариант и у нас реплика не отстает от мастера. Это прекрасно. 

Вот эта шестнадцатеричная позиция – это позиция в журнале транзакций. Она постоянно увеличивается, если в базе есть какая-то активность: inserts, deletes и т. д. 

Лаг репликации

Если эти вещи отличаются, значит есть какой-то лаг. Лаг – это отставание мастера от реплики, т. е. данные отличаются между серверами.

Есть три причины отставания: 

- Это дисковая подсистема не справляется с записью синхронизации файлов.  

- Это возможные ошибки сети, либо перегрузка сети, когда данные не успевают доезжать до реплики и он не может их воспроизвести.  

- И процессор. Процессор – это очень редкий случай. И я видел такое два или три раза, но такое тоже может быть.

И вот три запроса, которые нам позволяют использовать статистику. Мы можем оценить, сколько записано у нас в журнале транзакции. Есть такая функция «bg_xlog_location_diff» и можем оценить лаг репликации в байтах и секундах. Мы тоже для этого используем значение из этой вьюхи. 

С лагом, который в секундах, есть один момент. Если на мастере не происходит никакой активности, транзакция там была где-то 15 минут назад и активности никакой нет, и если мы на реплике посмотрим этот лаг, то мы увидим лаг в 15 секунд. Об этом стоит помнить. И это может вводить в ступор, когда вы посмотрели этот лаг. 

Pg_stat_all_tables

Pg_stat_all_tables – это тоже полезная вьюха. Она показывает статистику по таблицам. Когда у нас в базе есть таблицы, с ним есть какая-то активность, какие-то действия, мы можем эту информацию получить из этой вьюхи.

Sequential scans

Первое, что мы можем посмотреть, это последовательные проходы, последовательное сканирование по таблице. Само число после этих проходов еще не обязательно плохо и не показатель того, что нам нужно уже что-то там делать.

Однако есть вторая метрика – seq_tup_read. Это количество строк, возвращенных в результате последнего сканирования. Если усредненное число превышает 1 000, 10 000, 50 000, 100 000, то это уже показатель, что возможно вам нужно где-то построить индекс, чтобы обращения были по индексу, либо оптимизировать запросы, чтобы такого не было. 

Простой пример – это, допустим, offset с большим количеством и лимит стоит. Т. е. мы сканируем 100 000 строк в таблице и после этого берем 50 000 строк. Это тоже плохой кейс. И такие запросы нужно оптимизировать. И здесь вот такой простой SQL-запрос, на котором можно это посмотреть и оценить примерные цифры. 

Размеры таблиц

Размеры таблиц также можно получить с помощью этой таблицы и с помощью дополнительных функций «total_relation_size», «relation_size».

Есть метакоманды «/dt», которые можно выпустить в PSQL и посмотреть размеры. 

Однако использование функций помогает нам посмотреть размеры таблиц еще с учетом индексов, либо без учетов индексов и уже делать какие-то оценки на основе роста базы данных, т. е. как она у нас растет, с какой интенсивностью и делать уже какие-то выводы об оптимизации размеров. 

Write activity

Активность на запись. Что такое запись? Запись (я написал update) – это операция обновления в таблице. По сути, update – это две операции. Это вставка новой версии строки и пометка старой версии строки как неиспользуемая. В последствии придет автовакуум и вот эти неиспользуемые строки вычистит, пометит это место как доступное для повторного использования.

Кроме того, update – это не только обновление таблицы. Это еще обновление индексов. Если у вас на таблице много индексов, то при update все индексы, в которых участвуют поля, обновляемые в запросе, нужно будет перестроить. В этих индексах также будут мертвые строки, которые нужно будет почистить. 

И update – это тяжеловесные операции. Но их можно облегчить. Есть hot updates. Они появились в PostgreSQL версии 8.3. И что это такое? Это легковесный update, который не вызывает перестроение индексов. Т. е. мы обновили запись, но при этом обновилась только запись в страничке, а индексы по-прежнему указывают на ту же самую запись в странице. Там немного такая интересная логика работы, когда приходит вакуум, то он эти цепочки hot перестраивает и все продолжает работать без обновления индексов, и происходит все легковесно. Т. е. мы делаем легковесные обновления. 

И когда у вас n_tup_hot_upd большое, то это очень хорошо. Это значит, что легковесные updates проходят гораздо легче для таблиц и все прекрасно. 

Как увеличить объем hot обновляемых таблиц? Мы можем использовать fillfactor. Он определяет размер заполнения страницы в таблице. Когда в таблицу идут inserts, то они полностью заполняют страничку, не оставляют в ней пустого места. Потом выделяется новая страничка. Снова данные заполняются. И это поведение по умолчанию, fillfactor = 100 %.

Мы можем сделать fillfactor в 70 %. Т. е. при inserts выделилась новая страничка, но заполнилось всего лишь 70 % странички. И 30 % у нас осталось на резерв. Когда нужно будет сделать update, то он с высокой долей вероятности произойдет в той же самой страничке, и новая версия строки поместится в ту же страничку. И будет сделан hot_update. Таким образом облегчается запись на таблицах. 

Внизу приведет alter table, как можно задать fillfactor.

Autovacuum queue

Очередь автовакуума. Автовакуум – это такая подсистема, по которой статистике в PostgreSQL очень мало. Мы можем в таблицах только в pg_stat_activity увидеть, сколько у нас вакуумов длятся в данный момент. Однако понять, сколько таблиц в очереди у него с ходу очень сложно. 

Мы можем использовать вот такой упрощенный запрос. И можем посмотреть, когда должен будет сделан вакуум. Как триггерится вакуум? Вот эти мертвые строки, о которых я говорил раньше. Update произошел, новая версия строки вставилась. Появилась мертвая строка. В таблице pg_stat_user_tables есть такой параметр «n_dead_tup». Он показывает количество мертвых строк. И как только количество мертвых строк стало больше, чем определенный порог, к таблице придет вакуум. 

И как рассчитывается этот порог? Т. е. это процентное отношение от общего числа строк в таблице. Есть параметр «av_scale_factor». Он определяет процентное отношение. Допустим, 10 % + там есть базовый порог в 50 строк. И что получается? Когда у нас мертвых строк стало больше 10 % от таблицы, то мы ставим таблицу на автовауум.

Однако тут есть один момент. Базовые пороги у параметров «av_base_thresh» и «av_scale_factor» могут назначаться индивидуально. И, соответственно, порог будет не глобальный, а индивидуальный для таблицы. Поэтому чтобы рассчитать, там нужно использовать ухищрения и уловки. И если вам интересно, то вы можете посмотреть на опыт наших коллег из Avito. Они написали для …, которые учитывает эти вещи. Там портянка на два листа. Но считает он корректно и довольно эффективно позволяет оценить, где у нас вакуума много требуется для таблиц, где мало. 

Что мы можем с этим сделать? Если у нас очередь большая, автовакуум не справляется, то мы можем поднять количество воркеров вакуума, либо просто сделать вакуум агрессивнее, чтобы он триггерился раньше, обрабатывал таблицу маленькими кусочками. И тем самым очередь будет уменьшаться.

Pg_stat_all_indexes

Pg_stat_all_indexes – это статистика по индексам. Она небольшая. И мы можем по ней получить информацию по индексам сканирования. И можем определить какие индексы у нас лишние. 

Лишние индексы

Как я уже говорил, update – это не только обновление таблиц, это еще обновление индексов. Соответственно, если у нас на таблице много индексов и их нужно обновить, и если у нас есть неиспользуемые индексы, по которым нет индексовых сканирований, то они у нас висят балластом. И от них нужно избавляться. Для этого нам нужно поле «idx_scan». Мы просто смотрим количество индексовых сканирований. Если у нас небольшой промежуток времени – ноль, то это плохие индексы, нам нужно от них избавиться. 

И две ссылки есть. Это примеры запросов для того, как искать неиспользуемые индексы. 

Вторая ссылка – это довольно интересный запрос. Там очень крутая логика заложена. Рекомендую его для ознакомления. 

Что еще стоит подытожить? 

- Неиспользуемые индексы – это плохо.  

- Занимают место.  

- Замедляют операции обновления.

- Лишняя работа для вакуума.  

Если мы их спилим, то мы сделаем базе только лучше. 

Pg_stat_activity

Следующая вьюха – это pg_stat_activity. Это аналог PS, только в PostgreSQL. Если PS’ом вы смотрите процессы в операционной системе, то pg_stat_activity вам покажет бэкенды внутри PostgreSQL.

Что мы можем оттуда полезного взять?

Общая активность

Мы можем посмотреть общую активность, что происходит в базе. Можем сделать новый деплой. У нас там все взорвалось, коннекты новые не принимаются, ошибки сыплются в приложении.

Мы можем выполнить вот такой запрос и посмотреть общий процент подключения, и посмотреть, кто у нас занимает больше всего коннектов. И в данном приведенном случае мы видим, что user cron_role открыл 508 коннектов. И что-то с ним там произошло. Нужно с ним разбираться и смотреть. И вполне возможно, что это какое-то аномальное число подключений.

Долгие запросы

Если у нас нагрузка OLTP, запросы должны выполняться быстро, очень быстро и должно быть все хорошо. Однако, если возникают долгие запросы, то в краткосрочной перспективе ничего страшного нет, но в долгосрочной перспективе они вредят базе, они увеличивают bloat таблиц, когда у нас фрагментация таблиц увеличивается. И от bloat, и от вредных запросов нужно избавляться.

Обратите внимание: вот таким запросом мы можем определять долгие транзакции. Мы используем функцию «clock_timestamp()» для определения времени работы. И запросы, которые мы нашли, мы можем их запомнить, выполнить explain, посмотреть планы и как-то оптимизировать. Текущие долгие запросы мы отстреливаем и дальше живем. 

Плохие транзакции

Плохие транзакции – это транзакции в состоянии idle in transaction и idle in transaction aborted.

Что это значит? Транзакции имеют несколько состояний. И одно из этих состояний могут принимать в любой момент времени. Для определения состояний есть поле «state» в этой вьюхе. И мы используем его для определения состояния. 

И, как я уже сказал выше, эти два состояния – это плохо. Что это такое? Это когда код открыл транзакцию, сделал какие-то действия и ушел по своим делам. Транзакция осталась открытая. Она висит, они ничего не делает, она занимает коннект и потенциально еще увеличивает bloat других таблиц, потому что там есть накладные расходы на транзакционном движке. И такие транзакции тоже следует отстреливать, потому что они вредные в долгосрочной перспективе. 

Если вы видите, что их у вас в базе больше 5-10-20, то нужно уже обеспокоиться и начинать с ними что-то делать.

Здесь мы также для времени вычисления используем clock_timestamp(). Транзакции отстреливаем, приложение оптимизируем.

Блокировки

Как я уже говорил выше, блокировки – это когда две и больше транзакций борются за один или группу ресурсов. Для этого у нас есть поле «waiting» с боевым значением «try» и «false».

Try – это значит, что процесс находится в ожидании, нужно что-то делать. Когда процесс находится в ожидании, значит, клиент, который инициировал этот процесс тоже ждет. Клиент в браузере сидит и тоже ждет. 

Что делать? Если вы видите try, то значит, надо от них избавляться. Мы просто такие транзакции отстреливаем. Разработчикам пишем, что нужно как-то оптимизировать, чтобы не было гонки за ресурсами. И дальше разработчики оптимизируют приложение, чтобы такого не возникало. 

И крайний случай – это возникновение deadlocks. Две транзакции обновили два ресурса, потом обращаются к ним снова, уже к противоположным ресурсам. PostgreSQL в этом случае берет и сам отстреливает транзакцию, чтобы другая могла продолжить работу. Это тупиковая ситуация и она сама не разбирается. Поэтому PostgreSQL вынужден принимать крайние меры.

И вот два запроса, которые позволяют отслеживать блокировки. Мы используем вьюху pg_locks, которая позволяет отслеживать эти тяжеловесные locks.

И первая ссылка – это сам текст запроса. Он довольно-таки длинный.

И вторая ссылка – это статья по locks. Ее полезно почитать, она очень интересная.

Итак, что мы видим? Мы видим два запроса. Alter table – это блокирующий ресурс. Он как раз у нас ушел из транзакции и где-то занимается своими делами. И второй запрос – update. Он ждет, когда закончится alter table, чтобы продолжить свою работу. 

Вот так мы можем выяснять, кто кого залочил, держит и можем разбираться с этим дальше. 

Pg_stat_statements

Следующий модуль – это pg_stat_statements. Как я уже сказал, это модуль. Чтобы им воспользоваться нужно подгрузить его в конфигурацию, перезапустить PostgreSQL и дальше у нас появится вьюха для использования. 

Что мы можем оттуда взять? Если говорить о простых вещах, мы можем взять среднее время выполнения запроса. Это как средняя температура по больнице. Время растет, значит, у нас PostgreSQL отвечает медленно и нужно что-то делать.

Можем посмотреть самые активные пишущие транзакции в базе данных, которые меняют данные в shared buffers. Посмотреть, кто у нас там апдейтит, делитит. 

И можем просто посмотреть статистику по этим запросам.

Отчеты

Мы pg_stat_statements используем для построения отчетов. Мы раз в сутки сбрасываем статистику. Накапливаем ее. Перед сбросом статистики в следующий раз, строим отчет. Вот ссылка на отчет. Вы можете его посмотреть. Там тоже портянка на три экрана. 

Что мы делаем? Мы агрегируем … и подсчитываем общую статистику. Затем для каждого запроса мы считаем индивидуальный вклад. 

И что мы можем посмотреть? Мы можем посмотреть общее время выполнения этого запроса на фоне общей статистики. Можем посмотреть использование ресурсов процессора и ввода-вывода относительно общей картины. И уже оптимизировать эти запросы. Мы строим топ запросов по этому отчету и уже получаем пищу для размышления, что оптимизировать. 

За кадром

Что у нас осталось за кадром? Осталось несколько вьюх, которые я не стал рассматривать, потому что время ограничено. 

Есть pgstattuple – это тоже contrib. Он позволяет оценить bloat таблицы, фрагментацию таблицы. И если фрагментация большая, нужно ее убирать, использовать разные инструменты. И функция «pgstattuple» работает долго. И чем больше таблиц, тем дольше она будет работать.

Следующий contrib – это pg_buffercache. Он позволяет проводить инспекцию шаредных буферов: какие буфера у нас используются, какие нет. И просто позволяет заглянуть в shared buffers и оценить происходящее там. 

Следующий модуль – это pgfincore. Он позволяет проводить низкоуровневые операции с таблицами через системный вызов «mincore()», т. е. он позволяет загрузить таблицу в шаредные буфера, либо ее выгрузить. И позволяет помимо прочего проводить инспекцию страничного кэша операционной системы, т. е. то, насколько у нас таблица висит в page cache, в шаредных буферах и просто позволяет оценить загруженность таблицы.

Следующий модуль – pg_stat_kcache. Он также использует системный вызов. И вешает его перед выполнением запроса и после выполнения запроса. И смотрит в полученной метрике, сколько у нас запрос затратил на выполнение дискового ввода-вывода, т. е. операции с файловой системой и смотрит использование процессора. Однако модуль молодой и для своей работы он требует PostgreSQL 9.4 и pg_stat_statements, о котором я говорил ранее. 

Резюме

- Умение пользоваться статистикой – полезно. Вам не нужны всякие программы. Вы можете сами заглянуть, посмотреть, что-то сделать, выполнить.  

- Пользоваться статистикой несложно, это обычный SQL. Вы собрали запрос, составили, отправили, посмотрели.  

- Статистика помогает ответить на вопросы. Если у вас возникают вопросы, вы обращаетесь к статистике – смотрите, делаете выводы, анализируете результаты.

- И экспериментируйте. Запросов много, данных много. Всегда можно оптимизировать какой-то уже существующий запрос. Можно сделать свою версию запроса, которая подходит вам больше, чем оригинал и использовать его.  

Годные ссылки

Годные ссылки, которые встречались в статье, по материалам которой, были в докладе. 

И вот два блога. Один на английском, другой на русском. Если вам что-то хочется прочитать из моего творчества, то добро пожаловать!

И на этом все. Спасибо!


