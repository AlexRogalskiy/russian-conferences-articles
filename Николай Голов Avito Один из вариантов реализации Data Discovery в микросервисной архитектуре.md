**Здесь переводится видео в статью Николая Голова из Avito "Один из вариантов реализации Data Discovery в микросервисной архитектуре"**

Ссылка на видеодоклад https://www.youtube.com/watch?v=yYp6Nqf-SME

**Текст сделан из субтитров. Буду очень благодарен в форматировании текста, его вычитки. Для этого достаточно знать русский язык.
Присылайте свои pull request или присылайте текст на почту patsev.anton[собака]gmail.com**

Всем привет. Я Николай Голов. Расскажу вам про микросервисы, но с другой точки зрения. Авито большая компания. Мы недавно стали вторым classified на планете. Небольшая приписка: "А еще мы монолит пилим".

Я считаю себя разработчиком баз данных (далее просто база). И тут внезапно вопрос: при чем тут микросервисы? Я возглавляю в Авито Data платформу. Мы занимаемся всеми базами, которые используются в Авито: Vertica, PostgreSQL, Redis, MongoDB, Tarantool, VoltDB, самая наша любимая база SQLite. Баз много. У нас сотни сервисов, у нас сотни баз данных. 

В принципе, как должна быть построена микросервисной архитектура с точки зрения баз все неплохо знают. Вот паттерн с которого все обычно начинают. Есть общая база  между сервисами. На слайде оранжевые это сервисы и между ними общая база.

Так жить нельзя, потому что вы не можете изолировано тестировать сервис, когда между ними помимо прямой связи есть еще вот такая связь через базу.

Один сервис запросами может замедлять другой сервис. Это плохо.

С точки зрения работы с базами для микросервисной архитектуры должен применятся паттерн DataBase-per-Service - у каждого сервиса своя база. Если в базе много шардов, то база должна быть общая чтобы они синхронизировались.

Это теория, а в реальности все не так. В реальности когда мы смотрим реальную компанию. В ей используют не только микросервисы, но и монолит. Есть сервисы написанные правильно. Есть старые сервисы, которые до сих пор используют паттерн с общей базой.

Вадим Мэдисон на своей презентации показывал эту картину со связанностью. Только он не показывал без одного компонента и была равномерна сеть. В этой сети в центре есть точка, которая связана с многими точками (микросервисами). Это монолит. Он небольшой на схеме. На самом деле монолит большой. Когда мы говорим про реальную компанию, то вам нужно понимать нюансы сосуществования микросервисный возрождающиеся и уходящий, но по прежнему важной монолитической аналитической архитектуры.

С чего начинается переписывание монолита на микросервисную архитектуру на уровне планирования? Правильно доменное моделирование. Во всех пунктах написано что нужно сделать доменное моделирование. Мы в Авито несколько лет создавали микросервисы без доменного моделирования.

Вопрос: кто в компании может сделал доменное моделирование? Ответ из зала: Никто. Это тоже правильный ответ, но есть люди, которые могут попробовать. У нас в Авито так получилось архитекторы, которые занимаются микросервисами. Но доменное моделирование делал я и разработчики баз данных. Мы имеем представление о полных потоков данных. Эти знания неплохо помогают спроектировать доменную модель.

У Data discovery есть классическая интерпретация - это как работать с данными разбросанными по разным хранилищам чтобы приводить к совокупным выводам и делать какие-нибудь правильные выводы. На самом деле это все маркетинговый bullshit. Эти определения про то как все данные с микросервисов загрузить хранилище. Про это у меня были доклады несколько лет назад. Ничего подобного рассказывать не буду.

Я вам расскажу про другой процесс, который ближе к процессу перехода на микросервисы. Хочу показать способ как вы можете осознать сложность непрерывно эволюционирующей системы с точки зрения данных, с точки зрения микросервисов. В чем суть идеи. Сотни микросервисов сотни бас с этим надо жить где можно посмотреть цельную картину сотен service of base с команд людей и где вот все это можно хотя бы понять вот у вас в компании где нет не правильный ответ она может помочь но на самом деле нет потому что там нет кучи данных и она отстает от реальности то есть вот я задал вопрос и фактически этот вопрос является основной и идеи доклады что чтобы вам в этой микро сервис структуры не умереть вам нужен digital pen вам нужен вот есть ваш компания именно совокупность всего то что обеспечивает технологическую инфраструктуру и вам нужно создать адекватный образ всех этих сложностей с которому на основе которого можно быстро решать задачи и это не аналитическое хранилище то есть задачи для ну и кстати digital twin если что это один из главных хайпов это уже это круть блокчейна свеженькая тема так что запоминайте очень помогает общаться с топами значит какие задачи мы можем поставить такому digital twin у который вот электронным образами красе русской архитектуры потому что смотрите все начиналось дать задайте discovery а потом развелось с дайте discovery простейшего потом развелось очень интересно то есть вопросы в каких сервисов хранятся важные данные в каких не хранятся опять же персональные данные вот главный момент вот в каких sure as сотни баз в каких персональные данные есть а в каких нет кто знает как важные данные ходят между сервисом потому что в этом сервисе например не было персональных данных а потом он сын устал слушать и появились куда данные копируются когда стираются кто имеет работ кто может работать с какими данными кто может получить доступ напрямую через сервис кто через базу кто может шин услышать кто через другой сервис может дернуть api ручку и себе что-то скачать ну и все это приводит к вопросу как нам поднята есть вот вот эти вопросы ответом на них практически всегда является граф граф элементов граф связей и этот граф нужно как-то наполнить актуализировать и поддерживать свежим давайте я вам этот граф попытаюсь визуализировать мы этот граф решили назвать пирса стенд фабрик ну короче помнящая ткань вот давайте посмотрим компонент что в нашем что в этой помощи ткани может быть и . интерфейса давайте начнем с пользователей для простоты это не совсем стране это не совсем фронтовые страницы но это как бы короче элементы пользовательского взаимодействие с графическим интерфейсом то есть на одной странице может быть несколько у японцев к то есть услуга ритэк пользовательские ключевые действия которые он там делает дальше точки а японцы они дергают and point и ну в русские традиции это называют частью ручками ручки сервисов короче на youtube а in the end point и сервисов сервисов сотни сервисы которые как вы видите они связаны друг с другом при чем вот смотрите вот мы сейчас с вами строят строим эту ткань то есть вот у нас gui точки вот от них and pine там вот уже мы понимаем сервис и вот мы понимаем какой сервис может дернуть сервис и вызов wipe он так каким вызовом каких сервисов по цепочке может провести но и только начало база базы причем в логическом смысле то есть база это термин хранилища она немножко плохо звучит потому что под ним обычно понимается аналитическое что то это именно сторож причем рейде спас грыз тарантул неважно который в свою очередь ну вы понимаете что у одного сервиса у него обычно ну там сервиса бывают без вас не персистенции а если у сервиса база есть то обычно их несколько потому что там обычно есть какая-то база persistent найти папа сгрыз а и редис который кэш а еще часто есть тарантул который берет и на потоке что-то быстро быстро считает то есть если у сервиса базы есть то их несколько но несколько баз это еще не сам интересно потому что у базы есть развертывание на хаст и потому что одна база один редис на самом деле может жить на 16 машинах мастер кольцо и еще на 16 живут слой вы понимаете в контексте того к каким сервером нужно ограничивать доступ чтобы какие-то важные данные не утекли с одной стороны с другой стороны вот есть классные сервиса а точнее так ссоре в общем в базах что хранится от вот элементы этой discovery в базах хранятся сущности то есть причем каждая сущность ну например пользователь объявления а платеж она может храниться на самом деле в нескольких то что у вас микро сервисной архитектурой тут мгновенно получается тема что куча сущности хранятся много где и тут важно не просто знать что это все сущность принципе там есть оно важно знать что у этой сущности 1 один сторож является голым торсом то есть сущ на этой базы где сущность создается и редактируется а все остальные являются функциональными кашами тут очень важно то что если не дай бог у вас какой-то сущности 2 golden source а то здравствуйте согласование разделенных источников все будет очень плохо сущности а если мы работаем с сущностями нам нужно сущностям лежащими в базе нужно как-то к ним получать доступ если мы хотим наш сервис обогатить кают но и функциональностью и тогда у нас появляется команды которые владеют сервисами потому что сервис который не принадлежит командам это плохой сервис к с его помощью ну проблемы с ним очень тяжело решать непонятно где найти крайнего потому что вот вот смотрите тут я сейчас буду сильно коррелировать с рассказом вадима мэдисон а потому что вот он упоминал что в сервисах отражается человек который туда последним к метил это неплохо как 1 . для того чтобы для сервиса найти крайне unit но это в долгосрочной перспективе это плохо потому что человек который последний туда за к метил он может уволиться и все ищи-свищи и поэтому нужно знать команды и нужно знать людей в командах с их ролями вот и вот у нас получился такой простенький граф где на каждом слове несколько сотен элемент знаете ли вы систему где вот это все можно хранить вот то есть ну тут смотрите технически эту штуку кнопку дома то есть семьи беда в некотором смысле да давайте смотреть ключевой момент чтобы эта штука жила она должна она должна не просто один раз наполнится то есть и сытно можно всех посадить сказать ребят все вот заполняемые чтобы нам стало хорошо она должна жить потому что сервис остаются умирают стороны выделяются перемещаются по серверам команды создаются разбиваются люди ходят между командами сущности появляются новые добавляются новые сервисы убираются и так далее and point и создаются регистрируется пользовательские траектории с точки зрения гоев тоже переделываются тут самое важное не то что где-то технически хранить самое важное это чтобы сделать так чтобы каждый слой этого этой ткани он был свежим актуальным и он чтобы он актуализировалась а давайте пройдем по слоям вот я щас проиллюстрирую как делается у нас покажу как это можно сделать на уровне отдельных слоев ну давайте начнем с начала команды откуда команды но например за 1с и сорт структуры чтобы нет то есть я сейчас просто хочу иллюстрировать что для заполнения этой штуки не нужно заполнять вот весь гигантский граф не нужно понимать его все нюансы нужно что каждый слой просто правильно заполнялся и так команды все просто команда реальные у них растеклась 3 юнита тогда потом люди ну понятно дело тут всё обезличенно тут per person 1 person 2 при том что один человек он может в разных командах занимать разные роли это абсолютно нормально то что они там переходят бывает так далее соответственно яко и источник смотри тут другой ну вот у меня указанный ldap мы сейчас хотим сделать новую систему авито people и из нее убрать но это не так важно самое главное чтобы такие простейшие данные шли их чтобы хотя бы сохраняли ссылки на концы чтобы узлов игры название команд соответствовали команда вот отсюда дальше сервис и соответственно сервисы для сервиса нужно название правильно и команда который владеет причем источник это сервис discovery это вот та система которая в один мэдисон упоминал это атлас то есть общий реестр сервисов но при этом важный нюанс что как бы он общей но там сервисы есть не все и поэтому когда вы работаете с каждым таким слоем вам очень полезно почувствовать же знаете почти все такие системы от типа атласа они хранят ну информацию там знаете про 95 процентов сервисов опять процентов сервисов их там нет потому что они там старые ли как-то их сбоку создали или про не забыли и вот когда вы начинаете с этой схема работать вы сразу начинаете чувствовать чего вам не хватает так сейчас мужик к практическим более-менее мечом перейдем и так сервисы после этого у нас появляются стороны стороны вот я упоминал это обобщенные хранилище это может быть под сгрыз это может быть манга может быть memcache может быть vertica вот у нас есть разные источники у нас есть несколько источников сторож discovery то есть для нас гель base используется как бы такая половинка атласа которая как бы наши своя а для информация под грешных базах там услуг сейчас применяется парсинг yabla но они хотят сделать свой сторож discovery более правильный и так с тораджи и информация о том что сервис используют ну или владеет от разные типы это владеет сторожем так то есть смотрите вот все что я описал в принципе довольно просто это для первой итерации на самом деле это и в google что можно заполнить теперь смотрите что с этим можно делать вот давайте представим что ну это граф как работать с графом сунуть его в графу базу например в нем fuji это уже пример реальных запросов и примеры результатов этих запросов то есть вот давайте рассмотрим первый сценарий нам нужно выдавать права на базу потому что понятно что база она должна быть строго в сервисе туда должен ходить только этот сервис и только члены команды которая сервиса владеет по хорошему но мы живем в реальном мире и на самом деле довольно часто другим командам полезно сходить сервис другой в базы другого сервиса этот вопрос у кого спросить о выдаче прав вот это реально большая проблема то есть вот для к сотне басы понять кто там главный при том что тот кто ее создавал он давно уволился или перешёл на другую должность вообще не полностью с ней работает этот это простейший графа вый запрос вот пример запросы вот этот матч него fuji иск язык соответственно вы берете вот вам нужно доступ к сторожу вы берете от старриджа идите к сервису который владеет им переходите команду который владеет сервисом а дальше для сервиса вы узнаете кто у этой команды тех лиц это кстати важный вопрос потому что у нас у продуктовых команд там есть тех руководителя еще продуктовый руководитель который по базам не поможет ни как вот то есть пример запроса лица так далее довольно простой запрос но это на самом деле только половину запроса потому что доступ к 100 раджу это не атомарная операция чтобы вам получить доступ к сторожу вам нужно получить доступ к серверам где он на которой он установлен и чтобы вам все порты открыли и это может оказаться довольно интересная отдельной задачи для этого мы добавляем новый блок сущности мы добавляем такую связку как инсталляция тут вот чисто к терминологическая проблема то есть вот смотрите есть стоишь ну допустим некоторые радость база редис dressup меня примерно есть haste есть хост ну хост это может быть физическая машина может быть такси контейнер можете кубер найти быть host card виртуальные так далее и установка 100 раджа на хост мы называем это инстанциям то есть условно говоря о 1 100 раджива 1 редиса он может быть установлен на у него может быть 4 установки но 3-х 100 вот как в примере показано потому что смотрите когда вы делаете установку сто раджа для продакшен нагрузки вам разумно их поселить на отдельные физические машины чтобы там performance был повыше вот соответственно выселить их на отдельные машины для дев среды вам достаточно и сунуть в одной машины просто импорт и разной дать ну и поделить ресурсу внутри вот то есть инсталляция она такая специфическая вот и вот мы приходим уже ко второй части запроса по выдаче прав на базу когда нам то есть вот смотрите македа кинули первый запрос он ушел к руководителю руководитель подтвердил что права можно давать а дальше идет второй запрос который от стороже идет к инстанции хасты то есть рассматривает все инсталляции инсталляции для соответствующей среды точно для для prado например для про то кружения и исходя из этого выдается уже право на к на подключение к конкретным хастам конкретно портом вот это когда человек со стороны просит а теперь давайте посмотрим что происходит как эта штука может работать когда в команду нужно взять нового человека кстати выходит новый чек команду и этому новому человеку нужно дать по-хорошему доступ можно там readonly по первости но хотя бы такой к ко всем сервисам ко всем 100 раджим соответственно этой команды и вот происходит вот так реальная команда неполная выборка вот надписи видно как нибудь я думаю не очень ну давайте вам по цветам расскажу о принципе предполагал поверьте там еще дальше веселее будет то есть зеленый это руководитель команды красная . это команда в данном случае там man this action праздник все название сервисов и что воображаемые желтенькие то сервиса как видите у ряда жёлтеньких сервисов есть с тораджи и эти 100 раджа то есть синее это 100 раджа серы это хасты фиолетовый это инсталляции стороны хасты вот the city в принципе простой задачи причем довольно маленький июня то есть у нас есть куча юнитов у которых на самом деле сервисов не 727 и для них вот эта картинка она совсем не приятно выглядит вот но когда у вас есть помнящая ткань вы можете у нее кинуть получить ответы выдать просто под списком давайте продолжим нашу у меня ткани расширять значит у нас сущность под названием сущность сущность то есть это бизнес сущность бизнес сущность логическая вашего бизнеса вот например когда мы говорим про авито наша сущность это объявление дома этого это пользователи это платежи но и так далее в принципе это вот на моих докладах про хранилище данных там вы знаете что у нас эти сущности сотни но на самом деле прямо все их алагира вать не обязательно откуда можно получить список сущностей вот это вот тут как раз аналитическое хранилище поможет тогда они как раз его могут выгрузить и они могут выгрузить информацию о том откуда они эту сущность берут это хотя бы стартовой точки где сущность хранится и эту информацию уже дальнейшем можно развивать в контексте вот того что я упоминал что для каждой сущности адекватно составить список хранилищ где это сущность хранит с указанием того что сущность хранит то есть что сторож же хранит сущность как кэш или сторож хранит сущность как golden source то есть является ее первоисточником и когда вы заполняете вот такую штуку у вас появляется возможность делать вот такие вещи то есть у вас есть некоторая сущность и вам нужно понять где она живет где она живет где она отражается в каких сервисов в каких 100 раджаф инсталлированных на каких аст и потому что когда дело касается например персональных данных там же там там довольно частые нужные локи стирать и для этого очень важно понять физические машины где эти логе могут остаться а вот у меня endpoint а тут вот они так вот таким цветом нарисованы потому что and point и мы пока не пролили от от остальные вещи не более менее пролиты вот иллюстрация простенького запроса для так сказать воображаемых воображаемой сущности тут я честно говоря количество 100 раджей pm порезал чтобы было чтобы ему влезла на экран вот то есть красная эту сущность данном случае это вот объявление по он был синяя это базы где эта сущность есть ну а дальше все как в предыдущих сериях то есть серые the host и а фиолетово-это инсталляции стороны на хаст и соответственно если вы хотите для соображений комплаенс прикрыть определенную сочную сущность безопа ну ограничение без безопасности вам нужно прикрывать условно говоря все серые точки все фиолетовые точки если вы имеете ввиду реке real-time доступ вот причем это я не не все стороны вывел именно чтобы она в экран влезла вот но эта информация эта информация о состоянии на сейчас это вот такая статическая информация а когда мы говорим про микро серво на архитектуру самое важное в не это то что на меняется она меняется и данные по ней ходят и очень важно нам иметь не просто иерархическую связь между сущностями но и одноуровневые связи то есть вот пример одноуровневые связи которую мы более-менее неплохо уже прокачали используем это связка сервисов то есть связка вида сервис вызывает сервис при чем тут смотрите вот у меня есть несколько источников перечислено то вот это вот парсинг клиентов бо subscription стиву ну вот этот сервис маршрут эти модные слова я человек из другого мира но наслушался от вадима всех историй тут есть информация о вызовах прямых то есть когда сервис дергает другому api ручку но тут же должна быть информация о связи вида что сервис один кидает в шину события a service 2 на это событие подписан то есть это такая асинхронная медленная связь просто направь проходит через шину она точно также важно с точки зрения движения данных ну вот частности и по этой штуки можно еще смотреть какой сервис если что когда мы его переделываем кому нужно ходить чтобы кому нужно ходить чтобы проверить что они могут смогут работать с новой версии сущность этого прям реальный с новые версии сервиса это вот реальный пример кстати с сервисом словарей и так значит если мы рассматриваем задачу поиска точек использования сущности то очевидный запрос который нам возникает вот у нас сущность и мы знаем что она хранится в определенных старриджа и прямо классический запрос это проверка периметра то есть вот 100 раджа они при по они принадлежат некоторым сервисом и куда эта сущность может у течь из вот этого периметра она может у течь через вызовы сервисов то есть ну как бы сервис обратился получил например пользователя у тебя сохранил и она может учим течь через шины потому что как вы знаете столь же они могут вас могут быть соединены друг с другом там ребятами там landis томи всякими поджиг и всякими такими штуками вот у меня вот они сейчас стороны нарисована таким цветом потому что мы вот landis ты еще не подгрузили сейчас процессе а вот вызову уже подгрузили и вот пример реального запроса то есть смотрите тут прямо если по слоям 100 смотреть вот объявление вот две базы где он хранится вот два сервиса которые владеют этими базами а то есть вот это вот при колоночки все что после это сервисы которые работают сервисами которые владеют эту сущность то есть это потенциальные точки утечки которые возможно стоит добавить вот помимо этого что тут уже кейс более без таких рыб про практических примеров and point и источники от вадим упоминал что для построения реестра in point of сервисов можно использовать вот эти ну документацию это можно сделать в атласе можно но обычно всей лестнице это делать с другой стороны эту информацию можно получить и за мониторинг а потому что если and point важный сами разработчики вы добавить мониторинг и проще взять и посмотреть в этого сервиса какие and point и мониторить но ведь неплохо и скрытным поднимание талица значит на но он не нужны но это один вариант соответственно из мониторинга можно получить метрики привязка у метрик к сторожем к сервисам кастом ка ну ка инстанциям ну как бы шар донбасс и контентом а дальше когда у вас возникает какой-то сбой то есть сок говоря контент point вам начинает 500 в принципе очевидно кейс это взять поэтому in the point у и кинуть запрос с целью отследить корни проблемы то есть вы кида вы in the point от него переходите к сервису переходите к сервисам которые этот сервис вызывает от сервиса идете к сторожем от 100 руб же идете констанца мудха стом и дальше просто на уровне то есть а от всех них то есть найдя вот этот граф вниз вы уже можете взять и получить по ним мониторинге и посмотреть вот именно для этого in the point а вот эта цепочка вниз среди мониторингов не было ли чего-нибудь что вызвало косяк потому что вы понимаете да когда мы говорим про ролями красивую архитектуру там сбой на and panty а он может быть вызван например что там на каком-то серые на каком-то сервере на котором развернуто 1 шард база там чихнула сеть мониторинга это видно но когда у нас структура сервисов и стороны и даже вот такая то проверяйте вспоминать все мониторинге это можно застрелить снави особенно когда они еще новые постами появляются вот помимо этого сценария есть еще очень интересный сценарий что сценарий связанные с тестированием потому что смотрите на самом деле чтобы адекватно тестировать с учетом всех нюансов то есть вадим описывал кейса как можно все микро сервиса тестировать как бы в изоляции но на самом деле чтобы адекватно тестировать вам нужно сервис брать и все те кто нужен ему для работы то есть вам нужно поднять вашим тестовом окружения сервисы сервиса который он вызывает и для них все базы то есть технически вам вашим вашей ткани нужно поднять как бы связанный под графа там вам не все связи нужно этом некоторые можно подчеркнуть но можно нужно поднять под граф и уже этот под граф уже изолирована нагрузочном тесте как полностью такую замкнутую систему это прямо цель вот я сразу скажу тут бы конечно было бы круто крисом я показал как вот у нас граф сущности авито ну да вот это вот на тему все микро сервисной архитектуры был бы круто мне сейчас показать что сейчас граца граф сервисов авито и вот тут изолированные под гриф и которые можно изолированной под графа микро сервисов которые можно поднять независимо тестировать и катись продакшен типа быстро красиво но на самом деле когда вот так мы попытались сделать практически оказалось что любой микро сервис у него вот этот под граф вызовов он на входит и выходит из монолита а монолит он ходит выходит практически везде и то есть как бы это просто иллюстрация того что если микро сервису и пилить не думаю о таких вещах в итоге будет микро сервисной архитектура которая все равно без монолит не работает изолированно и тестирование не позволяет но вот подобное графова и представление позволяет вам найти кандидаты под графа изолированы то есть узнать вот это подмножество сервис оно почти готово для того чтобы работать изолирована нужно вот только парочку вызовов отсечь ну или там вот там как-нибудь из-за изолироваться и уже будет хорошо то есть это позволяет приоритизировать разбил монолита именно чтобы увеличить уменьшить связанность архитектуры вот ну и собственно на последок про то как всю эту штуку можно поддерживать и наполнять потому что я не знаю может кажется что этот все не знаю как это воспринимается снаружи на сложно не сложно просто я про это долго думал с этим долго работал нет кажется довольно простым 10 довольно просто сделать все при соблюдении маленьких правил то есть правило первое что с эта штука нельзя работать заставляя людей заполнять все зависимости понимает структур нужно чтобы каждый источник заполнял только свой маленький кусок информации то есть из одного источника при чем тут возможно доливка и из ручных инструментов воды и запер ручек заполняли сервисы из другого стороже из 3 сервера из 4 in the point и и просто а из отдельных источников заполнялись ссылки что сервис принадлежит команде что человек стал тех рядом команды это первый момент туда просто должна лица от максимально быстро просто то есть в режиме стерли пересолили информации из них отстой внешних источников дальше вот эта информация аграфия она соблюдением историчности должна загружаться в базу тут очень важная историчность потому что понимаете реальной микро cyrus на верхотуру она постоянно дышит и меняется то есть сервис ип и возникают умирают появляются новые базы появляется connection и старый connection отменяют люди ходят между командами и вам довольно часто в контексте того же расследования там какая сущность как ходит вам бывает полезно понять что эта сущность вот она сейчас живет у этого сервиса а она была жила в том сервисе туда за и за ней все ходили туда вот то есть нужно что все связи были историчной как делать граф исторических связей этого там мои дак доклады пранкер modeling отдельная история но историчности статичностью большинству людей для того чтобы работать с данными им историчность не нужно им нужен актуальный срез на сейчас и на основании исторического графу должна уже строится витрина графа на состояние сейчас которую уже можно в принципе можно с ней конечно их подгрести работать но намного проще и поднять во всякие инструменты вот он у нас например него fuji базы поднята еще один сторож которому ее можно использовать для визуализации и туда же через api и ручки можно вот эти запросы которые сказал кидать то есть вот этот запрос простейший пример вот база кто владелец базы графов и запрос ответ вот база доступа к ней какие сервера какие хасты в продакшен окружений это просто запрос в api ответа , опять же вот сервис история просто цепочка метрика от этого сервиса вот да например его стороны и его хранилищ и так далее вот то есть и чем чаще чем больше такой штукой люди используют тем больше у них появляются стимула самим следить за ее актуальностью потому что каждый каждый слой этого ткани его может наполнять отдельная команда то есть ой точки наполняют например front in der и сервисы заполняют backend разработчики стороны заполняют тебе сервера заполняют devops сущности заполняют аналитики то есть все чем-то заняты и они должны чувствовать что их заполнение она живет и приносит пользу вот ну и напоследок пара вещей то есть вот практически то что я вам все показал она уже такое живое там не везде пока 100-процентная заполненность но вот по некоторым вещам у нас шанс продолжается активная работа мы его сейчас хотим у нас сейчас есть информация уже залитая а вызовы сервисом сервисов мы хотим добавить еще информацию о потоке данных через жену вот шотландии стрижек и прочие этом те самые ребята и прочее и последняя вещь которую мы пытаемся добавить час это вот самая горячая вещь это графы пользовательских траекторий то есть связи о и точками на основании того как там пользователя между ними ходят то есть у нас уже сейчас сделано это на ул его не 1 уровня клиентского логирования сейчас вот мы переходим к сшивки этой информацией и пробросов ткань чтобы можно было пользовательский опыт уже оттранслировать в ой точки оттуда в in the point и оттуда в сервисы просто понять но условно говоря чем у нас пользователи честь чаще всего пользуются и почему вот этот маленький сервис который вроде как не очень нагружена не очень важный на самом деле так эффекте с пользовательский опыт так сказать дисклеймер потому что этот сервис вызов его находится на важной пользовательской траектории вот собственно я практически все что хотел рассказал давайте к вопросам так поднимайте ручки потом вставайте и задавайте спасибо за доклад ближе микрофон приводит спасибо большой так вот два маленьких вопроса первый кто наполняет эту ткань то есть это люди которые меняют конфигурацию как вот процесс изменения происходят каждый сунула тут эта иллюстрация она хорошо подсказывает то есть каждый слой наполняется отдельно то есть каждый слой практически наполняется из некоторого а api некоторого источника ну то есть в эту услугу или сервис и вот просто там запрос к атласу охлаждающие сервисы и там есть интерфейс который позволяет то вводить потому что все в атласе не всех баз в 1-ой сильнее всех сотрудников почему-то в вал api dapi нет всех команд вот то есть результат автоматически от штата рука автоматика на участие до часть продлевается руками потому что вот это позволяет понять что у нас вот автоматика то там не все есть а второй вопрос не кажется ли вам что это очень сильно похоже на то что десятками лет делается в semantic web собственно link td это где есть связи собственно семантика и описывается как что с чем связано кажется что это ну смотрите вообще идея графа знания она на самом деле много используется привет поисковым движками прочим ну да это все это все примерно про это вопрос как именно жить и этим как это быстро поднять у себя в конторе то есть это все делается руками без покупки всяких с авто и прочее довольно быстро спасибо за доклад значит у меня вопрос такой вот мы учитываем информацию пройти мы я здесь сейчас ну а вижу да значит мы учитываем информацию про этим и откуда они взялись куда они залились где за кашира волеси тогда в рамках этой концепции как еда рассматривается история о том что этим может быть за кашира ванне весь и какая часть его за кашира но просто предупреждаю я понимаю да что каждый элемент каждая их база она кэширует только фрагмент нужных им полей мы сейчас вот вот этот нюанс не капает потому что вам нафиг не надо ну потому что мы как бы мы слона начинаем есть да чё то тянулись тебя съели если это будет актуально это тоже добавим то есть тут суть этой ткани заключается в том что оно может разрастаться если нужно то есть возможно мы обогатим каналы информация перетекаем их атрибутов просто сейчас это пока излишняя сложность потребностей особо не было спасибо спасибо за доклад скажите а после появления у вас такой визуализации насколько ваша монолиту уменьшился вообще-то помогает уменьшать монолит которые стоится так ну во первых мне монолиту вот это вязать скажем так нет она не от этого не уменьшился вообще просто с ним стало проще жить то есть смотрите кейс про уменьшение монолита про обоснование монолита это вообще находится в другой зоне этим тоже кстати я занимаюсь во многих во многом в рамках доменного моделирования но это происходит не на техническом уровне это происходит на уровне продажи бизнес-идеи бизнесу продажи числовых метрик что распил монолита позволит нам вот здесь заработать больше а здесь терять меньше это вообще в другой зоне но визуализация позволяет а на презентациях пусть бы позволяет испугать какой страшной картинкой бонус еще есть вопрос можно и так так ага да добрый день спасибо за доклад собственно есть такие системы я уже говорил сентябре есть гендерное решение от объёма . например и от beyonce тоже есть пропиши вас перебью 7 тебе мы знаем он а вот информация серверах хостах от железах вот оттуда вот смотрите там есть спирали discovering знаете нам не расслышал есть такая штука как спиральный discovering это зонт автоматически начинают искать папу лай и адресов выделять сервис и находить на них марты и потом ну соответственно discovered вплоть до and user experience если есть интеграции там систему мониторинга и так далее вот ну почему вы решили использовать что-то новое а не используйте что-то старые что уже десятками лет работает и во многих но многие компании используют гендерные решения которые хорошо себя показали то есть есть скажем так сентябре который также отражает графы там все это можно найти можно найти связь от бизнес сервиса его owner а это вообще эта тема называется эти сервис-менеджмент от оттуда пошло того как бы войти у есть отдельная тема как управлять тишка это типа itsm и войти сэм есть отдельная ветка 7 db есть то же самое это ну как бы почему вот это не было взято хорошая старая да что-то новое и эта история ответ на эту историю стоит на это вопрос состоит из двух частей потому что во-первых мы не очень любим гендерное решение мы не любим платить вендорам кроме тех случаев когда не делать что-то прорывное но в данном случае у нас был ряд заходов когда к нам приходили крупные векторы тут например вот последний к нам приходил это оп оп detect динамик от не мой ноут у меня просто на ноуте так классно наклейка от них есть они тоже это делают из свежей компания вот про это же то есть который это делает вот лучше чем вот те ребят что вы описали ну и пройти как бы они теоретически это делают но дальше вон за им практически вопрос вот типа вот наши жизни вот у нас монолит вот у нас тут по хп тут у нас год тут у нас губерний тут все поднимается вот тут у нас свой суп описанный атлас тут у нас базы который развертывается ну типа давайте нет ну то есть короче и понятно чтоб через через пару лет внедрение кучу денег конечно да ну то есть речь идет о том что это очень простая вещь и вам для этого метр на решение и нужно они дали кому-то может нравиться работать вендорами ну смотрите а вот как вы собираете встретить юзер экспириенс они не смотрите мы в бою мы сейчас на уровне логированием и у нас вот во первых все пользовательские действия не лаги руется через шину в нашу аналитику и у нас каждое событие которое пользователь делает мы сейчас его обогатили и там появилась ссылка назад то есть ссылка то есть вот человека вот он делает действие точно же открывает ой там и мы знаем что такое забыть у нее было предыдущие и каждое событие она как бы лакируется ссылкой и мы вот эти события ссылками мы специальным накопителям на потоке мы выстраиваем в траектории это называется к разблокирование пользуетесь которых трое то что у меня на последнем слайде и там мы как раз можем отличить траектории которые частые насыщены а то те которые случайно вот таким образом это дело это уже реализовали или блокирование реализовано сшив к в процессе аналитика частично используется то есть логирование да все уже ссылками назад лакируется причем вступаете в чем проблема тут и ос android the same десктопном avi там все везде есть небольшие специфики потому что это чисто на фронте на отдел чтоб по-честному но это ездил спасибо вот я кстати не принуждая использовать винтер на и решение груш то есть технология 7 т.п. есть конечно магически discovering ну как бы технология старая неважно кто и внедряет vanderley open source конкретный вендор без разницы ну да такое тоже то же самое округа это тоже атлас вы посмотрите все же знают а то снова посмотрели как выглядит атлас у нас после того как мы его доработали то есть возможности подкрутить под себя она хороша всегда идет спасибо в центр сюда теперь вы т.д. спасибо за доклад на наболевшем у вопрос следующий на самом деле понять более факту по наболевшем понятно как идет связь сервисов между сервисами когда у нас идет синхронный запрос по синхронным когда мы пациенту это запрос шину вы пытаетесь тоже идти от сервиса к сервису они по сообщениям которые в его посылаются потому что я наряду со списком да по подпискам все-таки по типу сообщений да у нас тип сообщений четко вот он в кайф терминология кафка он считается как бы топиком и там четко происходит вот сервис вам публикует определенные топики и мы знаем что кто на какой топик подписан все общаешься позволяет если чего кому не надо закрытию возможности выйти на определенный топик чтобы там чем чё попало не слушали спасибо чуть не раскрыто был здрасте геннадий московская биржа спасибо за интересный возврат хайповые слова надеюсь пригодится тема точно актуальное и спасибо за доклад есть пара вопросов 1 вы упоминали в дата фабрики вот в этом своем pierce the фабрики на самом нижнем уровне entity вы их как-то автоматически отслеживается я не раз слышал ни одна предыдущих раз попридержать конечно вы на пирсе стэн фабрики на самом нижнем уровне на 2 entity на ткани на ткани на этого сказать не шутка меня же рассказывали ребята из беды что у них провал проекта дайте побрит был что они перевели как фабрика данных построили фабрику а вообще-то в оригинале имелось дудка не вот и поэтому сегодня получилось поэтому важно это не фабрика у меня департамент как раз фабрика дана понимаю так вот сущности вы как-то отдельно отслеживаете автоматически наполняете или это ручная работа срочности список сущности да и их связи если они есть и либо связи и не следить а ну это вот мои доклады про анкор modeling по х аналитическое хранилище то есть у нас фактически хранилище она автоматически генерируется по описанию сущности связи атрибуты и вот эта информация прямо напрямую льется там хитрец источниками потому что истоки что вот эта сущность она поступает от туда еще оттуда оттуда там часто еще из-за промежуточных буферов вот этого путь как каждая сущность прилетает не всегда допускает автоматический парсинг то есть сущности автоматически пути заливки сущностей полу ручном режиме а вы справляетесь со сложностью когда сущности из одной в другую сильно пересекаю трансформируются там в одной грубо говоря условно таблички лежит целая их пачка разделенные по каким-то признакам то есть со сложными читайте про анкор modeling там такого не бывает то есть мы у нас сущность это бизнес сущность а не то что система там какую-то сущность назвала x там изгибе юзер как кончита к у нас есть пользователь пойти пользователи этот чек из мяса то есть вот он тоже разная система могут его по-разному представляет но это одна сущность но это это это вот про другое завод из другой немножко областью ну окей хорошо спасибо большое спасибо большое николай вот это вам ура и скажите кому из-за давших вопросы книга книга вот кто просил baby рассказывал там было интересно вот он ушел не ушел он там