всем привет меня зовут антон я из 2гис и

сегодня я расскажу вам как сначала я не

понимал

хорошо ли работают мои сервисы потом

начал складывать их сырые логи в графа

ну в crack house нарисовала тысячу

графиков в графа не и понимание пришло

если вы тоже любите понимать работу

своих сервисов через за графике то

возможно клика вас вам может в этом

помочь и нам с вами сегодня по пути мы с

вами здесь не будем поднимать больших

кластеров и считать на них деньги мы

поднимем маленький персональный crack

house и будем показывать его внешнем

мире только через графа ну вот например

мы с ним работаем уже два года и у нас

всего пару серверов и нам пока хватает

вообще кто мы и что мы в 2гис

мы наша команда занимается сервисами

транспорта и транспортом данных от нас

пользователям и

статистике от пользователей к нам если

вы когда-нибудь пользовались мобильным

приложением 2гис то вы скачивали данные

одного или нескольких городов к себе на

устройство это оранжевые стрелки то есть

данные уходили с нашего data source

бэг-энда и приходили к вам на устройство

и в то же время все наши продукты

мобильные приложения мобильные

приложения сайт внутренние сервиса шлют

статистику о своей работе к нам мы на

своем пера критическом бы кэнди

принимаем во лидируем как-то там

обрабатываем и складываем в кафку

поговорим сначала право первый сервис то

есть просидел оранжевой стрелки когда

приложу мобильном приложении 2гис

пользователь хочет посмотреть карту

например новосибирска

он там тыкает на хочу скачать

новосибирск приложение идет на наш

маленький силен и запрашивают у него

файлы все файлы входящие в регион

новосибирск седин у нас очень простой

это десяток-другой каширу ющих и джинсов

1000 запросов прыжке несколько десятков

гигабит исходящего трафика трафик в

данном контексте не важно как было и что

болела до описываемых событий мониторинг

и джинсы как

джинса у нас сводился к тому что крон

скрипты раз сколько-то времени приходили

грипп или

из логов коды ответа считали их

количество по каждому коду с момента

предыдущего запуска складывали во

временный файл

потом раз пять минут приходил zabbix и

забирал эти данные к себе ну и плюс

собирал штатные метрики типа трафик с

интерфейсом познавательно аж жуть муж

был какой-то не дай ластик его никто не

любил предпочитали ходить напрямую на

сервера и там глеб отлогим хотелось

большего хотелось разных срезов запросов

и трафика например по версиям приложений

чтобы понять что новый релиз android не

принес деградации или например по

регионам чтобы понять что наша карта

покрытие без дыр и все регионы качаются

с удовлетворительной скоростью они

только новосибирска где находится наш

головной офис хотелось смотреть разные

процентили например время отдачи и

скорость скачивания чтобы понимать что

мы нормально обслуживаем пользователю

что у него ничего не тормозит

а еще хотелось поиска пологом на

достаточную глубину потому что

периодически приходят люди говорят

слушай я тут месяц назад ездил в москву

и это самое москва вы не тормозило ну

если она медленно мне качалась давай

разберемся в чем была проблема ну и мы

садимся и начинаем разбираться сравним

логе приложения и

логе сидена конечно проблему можно

закидывать деньгами на колбасить кучу

скриптов для подсчета агрегатов как вот

текст про который я говорил раньше

складывать их там в zabbix про металась

не важно поставить elastic на несколько

терабайт для поиска пологом это же жить

в принципе достаточно спокойно но есть

проблем чтобы закидать деньгами

естественно деньги надо где-то взять

а еще это будет как минимум две

различные системы для сохранения

агрегатов их для хранения своих логов а

если вы придумали новый клёвый агрегат

тоже вам либо надо ждать несколько

месяцев пока у вас наберется достаточно

данных чтобы можно было как-то

проанализировать его

либо выдирать из хранилища сырых данных

эти самые сырые данные считать агрегаты

и складывать в хранилище агрегатов это

если это хранилище поддерживает заливку

задним числом ну геморрой

мы думаем над альтернативы ну во-первых

access локон джинсы хорошо ложится на

табличное представление это куча записей

с одинаковой плоской структуры

а еще половина полей в этих записях это

числа или что-то близкое к ним типа date

а во второй половине очень много

коротких повторяющихся строк типа

платформы или имени региона еще для

построения какого-то среза обычно нужна

пара полей до то со временем это почему

группируем ну и опционально то почему

фильтруем на под это все отлично ложится

пока лодочная база данных как раз в то

время в open source вышел crack house у

которого идеология хранить вам не все

сырые данные а я вам агрегаты быстро

посчитаю ну поэтому попробовал

попробовал его развернуло какое-то

дохлой виртуалке там четыре ядра

4 гигов памяти какие-то непонятные

шпиндельные диски создало в табличку с

базовыми парами там дата время тебе

запросы код ответа отправленные байты

вот так вот такого плана

подумал что для срезов мы обычно будем

использовать ну там например дату будем

точно использовать тип запроса ну и код

ответа потому что типичный сценарий для

построения

для расследований это а давай посмотрим

запросы за вчера которую успешным то

есть двухсотым кодом от запросы на

данные вот почему акцентирует на

внимание потому что

логики выбора первичного ключа не всегда

говорят ну и это такая discussion тема

для дискуссии можно можно сказать что вы

чет не правы и надо совсем другие поля

были выбирать вот значит создал и

табличку сказал я знаю регулярное

выражение и налил в эту табличку сколько

было данных из сырых логов и все

наверняка ведь лет комикс надо тут надо

отметить что есть очень простая заливка

данных механизм ты говоришь insert into

the bomb формат json и чел потом на

каждой новой строчке плоский джейсон с

где имена полей это именно колонок в

табличке а значение это те значения

которых ты хочешь в эту табличку сложить

тогда cliff house возьмет ли джейсона те

поля которые есть джейсоне и скалы в

табличке

из заполнит их этими значениями те поля

джейсон некоторые которых таблицы нет он

отбросит а те поля который есть таблицу

нет джейсоне он заполнит значению по

умолчанию просто быстро удобно мне очень

нравится я сначала думал что решаю

задачу и txeq запросов то есть у меня

будет хранилище который я буду делать

как писать какие-то select и

и смотреть но она внезапно начала вести

себя так как сказано на футболке его

разработчика она не тормозило я

посмотрел техно не тормозит и к этому

графа ну решил притащить поставил плагин

для графа ны от ребят из where the media

тогда еще благо самой самой первой

версия 001 она завелась сразу из коробки

и графики начали рисоваться и рисоваться

быстро что надо сделать чтобы нарисовать

график вам надо сформировать такой

запрос который вернет в первой колонке

темп

количество миллисекунд с начала эпохи а

остальные колонки это те точки на

графике которые вы хотите нарисовать

именно колонок в этом случае будут

я именами линии в легенде либо можно

второй вариант использовать первая

колонка все так же темп а вторая это

массив кортежей где первый элемент

кортежа

это ими линии на графике а второй это

данута значение в которой надо поставить

точку как написать такой запрос все

просто мы берем временную шкалу dither

минирован и делим на одинаковые

временные интервалы и каждую точку

приводим к началу интервалов которая

нападает

звучит может быть сложно но на самом

деле мы делим на цело

на перемену интервал а потом на неё же

умножаем все попали в начало интервал

дальше просто аккаунт у нас будет ли

квестами uniq в нас будет уникальными

пользователями

точно так же можно сформировать и массив

но массива так обычно никто не формируют

с массивами можно делать более

интересные штуки например посчитать

квантили как в интере считаются ты

говоришь я хочу посчитать такой такой и

такой квантиль кликов за один проход по

табличке считает эти квантили и выдает

массив значений но нам-то нужен массив

кортежей ну что делаем мы формируем

такой же массив

массив такой длины с именами вот этих

квантили

а потом через и рэй map мы их объединяем

получили массив кортежей все просто

будут что можно делать еще с массивы

просто документации открываешь раздел

функции для работы с массивами и читаешь

там очень много интересного рекомендую

[музыка]

графики рисуются

это надо как-то использовать ну

напоминаю вы раньше было так просто ну

за лицом я рассказывал еще был файл бит

который читал все слуги джинсы и через

луг стаж отправлял их власти cto есть

чеснок стоишь у нас шёл поток

структурированных логов что я сделал

через простой базирующийся cryptic

направил этот поток сколько us спойлер

потом мы вообще отпилили схему забег

самые ластиком и получили буквально из

коробки вот такие интересные графики ну

например срезы по серверам

тут видно яма когда один из серверов

ушел в бокал запросы не

перераспределились и другие сервера как

должны были такие же графике можно

рисовать такие же срезы пока дам ответа

по платформам можно рисовать вот статус

и каша тут виден скачок миссов когда мы

опубликовали новые данные и кэш и только

прогревались этими данными можно

рисовать те самые процентили которые мы

хотели где-то там в начале

вот тут нам пришло слишком большая

нагрузка мы не справились и просели и

отдавали медленнее чем хотели бы если мы

хотим добавить новый срез то есть новые

поля по которой настроить свет это

делается очень легко

вы добавляете поле в логине джинкс и

добавляйте колонку в 3 классе

все остальное работает автоматом вот

например переходили мы на ищите теперь

мы добавили поле влоги какой признак

типаж дпс это или http ну и в догонку

сайфер to sew который установился и как

есть складывали их соответствующие

колонки в хаосе или например

договорились мы с мобильным приложением

что они нам будут слать какой-то красный

заголовок мы значение . они начали нам о

слать мы значение этого заголовка

складываем влоги

создаем колонку в крик хаусе все

работает автоматом

хотел сделать слайд со всеми полями

которые есть в колонке таблицы

ну вдруг понял что перечисляю тому

словно каждую пятую переменную из

документации джинсы вы все наверняка

видели эту страничку так что имеете

представление о чем и говорю важные

штуки типа 500 х годов ответа или

медианы скорости скачивания конкретных

серверов у нас zabbix и забирает через

бибиси несколько усояна это навешены

триггера alert улетают с лаку в почту ну

в общем все как у всех но время идет и

нам хочется смотреть графики за все это

время но на масштабах от пары недель она

начинает притормаживать

от пары месяцев начинает тормозить ну

вообще там даже отвалятся по таймауту

вот например на слайде видно что за

неделю мы график строим за 7 секунд за

месяца за полминуты а за полгода мы

строим график 3 минуты

ну никто не будет ждать график 3 минуты

и особенно даже если на дашборде таких

графиков еще там десяток ну надо читаем

документацию читаем про центрирование

crack house на диске хранить данные

отсортированные по полям входящему в

первичный ключ и если в первичный ключ

добавить ключ сэмплирование то можно

говорить

отдай мне не все строки под попадающие

под запрос а только их часть

либо в абсолютных значениях либо в

процентах мы например используем

абсолютное значение 100 миллионов вот

она слайде в процентах мы спрашиваем

половину строк и тогда клик house

постарается

выбрать примерно указан запрошена

количество строк и постарается сохранить

соотношение между различными сочетаниями

значений полей

который входит первичный ключ вот если

было 28 числа в два раза больше 200 х

годов

чем 304 то он это соотношение

постарается сохранить вы получили

семплированный данные вы потом выдам

ножа и ти это на специальную виртуальную

колонку сэмпл фактор это коэффициент во

сколько раз меньше выданных запросили

то есть для предыдущего запроса это

предыдущего примера это будет 2 то есть

мы спросили в два раза меньше данных

результатами ножами 2 получаем примерно

то что хотели не верили долго сравнивали

рисовали граффити по точным данным epa

центрированным но плюс-минус похоже есть

нас на центрирован их есть какие-то

личные пике но в целом не критично

важные вещи которые zabbix ну как на

который вам надо смотреть

этапе там 500 эти самые медиа на

скорости скачивания у нас забита

забирает по точным данным он забирает их

за короткое время можно позволить себе

полные запросы а для графиков посмотреть

как она себя вела на масштабе полгода и

и таких графика вообще за глаза хватает

а если не видно разницы то зачем строить

больше

цель достигнута все наши графики

строятся за примерно константное время

единицу секунд мы вот так жили жили

смотрели на эти графики например

приходит нам android говорит мы

зарелизили

ну мы одним глазом смотрим на график не

изменится ли чо

если меняется характер например

изменился мы такие смотрим расследуем

если это та самая новая версия android

идем к ним говорим чуваки чет не так

давайте разбираться разбираемся в

котором fix если что все имена и

совпадения случайны давайте посмотрим на

пример расследования как расследуем если

на каком-то из графиков есть какой-то

ниже неожиданное изменение характера

например ступенька из ниоткуда или

провал возможно такой же провал ли

ступенька есть и на других графиках и

можно найти корреляцию и можно либо

найти виновного сразу либо сузить круг

подозреваемых и тогда уже идти в базу

делать select и рассматривать точечные

запросу

вот я вам показывал эту яму один из

серверов назовем его мистер оранжевый он

ушел в укол запросы к нему уходили

никаких ответов не приходило дождитесь

пересчитав по идее наше приложение

написано так что они должны обрабатывать

такую ситуацию и когда один сервер

уходит black hole запросы те которые на

него уходили должны обрываться и уходить

на другие сервера то есть общая кривая

графика та самая пользовательская кривая

она должна остаться неизменной просто в

какой-то момент оранжевого до должно

было не стать других цветов должна была

стать больше потом раньше вывернулся

других цветов

основа меньше этого не произошло то есть

где то не до балансировка разбираемся

дальше ищем корреляцию смотрим на типы

запроса и по данными по метаданным есть

провал корреляции нет смотрим корреляцию

пока там ответу и ожидаемо нет ну потому

что это когда ответа и баг холл не

должно было быть но проверить-то надо

смотрим корреляцию по платформам up a

bingo таки да это и провал только у

айфона начинаем разбираться дальше

оказалось что закачка отданная

операционной системе уходит на сервер и

залипает и если серый выходит black hole

уточнил операционной система продолжает

ждать ждать ждать пока сервер не

вернется там может до бесконечности

ждать когда сервер вернулся вот видим

всплеск все те кто висели вот в этой

такой своеобразный очереди все до качали

причитающиеся им и дальше работа пошло

нормально ну и ребятам зари портили

они какой товар краны это сделали

починили если устроить и разрез по тем

вот в устройте графика там ли не слишком

много то имеет смысл корреляцию искать

надо только по какому-то top н например

по топ-10 тех тех линий от которых было

больше всего запросов или трафика смотря

почему корреляцию ищите например версии

приложений ну их много

можно также делать для хищников игиш

ников регионов так вот берем то почему

делаем срез

то есть версию приложения берем тот

временной интервал который нам дает

grafana то есть тот интервал в который

мы будем строить график и берем только

top top н то есть тут вот в переменной a

limit определяет какое количество мы

заберем и аккаунт значит по запросам то

есть от вот этого

от вот этих вот 10 от этого лимит версии

приложений у нас пришло больше всего

запросов все мы получили

vin номера версии и потом это можно

использовать секции при в и график

рисовать только по ним время шло где-то

вот наверно прошел мы смотрели нас все

устраивал но потом любопытство одолело

как известно любопытство не порок

любопытство это хобби что еще можно

вытянуть из этих данных ну вот например

что чувствует пользователь а как я

говорил пользователь качает ни один файл

он качает регион и пока все файлы

входящие в регион он не скачает он не

удовлетворен давайте посмотрим ну за

сколько времени мы его обслуживаем

принципе просто посчитать мы берем время

скачивания первого файла берем сказать

время скачивать конец скачивание

последнего файла вычитаем из конца

начала

группируем по пользователю

региону и версии региона чтобы

удостовериться что ну точнее чтобы

посчитать

скачивание время скачивания одного

региона одним пользователем получили

одну цифру все сми уже можно работать

можно например строить график вот

например тот же график соответствующее

тому провала про который я говорил

раньше видно что пользователи в

во-первых видно что скачок 8 5

процентили видно что пользователи

которые пришли в начале вот того

четырехчасового провал а вот они все

четыре часа ждали пока серверов вернется

тех которые пришли в конце ну они

обошлись получаса но тоже не сахар есть

проблема пока сгруппируем по

пользователям пока посчитаешь процентили

подтормаживает

вот бы можно было чтобы она фоне как-то

группировались агрегироваться мы потом в

какой мое время заходим в такое пришли

запросили данные и быстро нарисовали

график так вот есть такой механизм

называется крикете 03 в обычном марс-3

ну это семейство движков и

и сам движок crack house хранит данные в

кусках и периодически фоне производит их

слияния при котором там даны перри

упорядочиваются а я в агрегате мышцы все

тоже самое но можно хранить

промежуточные результаты работы в

реагирующих функций типа мем макс 0 и

как на слайде аккаунт и тогда при

слиянии если

будет больше одной строки с одинаковым

сочетанием значений полей входящих

первичный ключ

тогда он их до агрегирует и будет новый

промежуточный результат вот с данными за

29 и 30 число все просто они были в

одном экземпляре поэтому с ними ничего

не произошло а вот за двадцать восьмое

число было 2 2 строки и при слиянии они

промежуточный результат перри считался

и получилось 500 аналогично sum sum

аккаунтов ну кому то слишком просто

очень поинтереснее например уникальных

пользователей посчитаем для простоты

цифры те же опять же с 29 на 30 числом

все осталось так же а вот когда мы

производили слияние точнее кликал сам

где-то фоне производил коли слияние

данных за двадцать восьмое число он без

пересчитал и получилось меньше чем сумма

потому что 100 пользователей были

и в одном в одном куске и другом куски

при слиянии он и где дуплицировать мы

получилось действительно уникальные

пользователям так мы значит имея вот

этот механизм мы делаем

материализованные представление которое

у нас забирает данные из основной

таблицы

считает вот этот агрегат и складывает и

фоне он периодически вот так вот да

агрегирует мы приходим делаем запрос в

этом матери зова на и представление и

быстро выводим на экран если вы мы

строили из основной таблицы вот этот

график мы бы за полгода строил его три

минуты из материализованные

представления мы бы строили его меньше

16 секунд а если мы из материализованные

представления сэмплирования мы это будем

делать

чувствуете да уже на второй круг пошли

второй круг ускорение и атомы меньше чем

за 3 секунды

его построим вот таким образом уже можно

снова в real time рисовать эти графики и

смотреть не ухудшается ли

пользовательский опыт эти графики

довольно эмпирические и

общеобразовательные мы на них смотрим

если время сильно поползло вверх то

начинаем детально разбираться привлекаем

нашу статистику ну и другие мощные но

медленные инструменты но вообще хорошо

когда можно перед

верить через надежного через надежный

источник другой источник но в целом как

прав в концепт она взлетела и меня

радует в решении конечно есть недостатки

самый первый и самый главный это

отсутствие генерализации и чем и хранить

свои данные соответственно на каждый год

глубины хранения нам нужен условный

терабайт на каждый из реплик можно

конечно наплодить вот таких вот

агрегируются хвате рисованных

представлений и хранить нереализованные

данные в них но тогда мы лишаемся той

самой фишки помнить это придумал новый

агрегат и сразу получил его на всю

историю а ещё у нас самописный

прослойками из 27 крик хаосом хотелось

бы чего-нибудь более и более

стандартного вот сейчас мы

экспериментируем мы пробуем работу через

прокси мы как происходит мы из xt со

стандартными средствами отправляем

каждый запрос по одиночке

ну как каждую строчку logo поодиночке в

специализированный прокси в как house

bulk это прокси она агрегирует их в

пачке и уже эти пачки вставляет в как

house пробовали еще точнее хотелось

попробовать иплхаус от vkontakte но они

не поддерживают тот формат json и шоу

про который рассказывал то есть нам

нравится в контакт вам не нравится ну

ладно века вас баллов вроде выглядит то

что нам надо ну и нет аналогов киба на

мы конечно консольщики

но наклеивать мышка и фильтры быстрее и

удобнее вот чем каждый раз писать заново

select и ну че мы все о сидении да се

денег у нас и второй сервис есть

транспорт статистике вот напоминаю

фиолетовый стрелки как происходит все

наши сервисы

мобильные приложения сайт внутренне

сервисы шлют статистику свои работы нам

на наш бюрократический backend мы

складываем в кафку статистика это поток

пачки джейсон of то есть мы складываем в

краску пачки джексонов кафка поток

джейсона получился у нас все был поток

бессонов помните да мы его смешно

сделали правильно - ваш

левка cows а поток чемпионов это был

джейсон которые шли через за ваш язык

station взяли и направили этот поток и

cows что если мы здесь сделаем то же

самое в принципе тут уже все тоже самое

только

масштаба больше порядка 20 тысяч

сообщений секунду пишем с маленький

сириус окна скале который вычитывает и

сказки эти джейсон и и складывает их

клика us создаем табличку с простыми

техническими полями всякие там стемп и

тип сообщения продукт который послал это

сообщение только технический поля бизнес

поля не трогаем оставим их бизнесу и из

коробки получаем вот прикольные графики

например сколько у нас сообщение шло

через наш транспорт считается

элементарно мы взяли время сохранения

кафку взяли время которые когда мы

приняли его на engine xi вышли с первого

второе мы нарисовали квантили

тоже самое можно сделать например как

сколько пользователь задерживают у себя

сообщения то есть берем время при

приемной джинсе вычитаем из него

время генерации сообщения пользователя

мы получаем сколько пользователю себя

его держал можно строить всякие разрезы

по продуктам и по версиям приложений и

смотреть что мы нигде не теряем удобный

нам смотреть и поставщикам статистике

вот например был нас факап с

корпоративным дебетом и продукты под

номером 3 и 4

нам вот то время когда rabbit лежал не

слали статистику а если посмотреть на

такую же разбивку но по типам сообщения

видно что сообщение типа 3 тоже не

приходили вот ну посмотрели

проанализировали потом дослали все что

надо ну этих эти графики рисуются прямо

из коробки береги рисуй ну естественно с

центрированием потому что данных много

но можно поднапрячься сделать несколько

еще материализованные представлений и

сделать еще прикольные штуки

первый это польза дубликат ну что такое

дубль понятно если мы два раза запишем

сообщение о том что пользователь кликнув

баннер толстые комада тилль два раза

спишутся деньги так делать нельзя

но как посчитать вот например так вот

здесь например

техническом и мы сделали наивную поиск

дубликатов то есть из таблички выбрали

только тех те сообщения

к хищнику сообщения которые встречались

больше одного раза и нарисовали их на

графике и нарисовали график и обнаружили

что какой-то один внутренний наш сервис

под номером 9 он нам шлёт свои сообщения

с одинаковыми идиш никами но разными

делами

вот ну и сейчас мы думаем как как проще

и правильнее это сделать как пофиксить

либо им почините сделать а хищники

уникальными

либо нам считать дубликаты не по

хищником а по крышам например вот как бы

не считать дубликаты мы логин джинса

возьмем и через знакомый нам уже

механизм по оранжевым стрелкам через

блок стаж положим в crack house

специальную табличку и сообщение сказки

мы положим в эту же табличку причем

когда мы будем складывать из engine со

мы

колонку специальную lost запишем

единичку а когда будем складывать из

кафки запишем минус единичку а потом при

селекции мы сгруппируем поедешь ником и

те у кого результирующий lost оказался

ненулевым то есть положительным те

потеряны то есть на яндексе мы приняли

она

[музыка]

мы джим все мы приняли искать и мы их не

прочитали вот вот например видно что

сообщение a и c они дошли а бы не дошло

у bb потеряно вот например сервис

который прикладывают

из кафки в пик house я ставил на

какое-то время на графике у нас поползли

потери ну чо за фигня engineers

принимают сообщение

а в кафки соответствующих сообщений нету

вот потом сервис поднял этот горб пропал

вот это просто для демонстрации

ну и вот так вот мы жили жили и начали

на каждый патент поток структурирован

информации смотреть с таким вопросом

если мы это сложным в crack house то мы

сможем каким 10 классных графики

нарисовать и знаете обычно так

получается что до сможем придумываем

такие графики приходится складывать

рисовать и радоваться если вы не

пробовали то попробуйте реально

затягивает

тут немножко полезных ссылок и это

естественно то чем мы рисуем графики

плагин для графа на переменные джинсы

которые я упоминал если вдруг не были на

этой страничке вам вдруг хочется

почитать перед сном

то сходить там какие есть интересные

переменные ну естественно документации

накликал ваш вопрос

[аплодисменты]

во-первых хочу поблагодарить тебя знает

доклад очень интересная и благодарность

как официальный сертификат от

оргкомитета и от него же bluetooth на я

колонка дела спасибо выйду из света

чтобы видеть ваши руки ассистента

включите пожалуйста светов просто было

видно и есть уже до первый вопрос

отлично спасибо за доклад вопрос вы

говорите про агрегируются

merge 3 насколько я помню в документации

не гарантируются что они там вообще

ничего не гарантируются про время когда

но агрегируется если какие-то

особенности при работе с этим совершенно

верно она не она не гарантируется

поэтому когда мы хотим посмотреть точный

график мы забираем и честно-честно

даггер у им рисуем до агрегированные вот

то есть там аккаунт аккаунт мер и и

агрегирует каунта медленно вот ну и days

i agree git merge 3 она по-другому не

работает а вот например с именно ржд и

сами наш 3 можно делать хитро там там же

лежат у нас эти самые уже цифры которые

можно использовать секции при вы

соответственно сейчас соответственно

когда мы хотим построить быстрый грубых

график мы в привык говорим типа выбери

там где уж где уже больше больше 0 в а

например где дубликатов уже больше

одного вот и мы рисуем только то что он

успел да да суммировать а если хотим

точный график то вот эту секцию сперва

убираем и рисуем медленный но точный

график а если правильно помню там вроде

есть способ гнуть базу данных чтобы она

до griger овал optimized тоже не никаких

гарантий она пьет но все еще ну на без

гарантии отлично следующий вопрос здесь

и я вижу руку

раз спасибо большое такой вопрос какой

объема сырых данных которого запихиваете

в слегка us какой объем

после того как вы запихнули в plyo хауса

какой прирост этих данных у вас ежегодно

ежемесячно не запасе так вот это сложный

вопрос потому что сырых данным и

проникну вот как есть влогах мы их

практически не храним очень сложно

сказать на какие-то

гигабайт и десятки сотни гигабайт может

ну не сотни уже вряд ли наверное от

гигабайт до десятков гигабайт вот где-то

очень грубо в таких пределах

вот в день в день день вот в день мы это

складываем в клик house не только от вот

этих перечисленных 2 сервисов а вообще и

ну вот сейчас вот эти вот логин джинсы

ну да представляете даже логин джинкс и

где-то с полтинником полей за где-то год

у нас занимают где-то 800 700 800

гигабайт это уже сколько у сюда отлично

следующий вопрос я вижу

и вдали и на галерке человек тянет руку

добрый день так не вижу вас я здесь

вопрос внезапно не pro crack house of

legends вы когда показывали аналитику

скачивания целиком региона определенным

пользователем вы сказали что мы ищем

когда начали скачивать 1 первую часть да

и закончили скачать последнюю часть

соответственно вопрос как конкретно в

логах engine вы определяете что это

конкретно этот пользователь скачал этот

файл а не какой то там еще 3 5 10 по

этим denpa анонимизирован ему

видом то есть пользователь слётом uid

который мы записываем влоги и мы по нему

группируем то есть родишь не по сути а

то есть вы еще одну кастомные

хедер давай кастомные поля добавлять

уроки

спасибо сейчас вопрос последнего ряда

кто следующий отлично бы за доклад у

меня такой вопрос не думали на тему того

чтобы выбросить блок стаж вообще ну то

есть яндекс во-первых можно научить

писать структурированные данные это

очень просто а во-вторых можно на ложки

написать плагин который будет прямо

кидать данные в crack house напрямую она

и так же eshe ne среди данные на всякий

случай если вдруг что-то пошло не так

так это хорошо да кстати про prime

джинсы пара структурированные логика не

вы хорошо заметили потому что я забыл

спросить кто еще испытывает боль от того

как в инсульте эти структурированные

логе пишутся

там мы пишем джейсон через конкатенацию

строк ну это фу фу фу вот кто-нибудь у

кого нить еще болит это поднимите руки

отлично я такой не один это радует так

лук стриж почему не выкидываем потому

что ставишь файл бит есть лог стаж она

работает из коробки и ластик для для

таких для обычных логов для блога в

сервисов которые такие достаточно

разнородны он все еще стоит мы все еще

им пользуемся не пользуемся вот для тех

его сценариев про который раз как я

рассказывал то есть он все равно есть

почему бы его не использовать

если надо какие-то большие нагрузки как

я говорил про вычет его не и сказки и

складывания в к устам большой поток

данных

тут проще свой сервис окна писать про то

чтобы nalu написать плагин chic ну проще

заюзать уже имеющуюся файл биту и уже

имеющийся акташ она вывозят зачем чет

оградить новое спасибо чего просто у нас

есть и и потом будет вода около колонны

спасибо за доклад я насколько понял для

некоторых графиков вы как-то

агрегировать и данные и хранить их в

какой-то таблица томате vision

наставления вот насколько у вас много

таких графиков и какой вверх от сколько

вы там храните

данных в этих таблицах за какой период

таких мы обуты постараемся помине му

обходиться такими таблицами потому что

как я сказал если мы делаем запрос не из

сырых данных а из предпочтительных

агрегатов то мы теряем фишку

если мы придумаем новый то считаю на все

можем начать на всю глубину посчитать

поэтому нас ну по минимуму и занимает

она где-то на порядок меньше данных то

есть если вот грубо говоря я говорил что

мы там 700 800 на год тех логов engine

ксф у нас есть то агрегируются у нас там

гигов 20-30-40 вот в в агрегируются

представлениях спасибо то есть она

достаточно солидно схлопывается на

порядки на порядок так и кто еще хочет

задать вопрос

а рядом живой человек отлич несколько

наивный вопрос а почему нет ли house

например ластик не не хотели не

рассматривали elastic был elastic тогда

вот я рассказывал что он занимал тогда

много места то есть те же пол терабайта

вот в который у нас почти умещается год

данных там было всего какие-то несколько

недель вот я его конечно параллельно

готовил вот ну выкидывал там вишни

выжимал вот он учил его помине менее

прожорливым быть но она она работала не

так быстро вот если в house другая я

беру из строя график без проблем за

секунды то из-за ластика это прям надо

постараться чтобы во-первых

схоронить там этот год вот во вторых

чтобы график из этого построить а я

очень люблю графики вообще жизни себе не

представляю без них отлично есть

следующий человек и кто будет потом

если я не вижу вы кричите здравствуйте

спасибо за доклад а подскажите структура

данных вас получается одна плоская

таблицы для исходных данных и все ли

хаосе так ну для каждого сервиса да

такая одна основная плоская таблица

все-таки для каждого сервиса по таблице

ну да естественно допустим смотрите

таблица для

сидена и таблица для стать

sticky которую шлет наши наши продукты

вот они совершенно разные они совершенно

про разные поэтому при этом для каждого

сервиса одна-единственная таблица в

которой сваливаться все но одна большая

основная таблица

и рядом могут быть словарики могут быть

агрегируются представление про который

рассказывал на таблицы с исходниками

выполнения альтера никогда не доставляло

неудобство чтобы он долго выполнялся или

там заводить сыр и я вам больше скажу я

боб для раньше было благин написал

который управляет таблицами в хаос и я

их через раньше был гоняю автоматом и бы

это нам ни боли не доставляет но обычно

понятно что надо что думаешь головы

прежде чем чё там что-то написать что

приведет к альтеру если обычно это

добавление новых полей или удаление

старых

изменения типа она ну прям редко

происходит ну то есть она об этом

обычно на это на этом не затыкается

серверов и таблицу нас мало

точнее одна таблица вот такая

виртуальная

это две реплики на двух серверах ну по

одной реплики на каждый из серверов

ну вот прогнала альтерна другу на одном

на другом через у кипра синхронизировала

все в принципе нет затыков затыков не

видно были знаете затыки альтеры которые

на модификацию данных велит вот вот если

у вас там сложная штука contigo в то она

на каждый кусок который она будет

модифицировать она будет этот в заново

прогонять ответственно она может может

во первых долго работать и ставить в

очередь другие запросы ну наверно этом

сервере там какие-то у меня помню вот

был такой такой сложный alter и в

очередь вставали

сейчас скажу в очередь вставали запросы

которые потом должны были сложиться в

матери зуй у матери зова на и

представление вот вот на таких на таких

может быть до поэтому надо очень

аккуратно нас модифицирующие запросами

чтобы там не сильно сложно и были в

спасибо ребята еще вопросы кантона если

не вижу скажите об этом вот есть вопрос

здесь

здравствуйте спасибо за доклад а

подскажите подробнее как вы используете

zabbix в этом случае то есть вас есть

графа новые в ней видеть графики зале

столько для тортов или жаль только для

легкого так исторически сложилось как

обычный начать универсаме отмазка в

отрасли так исторически сложилось у нас

был zabbix мы ходили через мы и он умеет

в бибиси

через би си он ходит у нас в crack house

по специально подготовленным запросам

собирает метрики и пороге

все пороги триггеры улетела флаг как так

спасибо я напоминаю что тот то больше

всего удивит докладчиков получает приз а

это будет профессиональная книга еще

есть вопросы похоже докладчик удивил

больше а есть вопросы есть вопросы в

отлично здесь вы затронули тему поиска и

проблему и дубликатов до оукли house

есть встроенный механизм 3 вы как-то

пробовали его использовать смотрели на

это так

реплейсер мертв 3 зачем replacing

он когда у нас был один стоит потом

появился новый стоит и мы хотим новости

старый стоит заменить новым а я

использую сами наш 3

меня два есть два одинаковых ивента

пришедшие в разное время и я их по там

грубо говоря поедишь нику их слаб и у

меня в результате получается двоечку там

было 11 получилось в сумме двоечка зачем

не совсем представляет зачем тут

реплейсер нет я просто возможно не

совсем понял то есть проблема как

таковой с дубликатами именно данных у

вас не существо нет мы ищем африка . я

правда понимаю да хорошо спасибо еще

вопросы я не вижу вас последний шанс

антон ты выбираешь лучший вопрос так ну

игра выдает если честно это сложный

выбор но я пожалуй остановлюсь на том

кто был первым то есть вот да да да да

да да выходи

придется читать две книги выходе

смог снова представься для тех кто

вокзале овсянников михаил бетмобиль

спасибо так спасибо снова начала вот

подарок книга в подарок

ребята спасибо огромное спасибо михаилу

спасибо антону
