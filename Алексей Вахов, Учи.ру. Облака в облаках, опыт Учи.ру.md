**Здесь переводится из видео и пишется статья Алексея Вахова из Учи.ру "Облака в облаках, опыт Учи.ру"**

Ссылка на видеодоклад 
https://www.youtube.com/watch?v=C7utdhh6UCk

**Текст сделан из субтитров. Буду очень благодарен в форматировании текста, его вычитки. Для этого достаточно знать русский язык.
Присылайте свои pull request или присылайте текст на почту patsev.anton[собака]gmail.com**



Как раз об этом расшифровка доклада Алексея Вахова из компании Учи.ру. "Облака в облаках, опыт Учи.ру" на DevOpsDays Moscow 2018. В докладе: использование Ansible, Terraform, хранение в Git, ревью, пересборка, финансовые выгоды, горизонтальное масштабирование в 1 клик.

https://www.youtube.com/watch?v=C7utdhh6UCk

Меня зовут Алексей Вахов. Я работаю техническим директором в компании Учи.ру. Мы хостимся в публичных облаках. Активно используем Terraform, Ansible. С тех пор мы полностью перешли на Docker. Очень довольны. Насколько довольны, как мы довольны буду рассказывать.

Компания Учи.ру занимается производством продуктов для школьного образования. У нас есть основная платформа, на которой дети решают интерактивные задачи по разным предметам в России, в Бразилии, в США. Мы проводим онлайн олимпиады, конкурсы, кружки, лагеря. С каждым годом эта активность растет.

С точки зрения инженерии классический Web Stack (Ruby, Python, NodeJS, Redis, ELK, PostgreSQL. Основная особенность что много приложений. Приложения размещаются в 5 облаках по всему миру. Каждый день идут выкатки в production. 

Вторая особенность у нас очень часто меняются схемы. Просят поднять новое приложение, старое остановить, добавить Cron для background jobs. Каждые 2 недели идет новая олимпиада - это новое приложение. Это все нужно сопровождать, мониторить, быкапить. Поэтому окружение супердинамическое. эта динамичность это наш основной вызов.

Рабочей единицей у нас является площадка. В терминах облачных провайдеров это Project. Наша площадка это полностью изолированная сущность с API и приватной подсетью. Когда мы заходим в страну, мы ищем местные облачные провайдеры. Не везде есть Google и Amazon. Иногда бывают что отсутствует API к облачну провайдеру. Наружу публикуем VPN и HTTP, HTTPS на балансеры. Все остальные сервисы общаются внутри облака. 

Под каждую площадку у нас создан свой Ansible репозитарий. В репозитории есть hosts.yml, playbook, роли и 3 тайных папки, про которые дальше буду рассказывать. Это terraform, provision, routing. Мы фанаты стандартизации. У нас репозитарий должен всегда называться "ansible-имя площадки". Каждое название файла, внутренняя структура мы стандартизируем. Чтобы потом  накручивать крутую автоматизацию.

Terraform полтора года назад настроили, так им и пользуемся. Terraform без модулей, без  файловой структуры (используется плоская структура). Файловая структура terraform: 1 сервер - 1 файл. В terraform используем настройки сети, dns-записей, дисков, сетей. Terraform на площадке полностью готовит железо.

Ansible. Из-за того что у нас везде  используется одна и таже версия операционной системы, то мы все роли написали с нуля. В интернете обычно публикуются Ansible роли под все операционные системы, которые не работают ни нигде. Мы все взяли Ansible роли и оставили только то что нам нужно. Стандартизировали Ansible роли. У нас 6 базовых playbook. При запуске Ansible устанавливает стандартный список ПО: OpenVPN, PostgreSQL, Nginx, Docker. Kubernetes мы не используем.

Мы используем Consul + Nomad. Это очень простые программы. Запускаются 2 программы, написанные на Golang на каждом сервере. Consul отвечает за service Discovery, health check и key-value для хранения конфигурации. Nomad отвечает за scheduling, за выкатку. Nomad поддерживает rolling deploy health check. Nomad останавливает старую версию приложения в кластере, поднимает новоую версию приложения в кластере. Nomad поддерживает распределенный Cron.

После того как мы зашли в площадку, Ansible выполняет playbook, расположенные в директории provision. Playbook в этой директории отвечают за установку программного обеспечения в docker кластер, который используют администраторы. Устанавливаются prometheus, grafana и тайный софт shaman. 

Shaman это Web-dashboard для nomad. Nomad низкоуровневой и к нему пускать разработчиков не очень хочется. В shaman видим список приложений, разработчикам выдаем кнопку деплоя приложений. Разработчики могут менять конфигурации: добавлять контейнеры,  переменные окружения, заводить сервисы.

В завершении, Ansible выполняет playbook, расположенные в директории routing. В кластер мы выкатываем свой routing. Routing сделан на nginx + consul template. Используется nginx без дополнительных модулей, у который время от времени меняется конфиг. 

Таким образом каждая площадка состоит из 5 слоев. Мы достаточно долго прорабатывали слои, чтобы они были независимы друг от друга. Applications содержит приложения пользователей и приложения администраторов. Provision, routing, apps полностью на 100% совпадают везде независимо от облака. Если ИТ-специалисты переключается с проекта на проект, то попадают в полностью типовое окружение. В ansible мы не смогли сделать идентичными настройки firewall, VPN для разных облачных провайдеров. С сетью все облачные провайдеры работают по-разному.  Terraform везде свой, потому что он содержит специфичные конструкции для каждого облачного провайдера.

таким образом у нас 14 сегодня 14 не сакральное число просто получилось 14 production площадок и возникает вопрос как им управлять соответственно вопрос-ответ принципе суд на этом слайде мы сделали 15 мастер такую площадку которую пускаем только админов она работает по схеме федерации вот идея мы взяли из прометея прометей есть очень крутой режим когда у нас в каждой площадке мы ставим прометей но там соответственно эти но до 7 обходит собирать собирать собирает мы его достаём наружу через катетер псы basic авторизацию и соответственно мастер площадке мы ставим мастер примет и который забирает только нужные метрики то есть мы получаем возможность сравнить приложу хитом в разных облаках с тестом найти самые загруженные или наоборот не загружены вот посмотреть там диски какие-то и так далее ну и централизованно лифтинг тоже у нас идет через мастер прометей для админов именно разработчики могут в локальных прометея себе настраивать алё рты и по такой же схеме мы своего шамана сделали то есть у нас сейчас через главную площадку администраторы могут деплоить на конфигурировать что-то править на любой совершенно площадке через единый интерфейс там есть на разница будет что если там не знают в россии в бразилию летит там pink побольше там прям чувствуется как бы разница есть но все остальное тоже абсолютно одинаково и достаточно большой класс задач мы уже решаем как бы не выходя с этой мастер площадке тут нам не надо бегать по всем этим геном как раньше было это конечно большой прогресс сейчас я хочу немножко рассказать то есть как мы переходили на docker и потому что это был какой процесс очень небыстрый мы переходили примерно 10 месяцев то есть прошлым летом у нас было 0 контейнеров продакшене соответственно в апреле мы такие резеро вале и перри выкатили последнее наше приложение вот сейчас монумент побыстрее бы сделали на тому как с полного нуля делали мы вообще ребята из мира ruby on rails соответственно у нас там особенно раньше были 99 процентов приложения и ты рубишь ну вот соответственно rails катится капистрано то есть это просто классика жанра там да да докер на я как бы все пользовались всегда copy страны будут пользоваться если у них нет докера технически капистрано работает он следующим образом разработчик заходит набирает как deploy капистрано идет по applications сервером псы сашу там забирает последнюю версию кода собирая the city какие-то на миграции бас делает делать сим линк и посылает сигнал там юникорн у пуме соответственно веб-серверу типа давай новый новый код подцеплять когда мы начали думать про docker и естественно что последний шаг он в докер ах так не делается там нужно старый контейнер остановить новый поднять вот соответственно сразу же возникает вопрос как переключать трафик ну в обычном мире за это отвечает нам сервис discovery всякие поэтому первым делом что мы стали делать мы на каждую площадку загнали консул потому что может мастера for man дружили вовсю мы взяли sqashy карпа консул везде поставили на площадке офигенная штука вообще ни разу то есть konce вообще ни разу не падал никогда ну то есть он супер стабильный надежный вот и все конфиги индексом isover консул тимплей то есть формально просто то же самое но уже мы были как бы готовы рауте динамические трафик внутри площадок следующим шагом мы взяли вот эти капистрано убрали оттуда дефолта вы и шаги и прозрачно для разработчиков их заменили на собственно вот этот капистрано заходил на какую-то мастерноду там собирал образ его за сову вокальный реестр площадке потом дальше захотел по ssh как бы на сервера забирал этот образ из 100 пил стартовала контейнеры то есть такая фактически была ручной scheduling с помощью скрипта то есть вот мы короче этот скрипт писали писали писали как бы уже разработчики все делали все тоже самое но у нас уже были контейнеры мы как бы уже ловили там дефекты знакомились это все темы на самом деле получилось прикольно вот потом мы когда уже давно писались и поняли что это совсем тупиковый способ потому что там уже этот раздулся скриптом стручек на шесток по-моему не стал в напоминать это не пойми чего мы просто взяли и поставили нам от поверх консул он ставится одной командой вот это есть разработчики также вызывали как диплом но на самом деле они уже катились кластер не просто об этом не знали знали конечно догадывались дальше мы вот это отлаженную схему который мы как бы с капистрано тащили в docker и мы взяли реализовали в виде веб-сервера отнялись sage доступ дали зеленые кнопки дип ио и вот история замкнулась соответственно в принципе вот этот способ мне очень понравился потому что мы на каждом этапе тащили весь стек целиком то есть я не знаю я войти как бы достаточно уже лет 15 я видел много раз такую историю то есть у вас есть какой-то там софт стек что-то такое старенькое доброе там не знаю заперлись и написана она работает и приносит деньги естественно разработчики там часто неофициально иногда официально пишут вторую клёвую классную версию вот это вот всего который все бодро перейдут естественно когда-нибудь проходит годы не ok погоды а иногда годы оказывается что не реализованы даже половину функционала и сама вот эта вторая версия она уже стала такая тоже вот разработка всем с нами работают в той старой и начинает третью писать там 4 то есть это реально бесконечный процесс потому что это просто очень сильно фрустрирующая есть классная штука моя не могу пользоваться потому что она не не функциональная как бы не полностью не функционально вот мы вместо этого идем так что мы со скрипом там костылями и подпорками двигаем сразу же все тут у нас нельзя например обновить docker engine вернее можно но на 200 серверах тоже продумать как мы обычно энтузиазм хоть немножко падать с выходками какая история у нас когда мы начали делать ну когда мы начнут эти все там докеры читает там начитывать там смотрите все туториалы они всегда котят 10 engine иксов либо 10 радистов вот совершенно отвратный пример потому что образу уже собраны образу очень легонькие то есть ну и они как бы бессмысленные соответственно когда мы начали взяли наши хорошеньких жирненькие rails приложении завернули их в докер они оказались по 2 3 гигабайта и они уже как бы катится не так бодро я там дальше буду рассказывать как мы немножко срезали углы вот а вторая проблема оно пришло от хипстер ского небо то есть хипстерский веб это всегда гид have all the set как в одиннадцатом году вот этот эпохальный был пост что типа гид have a roulette ну в принципе так весь в покатится ну-ка насколько я так узнаю которые простые люди соответственно как это выглядит у вас есть мастер мастер всегда production вот делан ветку ветки там ходим review им тесты гоняем там устоишь окружении поднимаем бизнес смотрит эти station потом возникает момент x всю зеленую мы держим и выкатываем сразу живот на капистрано это естественно работал отлично потому что он как раз для этого и создан он берёт мастер и его катит а докер нам продает pipeline всегда то есть то что ребят у вас вы собрали контейнер вы его можете засунуть и разработчик будет тестеру дать там и на продакшен и препарат вот а тут как бы когда в момент мер за на самом деле код а немножко уже другой потому что все образа которые мы прошлые собирали они не мастерские соответственно мы сделали то что то есть как мы скопье странно ушли мы так и до этого дошли нажимаем когда на кнопку дипой мы быстро быстро быстро собираем образ который получился то есть такой в каждой площадке есть сменись я и кладем его локально в реестр и уже там все остальные операции делаем то есть там миграции там какие-то иногда бывают такие тестовые там ну какие трек задачи нам разработчики делают ну иди поймать все соответственно для того чтобы быстро быстро быстро этот образ собрать и он же тяжелый вот мы используем такими докер опять же в интернетах все пишу как там когда вы гуглите там всегда написано что это анти паттерну не работает он крошится вот у нас ничего подобного не было у нас тут вон сколько уже работает с ним никогда проблем не было вот и вот эту папочку которая докер indoor там соответственно по моему что товары докер или что-то убьемся свои вот эти свои жирные хранит мы еще кашира он поэтому как бы все промежуточные образы всегда уже лежат на машине и сборка нового образа как бы она ну там несколько минут обычно укладываемся и за счет таких странных вещей которые мы делаем их достаточно много дева странных вещей не просто работают новых делаем вот мы соответственно для каждой приложусь и делаем локальный реестр и вот этот вы на свой реестр внутреннюю это который режет 32 по-моему называется и свой билд валим потому что когда мы на площадке положили их централизовано эти все вещи они очень любят диск то есть там десятки гигабайт всегда и соответственно ну там все естественно замусорил ось и очень сложно чистить поэтому сейчас у нас каждый реестр мы знаем в утилизацию брутто то есть мы знаем сколько он диска требуют и можно через централизованную графа но даже их отлавливать и чистить пока мы их руками чести мы тоже будем автоматизировать потому что их приходится на самом деле чистить кэш постоянно приложении много вот еще одна фишка которую мы столкнулись странная то есть мы доки в свой жирненький собрали теперь его нужно разложить по серверам серверов 10 штук или там 15 вот и сеть падает ну то есть она не справляется в лаббоке гигабит у нас соответственно там такой происходит глобальный затык сейчас мы запускаем на тяжелых продакшен их такую спецсуд задачу которые вот мы там экспериментальную нашли что по 4-го по 4 сервера раскладывать вполне ок вот это как раз на графике видно что там 1 пачка серверов там диск поработал пошла вторая пачка серверов а снизу это утилизация канала с собственность реестра вот там вот как 1 гигабит мы почти там вытягиваем и больше там особо ну особо уже не ускорить и у меня мой любимый есть продакшн это южная африка соответственно там очень дорогое железо там четыре раза дороже чем в россии и очень медленно и очень плохой интернет хвата и стабильное соединение до вот этих всяких docker hub of ну или знаку там модемного уровня вот соответственно но фишка в том что они именно медленно но не глючные то есть они как бы работают мы нашу платформу умеем там катить за 40 минут до скромный deploy на этой фигне занимается рк минут но именно на этой площадке мы оттюнили все каши все параметры все тайм-аут и и у сейчас у нас как бы такая . отхода все что мы умеем катить в африке мы выкатим вообще где угодно потому что такое реально но они хорошие люди и последняя проблема которую я жутко порево перед тем как мы связывались все это докер авантюру вот нагрузка всегда же мы же мы же нагруженных жесть как вот и мы упадем если мы перейдем на docker вот ну на самом деле нет мы просто взяли такое железо просто запустили его просто заработала единственный был нюанс мы уперлись всего в одну точку и то если из docker engine и собирать логе через встроенный флинте драйвер на как раз нагрузке около там тысячи запросов в секунду сакральных там начинал q это замусориваем видимо я не знаю как это насколько это технический звучит вот это внутренний буфер и запрос начинать тормозить вот соответственно мы вынесли логирование вот такие как этот сайт корр контейнеры так называемый как вроде бы в модном мире называется нам айди там это есть право страничка документации того к schipper у них называется паттерн вот соответственно рядом с жирным контейнером приложения висит маленький контейнер единственная задача которого забирать логии отправлять как бы центральную точку после этого все заработало то есть вообще не мы уже там и олимпиад куча провели и как butcher у крутится никаких особых изменений незаметно вообще нигде вот соответственно как бы мы вот это ну как мы вот так шли водкой к этому и в принципе очень всегда полезно понять и куда мы пришли вообще то есть и от чего мысли потому что может быть не туда пришли или как-то не так шли вот про это я попытался так по проанализировать собственно какая у нас была задача то есть как бы такие вот у нас можно там может быть содрать до типовые схемы вот особенности ключевые наши нашей проблематике это у то что куча приложений вот достаточно logo их уже потому что действительно как бы несчетное количество вот и постоянные постоянные изменения схемы то есть это просто реально бич без докеров мы просто умерли бы как к этому времени и 2 мне показалось таким тонким моментом это собственно как раз did have a потому что я почему-то на обсуждение как бы интернетах не ловил статей где вы писали вот ну как как у с этой штукой работать ну и соответственно да не редис и мы катим докер образа достаточно жирный вот это собственно как бы проблематика и соответственно наши решения то есть мне кажется что федерация докер кластеров это достаточно хороший термин для того что мы сделали с точки зрения управляемости конечно геморойно потому что действительно ну все равно приходится там скакать по и пену там иногда вот но с точки зрения какого такой философско более там как это подачи вылью бизнеса там и не знаю как это назвать совершенно офигительная штука потому что мы работаем с персональными данными у нас в каждой стране сертификация вот соответственно в изолированный такой площадки и очень легко проходить потому что всегда же вопрос там где вы поститесь как вас там провайдер там где вы храните персонал ку-куда бы копите кто доступ имеет и так далее вот когда все изолирована то соответственно круг подозреваемых описать гораздо легче и следить за этим тесно гораздо легче вот соответственно дальше парке страции то есть вот понятно делать там сейчас кубер нить из он везде кому-то из каждой там не знаю нас уборщица скоро будут спрашивать используйте вы или нет вот поэтому я ни в коем случае его не сети просто говорю что консулом от это вполне production штука ну то есть мы и пользуемся пока не знаю может перейдем на им перейдем тут кладется тут уж как бы не мы выбираем а общество за нас соответственно да быстро собирать образы в докер integer можно это тоже как некая так hop можно паки мы разрешаем и нагрузку ну какую-то относительно там не супер большую но уже не супер маленькую держать тоже можно все это как бы вот в принципе то что я хотел бы своим докладом сказать то что вот такие вещи работают какой у нас с вектор направления развития то есть одна из больших таких проблем была в том что эти площадки ну как 15 штук они естественно расползаются разные версии софта кто-то там чё-то зашел то есть мы же сейчас как раньше мы заходили по ssh и ковырялись да потом мы стали devops вами теперь ковыряемся помощью ansi вот он у нас на 24 индексов было два настроены одинаково все остальные были по-разному кайлом наводили уборку как бы их свели сейчас они снова разбежались вот сейчас надо будет их обратно это сводить поэтому сейчас у нас прям тотальная такая унификация стандартизацию то есть мы это все сводим к одному соответственно мы это учимся именно работать как бы внедряем обычное мышление в голову то есть у нас нельзя поправить позгалев у нас есть ты правишь там 0 там по возрастам не знает жены кто-то еще если ты правишь какой таинство с чего то нужно подумать это как бы хак или фича то есть это нужна какая-то тонкая настройка именно сюда то есть как вот эту штуку которую мы поправили распространить везде потому что если этот процесс запустить то будет как бы обычный там зоопарк не знаю как вы назвать соответственно поэтому у нас есть еще там куча безумных идей как бы это далеко не конец вот наверное не именно не хотел углубляться прям куда-то в космосе там на самом деле когда вот мы разбирались мы иногда там закапывались успеть до отладки g-кода ну кто уже документациях читали в основу на самом деле вот но там был цикл следующий то есть вот мы настроили эти все утилита не залетают мгновенно то есть вы за вечер получаете реально рабочий докер кластер соответственно потом вы его мы долго долго внедряли продакшн это всяко качали качали качали потом провели уборку соответственно все сократили и вся вот сама вот удивительная вещь которая получилась в том что те настройки которые у нас сейчас есть они практически на 100 процентов совпадают с теми настройками которые получаешь 1 вечером работы то есть вот то что то как tutorial в принципе так вот и у нас то есть в этом конечно маги вот этих там современных таких простых опыт собственных штучек что он все таки да ну миссия компании у нас учить детей вот соответственно мы не хотим там становится в специалисты в комнату супер 3 keys of те там или в чем то другом вот и соответственно то что мы из коробки бесплатно получаем ну такую совершенно как действительно очень приятную в работе очень мощную там эту структуру ну как я вот этим так даже восхищенные рад что мы за кладом удачное время все живем этим занимаемся вот на как бы этом все то есть я там приглашают я из контактов я мне показалось что наиболее док строчных фейсбук то есть этом если мы чуть такой новенькое хорошие сделаем этом напишу поэтому он добавится как бы я его как адресную книгу держу всех добавляем вот соответственно по вопросам есть у нас время есть временно вопросы да вот все тогда давайте вопросы за хорошие вопросы призыв [аплодисменты] но у меня несколько даже на самом деле вопросов в чем преимущество консул темплейт в придании полки плитами почему и пользуйтесь консулом они ангельскими тимплей там например для настройки каких-то правил фаерболов кручу арт уже просто в группу wars все определить ее фигачить с русскими тимплей коми но потому что сейчас у нас пока что вот эти внешние балансира ней трафик ведут прямо на контейнеры то есть там нет никого промежуточного слоя поэтому там формируется конфиг который вот как раз он собственно сами вот и печники порты кластера пробрасывать только поэтому но и в принципе у нас из-за того что все настройки балансиров лежат в кафе соответственно съесть мечте и к который мы уже очень близко подошли отдать настройки роутинга девелопером ну через интерфейс понятно безопасной что мне ничего не сломали поэтому то есть как бы самом к поэтому именно за счет того чтобы роутинг такой динамический был и по поводу однородности всех площадок то есть неужели не бывает запрос под бизнес или от разработки что нужно вот на этой площадке вы качеством детка этом тарантул с кассандрой и не знают бывает но это не но это прямо именно очень большая редкость и это мы как бы как оформляем такой внутренний отдельный артефакт то есть мы ну допустим нас есть там кучеру он в облаке у него база не работает у нас там дедики которые про брошены в облака но cts на по сгрыз над языках для облака это вот как раз такой артефакт все остальное одинаковое не да это есть такая проблема но она редко реально и наконец вот проблема доставки на площадку мне кажется можно просто про его от регистре в каждой площадке завести фисташка а и правит registry в каждой площадке на каждом облаке и оттуда уже быстро лиц а как туда засовывать ну как снаружи и снаружи очень долго кашапова пену за засовывать ноты ввп нужно срочно одно правило регистре они не ним не у нас с внутри засохнет и где интерес они подожди прежде смотри а как ты засунешь ты все вернут упрешься это то что когда мы раскладываем если мы раскладываем на там 15 рядов одновременно мы упираемся в сеть так так то внутри части она мы внутри вам его внутренняя упираясь внутри что люди конечно мы в гигабит упираемся в смысле как упираемся там то есть у нас допустим да докера у нас было выкатка 13 минут на нашу любимую капистрано нас как бы теперь был не испортить ну не сильно испортить мы 18 час к темно это уже конечно же с кого-то ну окей пофиксим но выбираем вы прям во внутреннюю сеть конечно ну хорошо спасибо еще вопросы вопросов а вот есть вопросы с таким количеством продуктов и таким огромным количеством судя по всему доки контейнеров которые вас бегут они в принципе все основаны примерно на одном и том же стаки так ну например на там утопи там надо ну да как часто вы тестируете или проверяете на обновление своей образы докера и как вы имеете дело с проблемы обновления когда там жили psy надо починить тут везде прям щас или там у панаса цель надо починить когда такой огромной коллегу то есть это в принципе проблема для любого админа она в том числе карта столько разных ну если такую штуку нашел на неделю садимся и чиним вот если именно выкатить то мы можем выкатить там целиком целое облако ну то есть мы можем стали накатить просто через вот эта через федерацию мы можем все приложения ну то есть мы можем там про кликать вот эти зеленые кнопки рядком и утечек чай пить они выглядят совсем то есть этот шаман там с бубном пляж это вообще санс аманда не зря вы собираетесь свой шаманом выпустить для вообще людей как чтобы поделиться своим опытом своим качествам вот смотри позволяете шаман вот андрей он обещает нам среднюю осенью за концерт шумана потому что надо же надо добавить там поддержку кубера потому что не серьёзны иначе ну и почистить там всяких лампочек ну вот и почистить заодно ну не на суше но это как бы опыта всегда должен быть более качественно конечно же на конференции рассказываю как мы там и жить там как бы все это приходим там ну что ж там как как по-всякому может быть как об руку в концепт шаман там выйдет в какой-то момент мне не ним мы собираемся мы собираемся то есть ну смысле как это там я вот андрея надо собирать соберется штука прикольно кстати получилось то есть мы как бы и пилили исключительно для себя она на реакции на bootstrap и четвертом то есть такая молода еще вопросы нет вопросов хорошо спасибо большое [аплодисменты]