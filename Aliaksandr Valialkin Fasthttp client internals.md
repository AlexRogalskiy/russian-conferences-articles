Я Александр Валялкин. Работаю в компании VertaMedia. Я для наших нужд разработал fasthttp, который включает себя реализацию http клиента и http сервера. Fasthttp работает намного быстрее чем net/http из стандартных пакетов Go.![](https://habrastorage.org/webt/mw/xn/qb/mwxnqbi-ufmc9agmni-so-gy-ls.png)

Fasthttp - это быстрая реализация http сервера и клиента. Находится fasthttp на github.com

![](https://habrastorage.org/webt/ve/vz/07/vevz07ucp1l6ou4pg8zp2kuhvzu.png)

Я думаю что многие слышали про fasthttp server, что он очень быстрый. Но мало кто слышал про fasthttp client. Fasthttp server участвует в бенчмарке от techempower - известный benchmark в узких кругах для http серверов. Fasthttp server участвует в 12 и 13 раундах. 13 раунд еще не вышел.

![](https://habrastorage.org/webt/ow/t8/hv/owt8hvhbrxpvfxihc1golxlgp-y.png)

Результаты одного из тестов 12 раунда где fasthttp находится почти в самом верху. Цифры показывают сколько он делает запросов в секунду на данном тесте. В этом тесте делается запрос страничке, которая отдает hello world. На hello world fasthttp очень быстр.

![](https://habrastorage.org/webt/tk/h8/1t/tkh81tfzy0ee5jt0poqw_gxmv-e.png)

Предварительные результаты следующего раунда, который еще не вышел (в 2016 году), но 4 реализации fasthttp занимают первые места в бенчмарке, которые уже не только hello world отдает, но он еще и лезет в базу и формирует html-страничку на основе шаблона.

![](https://habrastorage.org/webt/lj/h1/ov/ljh1ovyrxst7hzjjgd16yk4tbmo.png)

Про fasthttp client мало кто знает. Но на самом деле тоже крутой. Я в данном докладе расскажу вам про внутреннее устройство fasthttp client и зачем он был разработан.

![](https://habrastorage.org/webt/z6/rp/az/z6rpazy3l_asbpcbaklgdo8mnkq.png)

На самом деле в fasthttp находится несколько клиентов: Client, HostClient и PipelineClient. Дальше я расскажу подробнее про каждого из них.

![](https://habrastorage.org/webt/vs/ok/5u/vsok5umamlhuly1-gcfdewuxybu.png)

Fasthttp.Client - это обычный http клиент общего назначения. С помощью него можно делать запросы любой на любой сайт интернета, получать ответы. Из фич его: быстро работает, у него можно ограничивать количество открытых подключений на каждый хост в отличие от net/http package. Документация находится на https://godoc.org/github.com/valyala/fasthttp#Client.

![](https://habrastorage.org/webt/r0/il/cc/r0ilcc3iwd6acpv1pqbawqxvfc4.png)

Fasthttp.HostClient - это специализированный клиент для общения с только одним сервером. Обычно его используют для обращения к HTTP API: REST API, JSON API. Также его можно использовать для проксирования трафика из интернета в внутренний DataCenter на несколько серверов. Документация находится здесь: https://godoc.org/github.com/valyala/fasthttp#HostClient. 

Так же как и Fasthttp.Client у Fasthttp.HostClient можно ограничивать количество открытых подключений на каждый из Backend серверов. Эта функциональность отсутствует в net/http и также эта фича отсутствует в бесплатном nginx. Эта функциональность есть только в платном nginx, насколько я знаю.

![](https://habrastorage.org/webt/sn/ys/ep/snysephpvj2u3itk5icip242ima.png)

Fasthttp.Pipeline - специализированный клиент, который позволяет управлять pipeline-запросами на сервер или на какое-то ограниченное количество серверов. Он может быть использован для обращения к API, поверх HTTP протокола, где нужно очень много выполнить запросов в единицу времени и как можно быстрее. Ограничение Fasthttp.Pipeline в том, что он может страдать от Head of Line blocking. Это когда мы отправляем на сервер много запросов и не ждем ответа на каждый запрос. Сервер на каком-то из этих запросов блокируется. Из-за этого все остальные запросы, которые за ним пошли, будут ждать пока этот сервер запрос не обработает. Fasthttp.Pipeline клиент нужно использовать только в том случае, если вы уверены что сервер будет моментально давать ответы на ваши запросы. Документация https://godoc.org/github.com/valyala/fasthttp#PipelineClient

![](https://habrastorage.org/webt/9b/sa/z2/9bsaz297eqozr0ckcwrlbmefdqk.png)

Теперь начну рассказывать про внутреннии реализации каждого из этих клиентов. Сначала начну с Fasthttp.HostClient, потому что на основе него построены почти все остальные клиенты.

![](https://habrastorage.org/webt/zm/vq/rt/zmvqrtpi1eogjgjqmlnvxbjh7ca.png)

Bот простейшая реализация HTTP клиента в псевдокоде на Go. Подключаемся, получаем http ответ по данному URL. Мы подключаемся к данному хосту. Получаем connection. В этом коде, чтобы он был меньше объёмом, все проверки на ошибки отсутствуют. На самом деле так нельзя. Всегда надо проверять ошибки. Cоздаем connection. Закрываем connection с помощью defer. Отправляем запрос на этот connection по URL. Получаем ответ, возвращаем этот ответ. Что не так с этой реализаций с HTTP Client?

![](https://habrastorage.org/webt/ev/lq/q4/evlqq4u3y3qbzr_agvrnmknzdee.png)

Первая проблема это то в этой реализации connection устанавливается на каждый запрос. Эта реализация не поддерживает HTTP KeepAlive. Как эту проблему решить? Можно использовать Сonnection Pool для каждого сервера. Нельзя использовать Сonnection Pool для всех серверов потому что следующий запрос непонятно на какой сервер отправлять. Для каждого сервера должен быть свой собственный Сonnection Pool. И используем HTTP KeepAlive. Это означает что в Header не надо указывать Сonnection Close. В HTTP/1.1 по умолчанию есть поддержка HTTP KeepAlive и Сonnection Close надо из header удалять. Вот реализация в псевокоде клиента с поддержкой Сonnection Pool. Есть набор нескольких Сonnection Pool до каждого хоста. Первая функция connPoolForHost возвращает Сonnection Pool для данного хоста из данного URL. Потом мы из-за этого Сonnection Pool достаем connection, планируем с помощью Defer отправку этого connection назад в Pool, отправляем KeepAlive запрос на этот connection, возвращаем response. После response выполняется Defer и connection возвращается в Pool. Таким образом у нас включается поддержка HTTP KeepAlive и все начинает работать быстрее. Потому что мы не теряем время на создание подключения на каждый запрос.

Но у решения тоже есть проблемы. Если посмотреть на сигнатуру функции, то видно что она возвращает на каждый запрос объект response. Это означает что под этот объект нужно каждый раз выделять память, инициализировать его и возвращать. Это плохо для performance. Может быть плохо, если таких вызовов функций Get у вас очень много. 

![](https://habrastorage.org/webt/jb/yq/rr/jbyqrrzhu_qusd9j9ocba8m0czk.png)

Поэтому эту проблему можно решить как вот она решена в Fasthttp путем помещения объекта указателя на объект response в параметры этой функции. Таким образом тот вызывающий код может переиспользовать этот объект response много раз. На слайде реализация данной идеи. В функцию Get передаем сюда на объект response и функция заполняет от response последняя строчка заполняет этот объект и responder 

![](https://habrastorage.org/webt/bm/z7/rq/bmz7rqtnowb5dreyup6c-er_tq0.png)

Вот как это как это может выглядеть в вашем коде. Функция, которая принимает channel, который передается список урлов, которые нужно опросить. Организуем цикл по этому channel. Создаем один раз объект response и в цикле его переиспользуем. Вызываем Get, передаем указатель на объект, процессим этот response. После того как мы обработали его сбрасываем его в первоначальное состояние. Таким образом мы избегаем выделение памяти и ускоряем наш код.

![](https://habrastorage.org/webt/ok/2t/5z/ok2t5zsghgoxj7ruc2z_1hhcagu.png)

Третья проблема это Сonnection close. Сonnection close - HTTP header, который может встречаться как в request так и в response. Если мы такой header получили, то этот Сonnection должен быть закрыт. Поэтому в реализации клиента нужно обязательно предусмотреть Сonnection close. Если вы отправили запрос с header Сonnection close, то после получения ответа нужно закрывать этот connection. Если вы отправили запрос без Сonnection close, а вам вернулся ответ с Сonnection close значит тоже нужно закрыть этот connection после получили ответ.

![](https://habrastorage.org/webt/bc/ve/up/bcveuplhhdifuc0malg7f7bm2vw.png)

Вот псевдокод этой реализации. После того как вы получили ответ, проверяем установлены ли там Сonnection close header. Если установлен, просто закрываем connection. Если не установлен возвращаем его обратно в pool. Если этого не сделать, то если сервер будет закрывать connection после того как возвращает ответы, то у вас connection pool будет содержать поломанные connection, которые сервер закрыл, а вы в них будете пытаться что-то записать и вас будут сыпаться ошибки. 

![](https://habrastorage.org/webt/wi/ms/gh/wimsghjdbpnjilbkgmvw5cryrvg.png)

Четвертая проблема, которые подвержены подвержены HTTP клиенты это медленные сервера, либо медленная, нерабочая сеть. Сервера могут переставать отвечать на ваши запросы по разным причинам. Например, сервер сломался либо сеть между вашим клиентом и сервером  перестала работать. Из-за этого все ваши горутины, которые вызывают Get функцию, которая перед всем было описана, будут блокироваться, ждать ответа от сервера бесконечно долго. Например, вы реализуете http прокси, который принимает входящее подключение и на каждоение подключение вызывает функцию Get, то будут создаваться большое количество горутин и они все будут висеть вашем сервере пока сервер не рухнет, пока память не закончится.

![](https://habrastorage.org/webt/cb/mq/1c/cbmq1c_b9ua-0ess-if8dfqkk0a.png)

Как эту проблему решить? Есть такое наивное решение, которое впервые приходит на ум - просто завернуть этот Get в отдельную горутину. Потом в горутину передать пустой channel, который будет закрыт после того как выполнится Get. После запуска этой горутины ждать на этом channel какое-то время (таймаут). В данном случае, если у вас пройдёт какое-то время и этот Get не выполнился, то выход из этой функции произойдет таймауту. Если выполнился этот Get, значит закроется channel и произойдет выход. Но это решение неправильное, потому что оно переносит проблему из больной головы на здоровую. Все равно горутины будут создаваться и висеть независимо от того какой у вас таймаут используется. Количество горутин, которые вызвали Get таймаут будет ограничено, но зато будет неограниченное количество горутин, которые будут создаваться внутри Get с таймаутом.

![](https://habrastorage.org/webt/yx/jx/nj/yxjxnjpdobdntdoel9119aqdgyo.png)

Как эту проблему решить? Есть первое решение - это ограничить количество заблокированных горутин в функции Get. Это можно сделать с помощью такого известного паттерна как использовать буферизованный channel ограниченный длины, который будет считать количество горутин, исполняющих функцию Get. Если это количество горутин превышает какой-то предел - капасити этого channel, то мы выйдем в default ветку. Это означает что у нас все горутины, который выполняет Get заняты и в дефолт ветке просто надо возвращать Error что нет свободных ресурсов. Перед тем как мы создаем горутину, мы пытаемся записать в этот channel какую-то пустую структуру. Если это не получается, значит у нас количество горутин превышено. Если получилось, значит создаем эту горутину и после того как Get выполнился читаем из этого channel одно значение. Таким образом мы ограничиваем количество горутин, которые могут быть заблокированы в Get. 

![](https://habrastorage.org/webt/w4/id/rr/w4idrrvfykc05ahmf_hrbyscwcs.png)

Второе решение, которое дополняет первое - это выставлять таймауты на connection к серверу. Это будет разблокировать функцию get, если сервер долго не отвечает либо сеть не работает. 

Если сеть не работает в Solution #1, то у нас все зависнет. После того как мы набрали cuncurrency ограниченное количество горутин, которые тут зависли, функция getimeout всегда будет возвращать ошибку. Чтобы она начала нормально работать, нужно второе решение (Solution #2), которое выставляет таймаут на чтение и запись из connection. Это помогает разблокировать заблокированые горутины, если сеть или сервер перестают работать.

![](https://habrastorage.org/webt/yx/jx/nj/yxjxnjpdobdntdoel9119aqdgyo.png)

В Solution #1 есть data race. Объект response, у которого передали указатель, будет занят, если у нас Get заблокировался. Но эта функция Get таймаут может выйти по таймауту. В данном случае мы выходим с этой функции, a response этот может быть будет висеть и через какое-то время перезапишется. Таким образом получается data race. Так как у нас response после выхода из функции еще где-то используется в горутине.

Решается проблема созданием response копии и передача response копию в горутину. После того как Get выполнился, копируем из этой response копии response в наш оригинальный response, который сюда передан. Таким образом data race решается. Эта копия response живет короткое время и возвращается обратно в pool. Мы переиспользуем response. Копия response может не поместится в pool только по таймауту. По таймауту происходит потеря response используя из pool. 

а что там вопрос это был еще после тайм-аут они идут вот потому что то опять превратится в до trace то есть этот response копи он завис здесь мы его и положили вот после time out of pool после после этого кто там в следующий раз вызывал get поймал а вот здесь вот так продажи пещера если его положить в пул то функции возвращается и потом этот тот кто вызвал эту функцию этот response опять будет и переиспользовать пытаться а он уже в пуле лежит и кто-то другой выдается гитой мод и и вы достанете его из пол и опять будет использовать дата раз получается

![](https://habrastorage.org/webt/dc/cr/rg/dccrrgzr0n01izqnk3hjpoekwv4.png)

такой вопрос интересную возник во время использования htp клиента для обращения копить сервером которая могли долго отвечать нужно ли закрывать connection после того как у вас есть какой то этот ограниченное время на запрос истечении этого времени запрос сервер не вернул ответ нужно ли закрывать connection после этого того как сервер не вернул ответ в течение 2 тайм аута ответ нет верней эт да если вы хотите забросить сервера ваш почему потому что закрытие смотрите вы отправляете connect запрос на сервер ждет истечении кого-то времени сервер в течение то время не отвечать не справляется запрос например вы закрываете connection но это не означает что сервер сразу же прекратить выполнение этого запроса на его продолжит выполняется он обнаружит что это запрос не нужно упрощать поставок это попытается за от вернуть ответ вам вы закрыли connection попытались снова создать новый опять стает прошел опять закрыли конечно создали новый то есть у вас и это все будет нагрузка на сервер повышаться повышаться повышаться и в итоге ваш сервис заботиться об этих ваших запрос энтони sync вот это ещё хуже это даст на уровне http-запрос нести это на уровне и т.п. поэтому чтобы если у вас такие китай с сервера которым обращайтесь который медленно работает и вы не хотите их задать то не нужно закрывать connection после поймал это нужно подождать какое-то время пустят но оставьте connection на искупление этому серверу пусть он попытается вернуть вам ответ а в это время использовать и другие конечно свободную и таким образом до сервера на предотвращается все что рассказывал до этого это все но какую-то этапы реализации пастор степи клиента который проблемы которые возникали во время реализацию его и которая решены по степи hotpoint 

![](https://habrastorage.org/webt/sc/cm/ar/sccmar-ze8kukg1nm5csyxz2riy.png)

что у нас теперь получился быстрый клиент типа не совсем надо посмотреть что у нас в к нашим пуля как релиз реализован connection pool 

![](https://habrastorage.org/webt/ht/yz/uj/htyzujg6gqaycezv_ot4_xucb6w.png)

наивная реализация к началу пула выглядит так есть какой-то адрес сервера куда нужно устанавливать connection и есть список свободных connection of блокировка для того чтобы для синхронизации обращение доступа к этому списку

![](https://habrastorage.org/webt/tk/rs/1u/tkrs1uhjy3nlqecg_j2payseg_i.png)

![](https://habrastorage.org/webt/zb/lk/j5/zblkj5q4hygyxgd9rmrzjx2nxpa.png)

вот фунт доступ получения на кашина из connection pool а мы смотрим пуст список наших collection of если там что то есть то достаем свободный connection и возвращаем его если ничего нет то создаем новое подключение к этому серверу и возвращаем его что же здесь не так 



![](https://habrastorage.org/webt/lw/xz/7q/lwxz7qmhwkqv3tmu4mc5f0tfumi.png)

а путь вот тут назад колодец connection свободы к конусу добавляет вторых там его не это обнаружится потом на при следующем доступе к этому connection у и потом за конечно уже вы единица достигал да да да насчет тайм-аут а потом дальше расскажу в fastapic клиенте есть максимально можно указывать максимальное время жизни и connection а открытого неиспользуемого и после того как это время прошло не используем и конечно закрываются автоматически выкидываются до топа да да он долго висит ну так вот все которые постарше они получаются становится неиспользуемыми в течение времени и автоматически удаляются от туда из пула ну закрываются ну как в ходе реализации реализован да он закрыт до добывают так и ну и такая штука обрабатывается ну как есть обработка там хвоста шипит такой штуки если при ну когда берется конечно из пула который оказался что его северус закрыл и выплата ли что-то записать то производится повторная попытка достается новый collection и пытается снова запросы поэтому conduction но это только в том случае если данный запрос идет один патент называется то есть это запрос который может быть выполнен много раз без побочных эффектов на сервере то есть это get запрос и ну то есть например вот http стандартном т.к. g там только сейчас тоже ну там этой проверки раньше не было сейчас только добавили проверку на закрытой connection и и ну там типа более хитрую сделали немного может быть я форсаж теперь тоже так и сделают они проверяют но когда пытаются управлять новый запрос в connection из пула проверяют отправился ли вообще хотя бы один байт в этот connection если отправился значит тогда уже все ну типа возвращаем если не отправился значит берем новый connection is полу если посчитать что типа конечно закрыт он может новый переиспользовать нобель даже для ни один патент запросов потому что ничего не отправили все тишь но пасторстве пока такого нет

![](https://habrastorage.org/webt/h2/ug/yv/h2ugyvjrfzht7gfwx2gemetfazy.png)

так что там с пулом к ночным пулом не так его размер не ограничен это как от фанатов цепь еще с реализация стандарта стандартным низации которых гол клиента если у вас вы напишете клиент который ломится там с миллионов гарате на сервер медленны то у вас создаст но попытаться создать миллион кексов на этот сервер ну то есть не то там ограничение на максимальное количество connections не за может быть уже в 18 добавить пока не было как как в этот как в этой реализации то есть для клеро boost клиента которые ну можно использовать для обращений к api по степи желательно ограничить размер этого connection pool а иначе как я еще раз говорю как я уже говорил ваши клиенты могут быть задач типа уйти в даун потому что у вас будет использую зря ресурс эти потоки ты объекты connection а в гору синай и память и также это может привести доступ ваших серверов так как на них будет установлен на очень много collection of которые либо не используется либо используются неэффективно потому что сервер стойка collection of не может держать 

![](https://habrastorage.org/webt/km/zk/pn/kmzkpnls98apnqltus4tvoeeb5c.png)

ограничиваем connection pool часть кода здесь нет потому что он слишком большой для того чтобы поместиться на один слайд для желающие могут посмотреть реализацию этой функции на гитхабе 

![](https://habrastorage.org/webt/ub/1a/ko/ub1akoqexz4yoqyn3xogkcwveza.png)

вторая проблема это то что неиспользуемая посмотрите вас зачастую встречается такой паттерн когда на клиент приходит какой-то момент времени очень много запросов одновременных а после этого происходит спад и возвращать возврат к предыдущему количество запросов там за какой-то момент элементом пришло одновременно 10000 запросы потом вернулся к 1000 запросов после такого вот спайка connection pool вырастет там до 10000 collection of и reconnection и будут висеть там бесконечно в теоретически как как принципе это в стандартном это штапик like клиенте было до версии 1 7 и поэтому нужно решать эту проблему 

![](https://habrastorage.org/webt/dm/o1/w4/dmo1w4jixcnjjjaoznw8r7zz8bw.png)

эта проблема решается путем ограничения жизни не использовал конечно то есть если конечно через конечно течение какого то времени не было отправлено ни одного запроса то он просто закрывается и выкидывается из пула и реализация тоже отсутствует то что она слишком большая нужно посмотреть тут вот

![](https://habrastorage.org/webt/hs/wj/wx/hswjwxgrlyawxzj_t-mmdbxhh3m.png)

ну что значит мы получили клиент который работает быстро и классно не совсем так у нас там ещё осталась функция создание connection отдел хост 

![](https://habrastorage.org/webt/cl/bs/jr/clbsjrbour6diwgkjri6jpdhnx8.png)

посмотрим на ее реализацию наивная реализация выглядит так просто вот вам передается это адрес куда нужно подключиться мы вызываем стандарту full сумел взял она возвращает код connection и возвращает возвращаем его из этой функции что не так в этой реализации

![](https://habrastorage.org/webt/sm/b_/bc/smb_bcj41taldeo3mvnfl9ek-2g.png)

то что не взял по умолчанию делает dns запрос на каждый вызов и это может быть привести к повышенному использованию ресурсов вашего систем dns и и вашего сервера как это обычно происходит в api клиентах если они подключаются к серверам которые не поддержит keep-alive соединения они закрывают соединение то есть вы поддерживается сервера не поддержат и каждый раз на каждый ответ после такого ответа закрывают соединение получается вас нет дела называется на каждый запрос из таких запросов там идет 10 тысяч в секунду то у вас 10000 секунду идет резал в dns и это нагружает подсистема dns и все процессор на время будет уходить туда 

![](https://habrastorage.org/webt/2j/au/e6/2jaue6kkmfwaob6p9tu-5quhgei.png)

как эту проблему решить зависти к которым и пит хост в и фишки на короткое время прямо в вашем гул коде и не вызывать dns resolving на каждый взял конектится к фишкам уже готовым реализация здесь массаж т.п.

![](https://habrastorage.org/webt/eh/n2/j3/ehn2j3tfuse-43qoibyq5oqqcsu.png)

вторая проблема это неравномерная нагрузка на сервера если вас назад dns именем доменом спрятана несколько филеров примерно как round robin dns в если использовать в лоб это вот решение типа caching афишировать там одну спичку только там произвольную да там на какой промежуток времени то в течение этого промежутка времени у вас все запрос все конечно будут уходить на один сервер хотя он прямо вас может быть там их несколько и нужно решать эту проблему решается на путем перебора всех доступных айпи шик которые спрятаны за данным доменным именем это также делается в фас htp клиенте

![](https://habrastorage.org/webt/wx/hb/6r/wxhb6r3hlt_wofv6o347jyvw_oo.png)

третья проблема то что взял также может зависнуть на неопределенное время из-за проблем с сетью либо сервером куда тайцы подключиться про эту проблему рассказывает тогда в этом случае ваши картины будет зависать на get этом функции и это тоже может приводить к повышенным использованию ресурсов



![](https://habrastorage.org/webt/jc/k3/id/jck3idzikb6vyzvsbcuckeg8wae.png)решение без добавить поймала the deal хост тут реализация либо использовать мпк чинит также если типа deal стоял там но насколько я знаю он реализован неправильно мы бы сейчас уже его исправили но раньше он был реализован вот так как я рассказывал сейчас покажу вот так вот был реализован нет вот так ну то есть будут взял функция место get была она выполнялась какой-то к рутине и количество вот то есть если водил зависал то у нас получалось что гарантия на пылесос вот тут вот в этом взял на этой строчке и количество таких грузин который тут зависли оно могло расти бесконечно но это стандартная реализация dell тайм аут не знаю может сейчас уже исправили на смотреть

![](https://habrastorage.org/webt/jo/tn/t0/jotnt0t9nwul2jx8sym4-kycfvu.png)

также ну я рассказал про основные проблемы с которыми пришлось столкнуться и лишить во время разработки вас клиента и которая частично присутствует стандартной реализации на этаж степи клайн то кроме этого hotline умеет следующая фича делать он умеет распределять нагрузку на список серверов которые вы указали там пускай on the door то можно не один адрес указывается несколько и таким образом реализовываться типа примитивный лад балансовых также он умеет пропускать нерабочие посты сервера то есть если у вас например есть несколько серверов и в какой то момент времени некоторые перестают работать the host kline но при при попытке обращения к этому серверу обнаружит и connection еще раз он типа запомнить этой и попытать но не не будет обращаться к этому серого пропускать будет его таким образом реализовано цыпа такая балансировка нагрузки не вы не теряйте минимальное количество запросов если там когда сервис упал я не помню там смотри файл host имел другой флаг сходство может быть по двум причинам первая причина это мы к нему не можем deal установить за там зависли на диомида в этом случае получается мы зависли на этом деле и get который завис это ли он будет ждать там какое-то время пока он ждет в это время сизо все остальные запросы будут идти на других от стыда то есть пропускаться будет таким образом все остальные хосты через остальные кости будут находить больше запросов и зачем через этот и второй вариант это когда сервер например начинают медленно отвечать но тут такая же штука получается то есть он в гетто за весну проводят больше времени чем остальные сервера и в этом случае количество запросов отравлен это сервер по становится меньше на остальные сервера а если просто развернулся тогда идет попытка там дробины подключение к следующему сервера то есть и поддержка ну там поддержка social очень легко делается так в голову очень классную реализация ее удобно использовать подключать своим решением

![](https://habrastorage.org/webt/py/wf/93/pywf93cfwemlknabq_iejxfgpt4.png)

так теперь мы переходим к fast htp клиенту на самом деле тут все намного проще построим сост кантом так как фарш пик lines реализован на основе host club 

![](https://habrastorage.org/webt/0s/f8/mz/0sf8mzfxpk1nl5lucgjvwaqkgy8.png)

вот примитивная псевдо-код для реализации клиента функция get мы просто выбираем у нас есть список хост клиентов для каждого известного хоста и вот эта функция возвращает просто нужных условий для данного поставив данного угла и потом и в этом классе вызываемую функцию get вот вся реализация клиента на оставив уст клайд вот такая базовая ну что тут надо упомянуть то что вкус клиент вот эта функция она может из создавать новые хувс клиенты для каких-то хвостов но которые появляются у нас в руле новое если ну и и реализовалась в лоб то и пример для использовать для веб crawling ну типа лазания по интернету ваш клиент может там к миллионам сайтом разным обратиться то в итоге у вас получится миллион этих хвост клиентов до каждого сайта и сыпались закончится чтобы этого не происходило от это именно так до недавнего времени была наташа рекламе со стандартным может быть сейчас уже решили проблему это чтобы это не происходило нужно периодически чистить тихо sqlite и которым не было давно обращение так поступает http 

![](https://habrastorage.org/webt/xd/nf/u8/xdnfu88duh8s5ibm0qx_riwe4go.png)

реализация здесь 

![](https://habrastorage.org/webt/r2/f7/bk/r2f7bkykq6m6oqcd3ylss9rwdr4.png)

теперь пару слов о по pipeline клэнси в отличие от клиента и хост клиента у него реализация немного другая там нету connection pool of так как pipeline клинтон пытается у него есть опция количество connection of которым нужно становиться на хвост и он будет он пытается пропихнуть все запросы через это количество конечно ограничены faith лайн режиме поэтому там нет никаких пулов он сразу становитесь connection и и распихивают входящие запросы во все таки доступное connection 

![](https://habrastorage.org/webt/lj/vw/ew/ljvwewxdpm8ag50y-tcfzthrxia.png)

реализован он как у него есть для каждого connection 2 грузию запускается райтер который пишет запрос и просто выйдут connection между не ожидая ответа от них и reader который считает ответа из этого connection а и сопоставляет их с запросами которые были отправлены через райдер и возвращает ответ функцию который коду которая вызывает функцию get

![](https://habrastorage.org/webt/nj/9q/lp/nj9qlpw3mexynplnky52vvhcar4.png)

вот примерная реализация функция get для pipeline клиента у нас есть такая структура pipeline work называется в ней есть суру которую нужно обратиться есть указатель на response а есть член алдан которая типа сигнала сигнализируя о том что у нас готов response можно забрать все вот реализация get создаем эту структуру заполняем и и отправляем ее членов который читается pipeline клайн прайтером и пишется все запросы в connection и ожидаем на вот этой вот финале дан который закрывается pipeline ридером когда пришел response для этого request а 

![](https://habrastorage.org/webt/s4/vf/oq/s4vfoqg_mmutotfdw66gs4nbxvs.png)

ну все пора заканчивать пиф у нас сравнение производительности наташ цепи клиента htp клиента у нас вечер 2 слайдах 

![](https://habrastorage.org/webt/ah/ra/-o/ahra-oaf0uydcje9yqofoh6l-6k.png)

вот бенчмаркинг соответствующие которые показаны на этих слайдах они присутствуют в степи вы можете их сами себя запускать проверять тестировать вот результаты для пассаж степи этих бенчмарков видно что остановить как одна из главных фишек массаж степи что он не выделяет память вообще часто выполняемом коде вот тут это видно что у него типа 0 allocation of на операцию было везде и вот время выполнения каждого из этих тестов вот заметьте какой здесь 

![](https://habrastorage.org/webt/q6/c3/ss/q6c3ss7kpmkwwlxk01o_ffyqhs0.png)

а теперь переключаемся на нет http соответствующая бенчмарки сравниваем циферки вот смогла коченов на каждое из этих итерации над htp и вот производительность сравниваем еще раз ну там если до 10 раз как я говорил там вот тут вот вот в этом тесте 554 100 наносекунд а cs50 2000 почти десять раз медленнее вот тут тут 25103 800 меньше чем десять раз ну тоже прилично 

![](https://habrastorage.org/webt/jm/fh/sg/jmfhsgqsqoiwblgnfsliiytqauw.png)

все к так нет сейчас я еще раз повторю вопрос за

когда pipeline клиент остановится записи запросов в конечном

у него есть там опция количество пинзеник запросов которые на тебя запросто которая еще не вернулись ответы это настройках можно настроить и вот сам пытается записать количество запросов да типа если ну и если пришел новые риски request а у нас это вот достигла это количество максимальных запросов которые мы отправили но еще не получили ответ то возвращаем ее рашку ночью то что не смогли записать запрос этот 



да нет ни опера слышал об этом но а на должность каким причинам они выпиливает да в принципе нормально решение да нет не совместимо почему не совместим объясняя потому что стандарт формат структур в стандартном этот меня тоже степи он не оптимизируем по потреблению памяти то есть там в структурах есть указатели на кита другие структуры есть там стринги какие-то которые но стринги вообще нельзя переиспользовать в ну как вы значит но до неё минут обильны и в итоге этот формат скульптур которая в стандартном это степи они ограничивают перри использования памяти итоге там по-любому нужно выделять память для того чтобы заполнить эти структуры в фаст htp все структуры сделано таким образом чтобы можно было переиспользовать память поэтому они не совместил еще раз нет не будут нет там просто отличия существенная на этаж цепи клиента от пассаж типе в том что помощи наташа типе клиента можно легче можно стрелять но типа отправлять и потом просто здоровенная дали бы принимать здоровенные респон же типа стрима текла из файла фас htp дизайн так сделал что терри квесты и рис пользы они все в памяти хранятся и поэтому там нельзя брутом здесь и гигабайт и request отправиться либо такой же здравии no response ну то есть это пока сейчас нельзя но может быть будущем почему нельзя потому что нам в компании это не надо было ну то есть у нас в основном используется там запросы и ответы там пограничная длинный да там там максимуму там сотни килобайт не больше поэтому если вам вам нужно гонять там в этих запросов ответа какие-то здоровенные базе то лучше используйте стандартную наши степи все равно там бостона время уйдет на передачу этих у центральной базе и там то что там фас ажиотаж цепи выделяет память о но они как даже не будет заметно
