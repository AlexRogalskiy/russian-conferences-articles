Я Александр Валялкин. Работаю в компании VertaMedia. Я для наших нужд разработал fasthttp, который включает себя реализацию http клиента и http сервера. Fasthttp работает намного быстрее чем net/http из стандартных пакетов Go.![](https://habrastorage.org/webt/mw/xn/qb/mwxnqbi-ufmc9agmni-so-gy-ls.png)

Fasthttp - это быстрая реализация http сервера и клиента. Находится fasthttp на github.com

![](https://habrastorage.org/webt/ve/vz/07/vevz07ucp1l6ou4pg8zp2kuhvzu.png)

Я думаю что многие слышали про fasthttp server, что он очень быстрый. Но мало кто слышал про fasthttp client. Fasthttp server участвует в бенчмарке от techempower - известный benchmark в узких кругах для http серверов. Fasthttp server участвует в 12 и 13 раундах. 13 раунд еще не вышел.

![](https://habrastorage.org/webt/ow/t8/hv/owt8hvhbrxpvfxihc1golxlgp-y.png)

Результаты одного из тестов 12 раунда где fasthttp находится почти в самом верху. Цифры показывают сколько он делает запросов в секунду на данном тесте. В этом тесте делается запрос страничке, которая отдает hello world. На hello world fasthttp очень быстр.

![](https://habrastorage.org/webt/tk/h8/1t/tkh81tfzy0ee5jt0poqw_gxmv-e.png)

Предварительные результаты следующего раунда, который еще не вышел (в 2016 году), но 4 реализации fasthttp занимают первые места в бенчмарке, которые уже не только hello world отдает, но он еще и лезет в базу и формирует html-страничку на основе шаблона.

![](https://habrastorage.org/webt/lj/h1/ov/ljh1ovyrxst7hzjjgd16yk4tbmo.png)

Про fasthttp client мало кто знает. Но на самом деле тоже крутой. Я в данном докладе расскажу вам про внутреннее устройство fasthttp client и зачем он был разработан.

![](https://habrastorage.org/webt/z6/rp/az/z6rpazy3l_asbpcbaklgdo8mnkq.png)

На самом деле в fasthttp находится несколько клиентов: Client, HostClient и PipelineClient. Дальше я расскажу подробнее про каждого из них.

![](https://habrastorage.org/webt/vs/ok/5u/vsok5umamlhuly1-gcfdewuxybu.png)

Fasthttp.Client - это обычный http клиент общего назначения. С помощью него можно делать запросы любой на любой сайт интернета, получать ответы. Из фич его: быстро работает, у него можно ограничивать количество открытых подключений на каждый хост в отличие от net/http package. Документация находится на https://godoc.org/github.com/valyala/fasthttp#Client.

![](https://habrastorage.org/webt/r0/il/cc/r0ilcc3iwd6acpv1pqbawqxvfc4.png)

Fasthttp.HostClient - это специализированный клиент для общения с только одним сервером. Обычно его используют для обращения к HTTP API: REST API, JSON API. Также его можно использовать для проксирования трафика из интернета в внутренний DataCenter на несколько серверов. Документация находится здесь: https://godoc.org/github.com/valyala/fasthttp#HostClient. 

Так же как и Fasthttp.Client у Fasthttp.HostClient можно ограничивать количество открытых подключений на каждый из Backend серверов. Эта функциональность отсутствует в net/http и также эта фича отсутствует в бесплатном nginx. Эта функциональность есть только в платном nginx, насколько я знаю.

![](https://habrastorage.org/webt/sn/ys/ep/snysephpvj2u3itk5icip242ima.png)

Fasthttp.Pipeline - специализированный клиент, который позволяет управлять pipeline-запросами на сервер или на какое-то ограниченное количество серверов. Он может быть использован для обращения к API, поверх HTTP протокола, где нужно очень много выполнить запросов в единицу времени и как можно быстрее. Ограничение Fasthttp.Pipeline в том, что он может страдать от Head of Line blocking. Это когда мы отправляем на сервер много запросов и не ждем ответа на каждый запрос. Сервер на каком-то из этих запросов блокируется. Из-за этого все остальные запросы, которые за ним пошли, будут ждать пока этот сервер запрос не обработает. Fasthttp.Pipeline клиент нужно использовать только в том случае, если вы уверены что сервер будет моментально давать ответы на ваши запросы. Документация https://godoc.org/github.com/valyala/fasthttp#PipelineClient

![](https://habrastorage.org/webt/9b/sa/z2/9bsaz297eqozr0ckcwrlbmefdqk.png)

Теперь начну рассказывать про внутреннии реализации каждого из этих клиентов. Сначала начну с Fasthttp.HostClient, потому что на основе него построены почти все остальные клиенты.

![](https://habrastorage.org/webt/zm/vq/rt/zmvqrtpi1eogjgjqmlnvxbjh7ca.png)

Bот простейшая реализация HTTP клиента в псевдокоде на Go. Подключаемся, получаем http ответ по данному URL. Мы подключаемся к данному хосту. Получаем connection. В этом коде, чтобы он был меньше объёмом, все проверки на ошибки отсутствуют. На самом деле так нельзя. Всегда надо проверять ошибки. Cоздаем connection. Закрываем connection с помощью defer. Отправляем запрос на этот connection по URL. Получаем ответ, возвращаем этот ответ. Что не так с этой реализаций с HTTP Client?

![](https://habrastorage.org/webt/ev/lq/q4/evlqq4u3y3qbzr_agvrnmknzdee.png)

Первая проблема это то в этой реализации connection устанавливается на каждый запрос. Эта реализация не поддерживает HTTP KeepAlive. Как эту проблему решить? Можно использовать Сonnection Pool для каждого сервера. Нельзя использовать Сonnection Pool для всех серверов потому что следующий запрос непонятно на какой сервер отправлять. Для каждого сервера должен быть свой собственный Сonnection Pool. И используем HTTP KeepAlive. Это означает что в Header не надо указывать Сonnection Close. В HTTP/1.1 по умолчанию есть поддержка HTTP KeepAlive и Сonnection Close надо из header удалять. Вот реализация в псевокоде клиента с поддержкой Сonnection Pool. Есть набор нескольких Сonnection Pool до каждого хоста. Первая функция connPoolForHost возвращает Сonnection Pool для данного хоста из данного URL. Потом мы из-за этого Сonnection Pool достаем connection, планируем с помощью Defer отправку этого connection назад в Pool, отправляем KeepAlive запрос на этот connection, возвращаем response. После response выполняется Defer и connection возвращается в Pool. Таким образом у нас включается поддержка HTTP KeepAlive и все начинает работать быстрее. Потому что мы не теряем время на создание подключения на каждый запрос.

Но у решения тоже есть проблемы. Если посмотреть на сигнатуру функции, то видно что она возвращает на каждый запрос объект response. Это означает что под этот объект нужно каждый раз выделять память, инициализировать его и возвращать. Это плохо для performance. Может быть плохо, если таких вызовов функций Get у вас очень много. 

![](https://habrastorage.org/webt/jb/yq/rr/jbyqrrzhu_qusd9j9ocba8m0czk.png)

Поэтому эту проблему можно решить как вот она решена в Fasthttp путем помещения объекта указателя на объект response в параметры этой функции. Таким образом тот вызывающий код может переиспользовать этот объект response много раз. На слайде реализация данной идеи. В функцию Get передаем сюда на объект response и функция заполняет от response последняя строчка заполняет этот объект и responder 

![](https://habrastorage.org/webt/bm/z7/rq/bmz7rqtnowb5dreyup6c-er_tq0.png)

Вот как это как это может выглядеть в вашем коде. Функция, которая принимает channel, который передается список урлов, которые нужно опросить. Организуем цикл по этому channel. Создаем один раз объект response и в цикле его переиспользуем. Вызываем Get, передаем указатель на объект, процессим этот response. После того как мы обработали его сбрасываем его в первоначальное состояние. Таким образом мы избегаем выделение памяти и ускоряем наш код.

![](https://habrastorage.org/webt/ok/2t/5z/ok2t5zsghgoxj7ruc2z_1hhcagu.png)

Третья проблема это Сonnection close. Сonnection close - HTTP header, который может встречаться как в request так и в response. Если мы такой header получили, то этот Сonnection должен быть закрыт. Поэтому в реализации клиента нужно обязательно предусмотреть Сonnection close. Если вы отправили запрос с header Сonnection close, то после получения ответа нужно закрывать этот connection. Если вы отправили запрос без Сonnection close, а вам вернулся ответ с Сonnection close значит тоже нужно закрыть этот connection после получили ответ.

![](https://habrastorage.org/webt/bc/ve/up/bcveuplhhdifuc0malg7f7bm2vw.png)

Вот псевдокод этой реализации. После того как вы получили ответ, проверяем установлены ли там Сonnection close header. Если установлен, просто закрываем connection. Если не установлен возвращаем его обратно в pool. Если этого не сделать, то если сервер будет закрывать connection после того как возвращает ответы, то у вас connection pool будет содержать поломанные connection, которые сервер закрыл, а вы в них будете пытаться что-то записать и вас будут сыпаться ошибки. 

![](https://habrastorage.org/webt/wi/ms/gh/wimsghjdbpnjilbkgmvw5cryrvg.png)

Четвертая проблема, которые подвержены подвержены HTTP клиенты это медленные сервера, либо медленная, нерабочая сеть. Сервера могут переставать отвечать на ваши запросы по разным причинам. Например, сервер сломался либо сеть между вашим клиентом и сервером  перестала работать. Из-за этого все ваши горутины, которые вызывают Get функцию, которая перед всем было описана, будут блокироваться, ждать ответа от сервера бесконечно долго. Например, вы реализуете http прокси, который принимает входящее подключение и на каждоение подключение вызывает функцию Get, то будут создаваться большое количество горутин и они все будут висеть вашем сервере пока сервер не рухнет, пока память не закончится.

![](https://habrastorage.org/webt/cb/mq/1c/cbmq1c_b9ua-0ess-if8dfqkk0a.png)

Как эту проблему решить? Есть такое наивное решение, которое впервые приходит на ум - просто завернуть этот Get в отдельную горутину. Потом в горутину передать пустой channel, который будет закрыт после того как выполнится Get. После запуска этой горутины ждать на этом channel какое-то время (таймаут). В данном случае, если у вас пройдёт какое-то время и этот Get не выполнился, то выход из этой функции произойдет таймауту. Если выполнился этот Get, значит закроется channel и произойдет выход. Но это решение неправильное, потому что оно переносит проблему из больной головы на здоровую. Все равно горутины будут создаваться и висеть независимо от того какой у вас таймаут используется. Количество горутин, которые вызвали Get таймаут будет ограничено, но зато будет неограниченное количество горутин, которые будут создаваться внутри Get с таймаутом.

![](https://habrastorage.org/webt/yx/jx/nj/yxjxnjpdobdntdoel9119aqdgyo.png)

Как эту проблему решить? Есть первое решение - это ограничить количество заблокированных горутин в функции Get. Это можно сделать с помощью такого известного паттерна как использовать буферизованный channel ограниченный длины, который будет считать количество горутин, исполняющих функцию Get. Если это количество горутин превышает какой-то предел - капасити этого channel, то мы выйдем в default ветку. Это означает что у нас все горутины, который выполняет Get заняты и в дефолт ветке просто надо возвращать Error что нет свободных ресурсов. Перед тем как мы создаем горутину, мы пытаемся записать в этот channel какую-то пустую структуру. Если это не получается, значит у нас количество горутин превышено. Если получилось, значит создаем эту горутину и после того как Get выполнился читаем из этого channel одно значение. Таким образом мы ограничиваем количество горутин, которые могут быть заблокированы в Get. 

![](https://habrastorage.org/webt/w4/id/rr/w4idrrvfykc05ahmf_hrbyscwcs.png)

Второе решение, которое дополняет первое - это выставлять таймауты на connection к серверу. Это будет разблокировать функцию get, если сервер долго не отвечает либо сеть не работает. 

Если сеть не работает в Solution #1, то у нас все зависнет. После того как мы набрали cuncurrency ограниченное количество горутин, которые тут зависли, функция getimeout всегда будет возвращать ошибку. Чтобы она начала нормально работать, нужно второе решение (Solution #2), которое выставляет таймаут на чтение и запись из connection. Это помогает разблокировать заблокированые горутины, если сеть или сервер перестают работать.

![](https://habrastorage.org/webt/yx/jx/nj/yxjxnjpdobdntdoel9119aqdgyo.png)

В Solution #1 есть data race. Объект response, у которого передали указатель, будет занят, если у нас Get заблокировался. Но эта функция Get таймаут может выйти по таймауту. В данном случае мы выходим с этой функции, a response этот может быть будет висеть и через какое-то время перезапишется. Таким образом получается data race. Так как у нас response после выхода из функции еще где-то используется в горутине.

Решается проблема созданием response копии и передача response копию в горутину. После того как Get выполнился, копируем из этой response копии response в наш оригинальный response, который сюда передан. Таким образом data race решается. Эта копия response живет короткое время и возвращается обратно в pool. Мы переиспользуем response. Копия response может не поместится в pool только по таймауту. По таймауту происходит потеря response используя из pool. 

![](https://habrastorage.org/webt/sc/cm/ar/sccmar-ze8kukg1nm5csyxz2riy.png)

Нужно ли закрывать connection на запрос по истечению ограниченного времени? Запрос сервер не вернул ответ. Нужно ли закрывать connection после того как сервер не вернул ответ в течение таймаута? Ответ нет. Вернее да, если вы хотите заDoSсить сервер. Потому что, когда вы отправляете запрос на сервер, ждете в течение кого-то времени, сервер в течение этого времени не отвечает - не справляется с запросами. Например, вы закрываете этот connection, но это не означает что сервер сразу же прекратит выполнение этого запроса. Сервер  продолжит его выполнение. Сервер обнаружит что это запрос не нужно выполнять после того как попытается вам вернуть ответ. Вы закрыли connection, попытались снова создать новый запрос, опять таймаут прошел, опять закрыли, создали новый запрос. У вас будет нагрузка на сервер повышаться. В итоге ваш сервис заDoSится от ваших запросах. Это DoS на уровне http-запросов. Если у вас сервера, которые медленно работает, и вы хотите их заDoSить, то не нужно закрывать connection после таймаута. Нужно подождать какое-то время, оставить connection на искупление этому серверу. Пусть он попытается вернуть вам ответ. А в это время использовать другие свободные connection. Все что рассказывал до этого, это все этапы реализации Fasthttp.Client и проблемы, которые возникали во время реализации Fasthttp.Client.  Эти проблемы решены в Fasthttp.HostClient.

![](https://habrastorage.org/webt/ht/yz/uj/htyzujg6gqaycezv_ot4_xucb6w.png)У нас теперь получился быстрый клиент? Не совсем. Надо посмотреть как релиз реализован Connection Pool.

![](https://habrastorage.org/webt/tk/rs/1u/tkrs1uhjy3nlqecg_j2payseg_i.png)

Наивная реализация Connection Pool выглядит так. Есть какой-то адрес сервера куда нужно устанавливать connection. Есть список свободных connection и блокировка для синхронизации обращение доступа к этому списку.

![](https://habrastorage.org/webt/zb/lk/j5/zblkj5q4hygyxgd9rmrzjx2nxpa.png)

Вот функция получения connection из connection pool. Мы смотрим список наших collection. Если там что-то есть, то достаем свободный connection и возвращаем его. Если ничего нет, то создаем новое подключение к этому серверу и возвращаем его. Что же здесь не так?



![](https://habrastorage.org/webt/lw/xz/7q/lwxz7qmhwkqv3tmu4mc5f0tfumi.png)Функция connPool.Put возвращает свободный connection.

На счет таймаута. В Fasthttp.Client можно указывать максимальное время жизни открытого неиспользуемого connection. После того как это время прошло неиспользуемые connection закрываются автоматически выкидываются из этого pool. 

Более старые connection становится неиспользуемыми в течение времени и автоматически закрываются и удаляются из pool.

Когда берется connection из pool, который оказался что его сервер закрыл, и вы пытадись что-то туда записать, то производится повторная попытка - достается новый connection и пытается снова запросы поэтому connection. Но это только в том случае, если данный запрос идемпотентный -  то есть запрос, который может быть выполнен много раз без побочных эффектов на сервере - это GET HEAD запрос. Например, вот стандартном net/http только сейчас только добавили проверку на закрытые connection. Там сделали более хитрую проверку. Они проверяют, когда пытаются отправлять новый запрос в connection из pool, проверяют отправился ли вообще хотя бы один байт в этот connection. Если отправился, значит тогда уже все ну типа возвращаем Error. Если не отправился, значит берем новый connection из pool.

![](https://habrastorage.org/webt/h2/ug/yv/h2ugyvjrfzht7gfwx2gemetfazy.png)

Что не так с pool? Его размер не ограничен. Такая же реализация стандарта как в net/http. Если вы напишете клиент, который ломится с миллионов горутин на медленный сервер, то клиент попытаться создать миллион connection на этот сервер. В стандартном пакете net/http не ограничения на максимальное количество connection. Для клиента, который используется для обращений к API по HTTP желательно ограничить размер этого connection pool. Иначе ваши клиенты уйти в down, потому что у вас будут использоваться все ресурсы: потоки, объекты, connection, горутины и память. Также это может привести к DoS ваших серверов, так как до них будет установлено очень много connection, которые либо не используется либо используются неэффективно, потому что сервер столько connection не может держать.

![](https://habrastorage.org/webt/km/zk/pn/kmzkpnls98apnqltus4tvoeeb5c.png)

Ограничиваем connection pool. Кода здесь нет, потому что он слишком большой для того чтобы поместиться на один слайд. Желающие могут посмотреть реализацию этой функции на github.com.

![](https://habrastorage.org/webt/ub/1a/ko/ub1akoqexz4yoqyn3xogkcwveza.png)

Вторая проблема. На клиент приходит в какой-то момент времени очень много запросов. А после этого происходит спад и возврат к предыдущему количество запросов. Например, пришло одновременно 10000 запросов, потом количество запросов вернось к 1000 запросов. После этого connection pool вырастет до 10000 connection. Эти connection будут висеть там бесконечно. Такая проблема была в стандартном net/http клиенте до версии 1.7. Поэтому нужно решать эту проблему.

![](https://habrastorage.org/webt/dm/o1/w4/dmo1w4jixcnjjjaoznw8r7zz8bw.png)

Эта проблема решается путем ограничения жизни неиспользованных connection. Если через в течение какого-то времени не было отправлено ни одного запроса, то он просто закрывается и выкидывается из pool. Реализация отсутствует, потому что она слишком большая.

![](https://habrastorage.org/webt/hs/wj/wx/hswjwxgrlyawxzj_t-mmdbxhh3m.png)

Мы получили клиент, который работает быстро и классно? Не совсем так. У нас там ещё осталась функция создание connection - dialHost.

![](https://habrastorage.org/webt/cl/bs/jr/clbsjrbour6diwgkjri6jpdhnx8.png)

Посмотрим на ее реализацию. Наивная реализация выглядит так. Просто вам передается это адрес куда нужно подключиться. Мы вызываем стандартную функцию net.Dial. Она возвращает connection. Что не так в этой реализации?

![](https://habrastorage.org/webt/sm/b_/bc/smb_bcj41taldeo3mvnfl9ek-2g.png)

По умолчанию net.Dial делает dns запрос на каждый вызов. Это может привести к повышенному использованию ресурсов вашего DNS и вашего сервера. Если API клиенты подключаются к серверам, которые не поддержит KeepAlive соединения, то они закрывают соединения. Вы поддерживается KeepAlive, а сервера не поддержат KeepAlive. После такого ответа сервера закрывают соединение. Получается net.Dial вызывается на каждый запрос. Таких запросов около 10 тысяч в секунду. У вас 10 тысяч секунду идет resolve в dns. Это нагружает подсистему DNS.

![](https://habrastorage.org/webt/2j/au/e6/2jaue6kkmfwaob6p9tu-5quhgei.png)

Как эту проблему решить? Зависти кеш, который map-ит host в IP на короткое время прямо в вашем Go коде и не вызывать dns resolving на каждый net.Dial конектится к IP уже готовым. 

![](https://habrastorage.org/webt/eh/n2/j3/ehn2j3tfuse-43qoibyq5oqqcsu.png)

Вторая проблема это неравномерная нагрузка на сервера, если у вас за DNS доменом спрятана несколько серверов. Например, как Round Robin DNS. Если кешировать DNS в один IP адрес, то в течение этого промежутка времени у вас все запросы будут уходить на один сервер. Хотя у вас может быть там их несколько. Нужно решать эту проблему. Решается на путем перебора всех доступных IP, которые спрятаны за данным доменным именем. Это также делается в Fasthttp.Client.

![](https://habrastorage.org/webt/wx/hb/6r/wxhb6r3hlt_wofv6o347jyvw_oo.png)

Третья проблема это что net.Dial также может зависнуть на неопределенное время из-за проблем с сетью либо сервером куда вы пытаетесь подключиться. В этом случае ваши горутины будут зависать на функции Get. Это тоже может приводить к повышенному использованию ресурсов.

![](https://habrastorage.org/webt/jc/k3/id/jck3idzikb6vyzvsbcuckeg8wae.png)Решение добавить таймаут. Либо использовать в стандартном package net также есть Dial с таймаутом, но насколько я знаю он реализован неправильно. Можеь сейчас уже его исправили, но раньше он был реализован так как я рассказывал.

![](https://habrastorage.org/webt/cb/mq/1c/cbmq1c_b9ua-0ess-if8dfqkk0a.png)

Вот так вот был реализован. Вместо Get была Dial функция. Она выполнялась в какой-то горутине. Если Dial, то зависал то получалось, что горутины накапливались. Количество таких горутин, которые зависли могли расти бесконечно. Это стандартная реализация Dial таймаут. Может сейчас уже исправили.

![](https://habrastorage.org/webt/jo/tn/t0/jotnt0t9nwul2jx8sym4-kycfvu.png)

Кроме этого HostClient имеет следующие возможности.

HostClient умеет распределять нагрузку на список серверов, которые вы указали. Таким образом реализовываться примитивный LoadBalance.

Также HostClient умеет пропускать нерабочие сервера. Если в какой то момент времени некоторые сервера перестают работать, то the HostClient при попытке обращения к этому серверу это обнаружит. В следующем connection он не будет обращаться к этому серверу. Таким образом реализована балансировка нагрузки. Вы теряйте минимальное количество запросов. 

Fauly hosts может быть по двум причинам.

Первая причина - это мы к серверу не можем Dial установить. Зависли на Dial. В этом случае получается мы зависли на этом Dial и Get, который завис, он будет ждать какое-то время. Пока он ждет в это время все остальные запросы будут идти на другие от сервера. Таким образом все остальные через остальные хосты будут проходить больше запросов чем через этот.

Второй вариант - это когда сервер начинает медленно отвечать. Он в Get проводит больше времени чем остальные сервера. В этом случае количество запросов отравленных на этот сервер становится меньше, чем на остальные сервера.

Если просто Error вернулся, тогда идет попытка в Round Robin подключение к следующему серверу.

Поддержка SSL очень легко делается, так как в Golang очень классная реализация. Ее удобно использовать и подключать в свои решения.

![](https://habrastorage.org/webt/py/wf/93/pywf93cfwemlknabq_iejxfgpt4.png)

Переходим к fasthttp.Clinet. На самом деле тут все намного проще по сравнению с HostClient, так как fasthttp.Clinet реализован на основе HostClient.

![](https://habrastorage.org/webt/0s/f8/mz/0sf8mzfxpk1nl5lucgjvwaqkgy8.png)

Вот примитивный псевдокод для реализации клиента функции Get. У нас есть список HostClient для каждого известного хоста. Вот эта функция возвращает нужный HostClient для данного хоста из данного угла. Потом мы в этом HostClient вызываемую функцию Get. Вот вся реализация клиента на оставе HostClient.

![](https://habrastorage.org/webt/xd/nf/u8/xdnfu88duh8s5ibm0qx_riwe4go.png)

Вот эта функция может создавать новые HostClient для каких-то новых хвостов, которые появляются у нас в URL. Если использовать для web-crawling (лазания по интернету), то ваш клиент может обратиться к миллионам сайтам. В итоге у вас получится миллион этих HostClient до каждого сайта и вся память закончится. Именно так было до в стандартном net/http, может быть сейчас уже решили проблему. Чтобы этого не происходило нужно периодически чистить HostClient, которым давно не было обращения. Так поступает fasthttp. 

![](https://habrastorage.org/webt/r2/f7/bk/r2f7bkykq6m6oqcd3ylss9rwdr4.png)

В отличие от Client и HostClient у PipelineClient реализация немного другая. В PipelineClient отстутствует connection pool. У PipelineClient есть опция количество connection, которое нужно становиться на хвост. PipelineClient будет пытатся пропихнуть все запросы через это количество connection. Поэтому там нет никаких connection pool. PipelineClient сразу устанавливает connection и распихивают входящие запросы в доступное connection.

![](https://habrastorage.org/webt/lj/vw/ew/ljvwewxdpm8ag50y-tcfzthrxia.png)

У PipelineClient для каждого connection запускается две горутины. PipelineConnClient.writer - пишет запросы connection не ожидая ответа. PipelineConnClient.reader - считает ответы из этого connection и сопоставляет их с запросами, которые были отправлены через PipelineConnClient.writer. PipelineConnClient.reader возвращает ответ, коду который вызвал эту функцию Get.

![](https://habrastorage.org/webt/nj/9q/lp/nj9qlpw3mexynplnky52vvhcar4.png)

На слайде примерная реализация функции PipelineClient.Get для PipelineClient. В структуре pipelineWork есть url, на который нужно обратиться, есть указатель на response, есть channel done, который сигнализирует о готовности response. 

Ниже на слайде реализация Get. Cоздаем и заполняем структуру. Отправляем ее в channel, который читается PipelineConnClient.writer и пишется все запросы в connection. Ожидаем на channel w.done, который закрывается PipelineConnClient.reader, когда пришел response для этого request.

![](https://habrastorage.org/webt/s4/vf/oq/s4vfoqg_mmutotfdw66gs4nbxvs.png)

Сравнение производительности net/http клиента fasthttp.Client на следующих 2 слайдах.

![](https://habrastorage.org/webt/ah/ra/-o/ahra-oaf0uydcje9yqofoh6l-6k.png)

Бенчмарки, которые показаны на этих слайдах, присутствуют в fasthttp. Вы можете их сами запускать, проверять, тестировать. Вот результаты для fasthttp эти бенчмарки. Видно что одна из главных фишек fasthttp, что он не выделяет память вообще в часто выполняемом коде. У него ноль allocation на операцию. И также указано время выполнения каждого из этих тестов.

![](https://habrastorage.org/webt/q6/c3/ss/q6c3ss7kpmkwwlxk01o_ffyqhs0.png)

А теперь переключаемся на net/http. Видим сколько allocation на операцию у net/nttp. Видим время выполнения каждого из этих тестов.

![](https://habrastorage.org/webt/jm/fh/sg/jmfhsgqsqoiwblgnfsliiytqauw.png)

Вопрос: Когда PipelineClient остановится в записи запросов в connection?

Ответ: У него есть опция количество pending запросов, запросты у которых еще не вернулись ответы. Это в настройках можно настроить. Если пришел новые request, а у нас достигнут количество максимальных запросов, которые мы отправили, но еще не получили ответы, то возвращаем Error.

Вопрос: Совместимы формат API и структур данных, которые возращаются от fasthttp, с net/http? 

Ответ: Не совместим. Формат структур в стандартном net/http не оптимизирован по потреблению памяти. Там в структурах есть указатели на другие структуры. Там string какие-то, но string вообще нельзя переиспользовать. Формат скульптур, которые используются в стандартном net/http ограничивают переиспользование памяти. В итоге там по-любому нужно выделять память для того чтобы заполнить эти структуры. В fasthttp все структуры сделаны таким образом, чтобы можно было переиспользовать память. Поэтому они не совместимы. Существенное отличие net/http клиента от fasthttp в том, что помощи net/http клиента легче можно отправлять большие POST-запросы, принимать здоровенные response, например стримить(отдавать) файл. А дизайн fasthttp сделан так, что request и response все в памяти хранятся. Поэтому там нельзя 10ГБ request отправить или 10ГБ response принять. ну то есть это пока сейчас нельзя но может быть будущем почему нельзя потому что нам в компании это не надо было ну то есть у нас в основном используется там запросы и ответы там пограничная длинный да там там максимуму там сотни килобайт не больше поэтому если вам вам нужно гонять там в этих запросов ответа какие-то здоровенные базе то лучше используйте стандартную наши степи все равно там бостона время уйдет на передачу этих у центральной базе и там то что там фас ажиотаж цепи выделяет память о но они как даже не будет заметно