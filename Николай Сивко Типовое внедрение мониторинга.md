![](https://habrastorage.org/webt/6p/1s/ag/6p1sagfqodqg4wvy6b8xmlinusm.png)

﻿Меня зовут Николай Сивко. Я тоже делаю мониторинг. Okmeter это 5 мониторинг, который я делою. Я решил что я спасу всех людей от ада мониторинга и мы избавим кого-то от этих страданий. Я всегда в своих презентациях стараюсь не рекламировать окметер. Естественно картинки будут оттуда. Но идея того, что я хочу рассказать заключается в том что мы делаем мониторинг несколько другим подходом, чем все делают обычно. Мы очень много об этом рассказываем. Когда мы каждого конкретного человека пытаемся в этом убедить в итоге он убеждается. Я хочу рассказать о нашем подходе именно для того чтобы, если вы будете делать мониторинг сами, чтобы вы избежали наших граблей. 

![](https://habrastorage.org/webt/za/jq/fi/zajqfi-zfkopot4qxgmw79zgnp8.png)

Про окметер вкратце. Мы делаем то же самое что и вы, но есть всякие фишки. Фишки:

- детализация;
- большое количество преднастроенных триггеров, которые основаны на проблемах наших клиентов;
- автоконфигурация;

![](https://habrastorage.org/webt/nj/n0/vs/njn0vsnh6hfcyvjuejxy7qtopek.png)

Типичный клиент приходит к нам. У него есть две задачи:

1) понимать что все сломалось из мониторинга, когда вообще ничего нет.

2) быстро чинить это.

Он приходит в мониторинг за ответами что у него происходит.

![](https://habrastorage.org/webt/ig/ff/fl/igffflnnpqwybqqxxw1yd0nb9tw.png)

Первое что делают люди, у которых ничего нет - ставят https://www.pingdom.com/ и другие сервисы для проверки. Плюс этого решения в том что это можно сделать за 5 минут. Вы уже не от звонков клиентов узнаете о проблеме. там есть проблемы точностью, с тем что они пропускают проблемы. Но для простых сайтов это достаточно. 

![](https://habrastorage.org/webt/cz/hb/td/czhbtddbrnh7n0msqxzrqxn8_wq.png)

Второе что мы пропагандируем - считать по логам по статистику реальных пользователей. То есть сколько конкретный пользователь получает ошибок 5хх. Сколько время ответа по пользователям. Есть свои минусы, но в целом такая штука работает. 

![](https://habrastorage.org/webt/4g/ka/bk/4gkabkle1j9w96av-pkspnlwtis.png)

Про nginx: мы сделали так что любой клиент, который приходит, сразу ставит агент на фронтэнд и у него сразу все автоматом подхватывается, начинает парсится, начинают показываться ошибки и так далее. Ему почти ничего не надо настраивать.

![](https://habrastorage.org/webt/cf/ef/5p/cfef5pftq8hwwmmb1zqfwiqyf7m.png)

Но у большинства клиентов нет в логах таймеров в стандартном nginx. Это 90 процентов клиентов не хотят знать время ответа их сайта. Мы с этим все время сталкиваемся. Надо лог nginx расширять. Тогда из коробки автоматом мы начинаем показывать еще и гистограммы. Это наверное важный аспект того что время надо мерить.

![](https://habrastorage.org/webt/qv/yx/_x/qvyx_xrqm7dg8vqcxkonum__aws.png)

Что мы оттуда выдергиваем? На практике мы снимаем метрики в таких размерностях. Это не плоские метрики. Метрика называется index.request.rate - количество запросов в секунду. Она детализировано по:

- хосту, с которого вы сняли логи;

- логу, с которого эти данные снялись;

- http по методу;

- http статусу;

- cache статусу;

  

Это НЕ каждый конкретный URL со всеми аргументами. Мы не хотим снимать из лога 100000 метрик.

![](https://habrastorage.org/webt/u6/ah/0r/u6ah0rgp43jp3mnzdrqjpet5sza.png)

Мы хотим снять 1000 метрик. Поэтому мы пытаемся URL нормализовать, если это возможно. Берем топ URL. А для URL, которые значимы, мы показываем отдельную гистограмму 5хх.

![](https://habrastorage.org/webt/ij/dr/ir/ijdrirnx6vwpo9jfteyepp3ax_e.png)

Вот пример того как эта простая метрика превращается в юзабельные графики. Это наш DSL сверху. Я пытался этим DSL объяснить примерную логику. Мы взяли все nginx request в секунду и разложили их по машинам все которые у нас есть. Получили знание о том как у нас это балансируется, сколько у нас суммарно RPS (request per second, запросов в секунду).

![](https://habrastorage.org/webt/mc/hv/sv/mchvsvendei8dswx2umciwkg8qu.png)

С другой стороны мы можем эту метрику отфильтровать и показать только 4хх. На графике 4хх могут быть разложены по статусу, который настоящий. Напоминаю это та же самая метрика. 

![](https://habrastorage.org/webt/uk/14/vc/uk14vcumvrmenkg4mubhonkv5gu.png)

На графике можно показать 4хх с разбивкой по URL. Это одна и та же метрика.

![](https://habrastorage.org/webt/1l/n4/g8/1ln4g8sgwvteebpsdsbg_xmtly8.png)

Еще мы снимаем из логов гистограму. Гистограма это метрика response_time.histrogram, которая на самом деле RPS c дополнительным параметром level. Это как раз отсечка времени в какой bucket попадает запрос. 

![](https://habrastorage.org/webt/cb/3b/nh/cb3bnh0wosk9il_ntyywe3z1kiq.png)

Мы рисуем запрос: просуммирую всю гистограмму и разложи по уровням:

- медленные запросы;
- быстрые запросы;
- средние запросы;

Мы имеем картинку, которая уже просуммирована по серверам. Метрика одна и та же. Ее физический смысл понятен. Но пользу извлекаем из нее совершенно по-разному.

![](https://habrastorage.org/webt/og/_q/0a/og_q0acmw4ianhc6n5sc3z4aokq.png)

На графике можно показать гистограмму только по URL, начинающимся с "/api". Таким образом мы смотрим гистограмму отдельно. Мы смотрим сколько в этот момент мы видим сколько в URL "/api" было RPS. Та же метрика, но другое применение.

![](https://habrastorage.org/webt/lt/jw/46/ltjw46topobrcyeyyhkkigncknm.png)

Пара слов про тайминги в nginx. Есть request_time, который включает себя время от начала запроса и до передачи последнего байта в сокет клиенту. А есть upstream_response_time. Их нужно мерить обе. Если просто снимаем request_time, то там вы увидите задержки из-за проблем связанности клиента с вашим сервером, вы увидите там задержки, если у нас у вас настроен limit request c burst и клиент в бане. Вы не будете понимать нужно сервер чинить или хостеру звонить. Соответственно снимаем обе и примерно понятно чего происходит.

![](https://habrastorage.org/webt/uy/xy/a9/uyxya9gyu-fr0ccab75sa7fjt3q.png)

С задачей понимать работает сайт или нет, я считаю что мы более менее разобрались. Там есть погрешности. Там есть неточности. Общие принципы такие.

Теперь про мониторинг многозвенной архитектуры. Потому что даже самый простой интернет магазин имеет как минимум frontend, за ним битрикс и базу. Это уже много звеньев. Общий смысл в том, что нужно снимать какие-то показатели с каждого уровня. То есть пользователь думает про frontend. Frontend думает про backend. Backend думает про соседние backend. И все они думают про базу. Вот так по слоям по зависимостям и пробегаемся. Покрываем все какими-то метриками. Получаем что-то на выходе.

![](https://habrastorage.org/webt/nq/ov/rx/nqovrxw3la9pl8bkrufpklydrii.png)

Почему нельзя ограничиться одним слоем? Как правило между слоями находится сеть. Большая сеть под нагрузкой крайне нестабильная субстанция. Поэтому там бывает всякое. Плюс могут врать те замеры, которые вы делаете на каком слое. Если вы делаете замеры на слое "А" и слое "Б", и если они между собой взаимодействуют через сеть, то вы можете сравнивать их показания, находить какие-то аномалии и нестыковки.

![](https://habrastorage.org/webt/7a/kq/ov/7akqovksuz3bhdmaxez5vcibepk.png)

Про backend. Мы хотим понимать как backend мониторить. Что с ним делать чтоб понимать быстро что происходит. Напоминаю что мы уже перешли к задаче минимизации downtime. А про backend мы стандартно предлагаем понимать:

- Сколько это поедает ресурсов?
- Не уперлись ли мы в какой-нибудь лимит?
- Что у нас происходит с runtime? Например, платформа JVM runtime, Golang runtime и другие runtime. 
- Когда мы уже все это покрыли нам интересно уже ближе к своему коду. Мы можем либо воспользоваться автоматическими интруметрарием (statsd, *-metric), которые нам все это покажут. Либо заинструментировать сами, расставив таймеры, счетчики и т.д.

![](https://habrastorage.org/webt/wk/xq/6p/wkxq6ptxbigdvp3evm4t2mqh3lq.png)

Про ресурсы. У нас стандартный агент снимает потребление ресурсов всеми процессами. Поэтому для backend нам не надо отдельно снимать данные. Мы берем и смотрим сколько потребляет CPU процесс, например Python на серверах по маске. Мы показываем на одном графике все сервера в кластере, потому что мы хотим понять нет ли у нас разбалансировки и не взорвалось ли что-то на одной машине. Мы видим суммарное потребление от вчера к сегодня.

![](https://habrastorage.org/webt/t0/fl/oe/t0floe26e2hgev70o5fs18yf4ua.png)

То же самое про память. Когда мы рисуем это в таком виде. Мы выбираем Python RSS (RSS - размер страниц памяти, выделенных процессу операционной системой и в настоящее время находящихся в ОЗУ). Cуммируем по хостам. Cмотрим нигде не течет память. Везде память распределена равномерно. В принципе на свои вопросы мы ответ получили.

![](https://habrastorage.org/webt/zl/cu/yz/zlcuyz_bgzybypkgcndsotzdcsk.png)

Пример runtime. У нас есть Golang приложение агента. Golang агент присылает про себя метрики своего runtime. Это в частности количество секунд потраченных Golang garbage коллектором на сборку мусора в секунду. Мы здесь видим что у одних серверов метрики отличаются от других серверов. Увидели аномалию. Пытаемся это объяснить.

![](https://habrastorage.org/webt/oj/ir/pu/ojirpuokww_ym6e1hg1yrwz_8ao.png)

Есть другая метрика runtime. Сколько памяти аллоцируется в единицу времени. Видим что агенты с типом, которые верху, аллоцируют больше памяти, чем агенты которые внижу. Внизу агенты с менее агрессивным Garbage Collector. Это логично. Чем больше памяти через вас проходит, аллоцируется, освобождается, тем больше нагрузка на Garbage Collector. Дальше мы по своим внутренним метрикам понимаем почему мы столько памяти хотим на тех машинах и меньше на этих машинах.

![](https://habrastorage.org/webt/8h/4s/yq/8h4syq_g35fjhfdztsheuybzyrc.png)

Когда мы говорим про инструментирование, то приходят всякие инструменты <http://pinba.org/> для PHP. Pinba это extension для php от компании Badoo, который вы ставите и подключаете к php. Он вам позволяет сразу снимать и отправлять по протоколу UDP protobuf. У них есть Pinba-сервер. Но мы сделали встроенный Pinba-сервер в агенте. PHP про себя отправляет сколько она потратила CPU и памяти на такие-то скрипты, сколько трафика отдано такими скриптами и так далее. Здесь пример с Pinba. Мы показываем топ-5 скриптов по потреблению CPU. Мы видим фиолетовый выброс это замазанная точка PHP. Идем чинить замазанную точку PHP или разбираться почему она съедает CPU. Мы уже сузили область проблемы настолько, что мы понимаем следующие шаги. Мы идем смотреть код и чиним. 

![](https://habrastorage.org/webt/kx/el/vv/kxelvvi9xxzv4bfefhf4m0xbhay.png)

То же самое про трафик. Мы смотрим топ-5 скриптов по трафику. Если нас это парит мы идем и разбираемся.

![](https://habrastorage.org/webt/nz/io/zs/nziozsp_7pzn3ej88j8t3bdpenk.png)

Это график про наши внутренние инструменты. Когда мы через statsd ставили таймер и измеряли метрики. Мы сделали так что количество суммарно проведенного времени в CPU или в ожидании какого-то ресурса раскладывается по хендлеру, который мы сейчас обрабатываем. Это внутренней хендлер и по стадиям как бы стадии значимой кодом то есть куски кода типа ждали кассандру ждали там не зная ластик search и мы и говорим покажи нам топ 5 статей по хендлера метрик вере соответственно можем как показать покажи нам топ-5 хендлеров по потреблению циpкa так ли что там внутри происходит ну картинки примерно такие то есть понятно чаю чинить

 про базу данных добрый backend как-то там можно дальше углубляться есть штуки которые делают racing то есть вы можете видеть что там вот этот конкретный запрос пользователя там скукой такой-то пи адрес он такой-то породил столько-то запрос в базу они ждали столько то мы tracing не умеем мы tracing не делаем мы по-прежнему мы умеем все вот это но по-прежнему считаем что applications and performance monitoring мы не делаем соответственно поэтому backend предлагаю закончить

![](https://habrastorage.org/webt/pr/zy/yf/przyyfqriaulwy_fe4swdvq2bco.png)

 перейти к базе а естественно пара базу то же самое базы тот же процесс он потребляет ресурсы единственное что если база очень чувствительна к этой нас титан немножко другие заморочки вот то на что трясутся дуба то есть там еще мы предлагаем проверять что ресурсов не стало меньше то есть деградации по ресурсам нету и идеально понимать если от вас база стала потреблять больше чем потребляла понять чего конкретно в вашем коде изменилось что база больше начала потреблять соответственно про ресурсы точно так же берем смотрим сколько процесс mais quel порождает у нас операции записи на диск 

![](https://habrastorage.org/webt/az/zc/lj/azzcljm0hkvcfxc1lgeqeukrdgq.png)

видим что там типа в среднем столько это на случается какие-то планшетом и так далее или там нам приходит туда кучин cert of и вот он начинает писать в 1515 1615 1715 

![](https://habrastorage.org/webt/u8/vb/rc/u8vbrcgbovxfcalnkk7sph4rw2i.png)

соответственно против градацию ресурсов это будет примерно так у райда батарейка ушла на в maintenance мод то есть она перестала контроллеру быть как живая батарейка она там чуть не знаю там разрядиться там проверяет сколько у нее там скорость разрядки так далее не знаю что там конкретном железе происходит но я знаю что в этот момент отключается write cache и latency дисков на запись возрастает то есть в этот момент если база у вас там начала тупить притом ожидания диска вы там примерно знаете швед момент у вас при такой же нагрузки на запись на диск в этом все было другое как бы и это вот ресурс которым надо жить

![](https://habrastorage.org/webt/j_/ap/qb/j_apqbgrlnp5zkiopa794hq0v4y.png)

 соответственно ресурсы по запросам тут все не так просто зависит конечно от базы то есть база должна сама про себя уметь рассказывать куда она тратит ресурсы на какие запросы самый лидер тампа покайфовать это puzzles потому что у него есть пиджи состоятельность он умеет показывать по запросам условно там звездочки стоят потому что все там с погрешностью все косвенно но блин хотя бы что то то есть мы вы можете понимать какой запрос у вас живет циpкa какой запрос диск его вызывает там на чтение на запись и примерно какой запрос вам создал трафик 

mais quel и если честно все гораздо хуже там есть performance kimo она там с 57 как-то работает в отличие там от одной вьюшки в подгрести это 27 помыли 23 таблицы системных вьюг mais quel и иногда если вы будете делать запросы к неправильным таблицам к неправильным ухом вы можете там просадить мускул короче шепотом полное 

вот в одессе есть статистика по командам то есть вы видите что там команда такая то живет циpкa команда такая-то не же циpкa 

в кассандре есть времена по запросам конкретных таблиц но так как кассандры проектируется таблицы так чтоб не будет один тип запросы делается это достаточно 

![](https://habrastorage.org/webt/qx/gt/wo/qxgtwoplv8i3wnce0ncygyipfgw.png)

естественно картинки про все это это редис видим что с пузырек фиолетового фиолетовое the settings то есть и тут как бы запись ключа с установкой отеля соответственно если нас это парит идем с этим разбираться если нас это не парят просто знаем как бы куда вроде все ресурсы уходит

![](https://habrastorage.org/webt/78/x_/ng/78x_nghhya3bc-3zd2xtgd2kyxy.png)

 с другой стороны вот кассандра да мы видим что запросы на чтение топ 5 таблиц по запросам на чтение по суммарному времени ответа естественно мы видим что там вот этот выброс это запросы к таблице там entity не условно и мы примерно понимаем что к этой запросе коты и таблицы запрос нас делает один кусок кода там одна один тип запроса и это не из quelle база в который мы можем сделать кайт таблицы такой запрос и щекой запрос в кассандре все более убого 

вот соответственно про содержательной части рассказал еще пару слов про workflow работ с инцидентами как я это вижу как эксплуататор бывший он бывших не знаю бывает не бывает 

![](https://habrastorage.org/webt/z3/ho/s3/z3hos3wz7mgt5yvh3jbw9sgodxi.png)

про alert и естественно правильно если верить и мы обсудим то есть здесь есть несостыковка с общепринятым понятиям как бы наше наше видение это что людей обычно бывает и как что делать когда у нас пришла эсэмэска то есть порядок действий на наш взгляд опять же я не знаю там за топлю за свою религию 

![](https://habrastorage.org/webt/px/zd/n4/pxzdn4r9vdjznfd6hrr2x63nmxi.png)

правильные сверить и наше видение такая критика это когда вот вообще просто пипец мы уведомляем и смсками мы вот сразу прям будем там по всем real-time каналам связи и так далее противоположно уровне

 the info это лампочка которая может вам чем-то помочь при работе на студентами она никуда не ратифицирована просто висит и там говорит вам о том что что то происходит 

варнинг это то что можно там куда-то модифицировать а можно и может и нет подробнее про каждые

![](https://habrastorage.org/webt/op/hd/az/ophdazu-e1tchrtymsdxetidpq8.png)

 примеры critical of sight не работают вообще не знаю там 5 соток сто процентов или там время ответа выросла и пользователи уже начали уходить потому что ну ждать нет никаких сил 

ошибки бизнес-логики то есть то что критично здесь же не как раз говорил что надо мерить деньги в секунду вот деньги в секунду хороший как бы источник данных для критиков соответственно заказы там не знаю открытка реклама ну кому что важно тот critical и себе на этом устроит

![](https://habrastorage.org/webt/it/n3/em/itn3emdzqhe7lapptysa1nvlwjy.png)

 соответственно workflow с критиком он такой что это нельзя отложить это на это нельзя забить нельзя нажать ок и пойти домой не знаю если вам пришел критика вы едете в метро вы должны выйти из поезда подняться на ум наружу сесть на лавочку начать чинить в противном случае это не критика и соответственно из этих соображений мы уже там остаточному признаку остальные severity конструируем

![](https://habrastorage.org/webt/pq/ct/ww/pqctww-7nkjkjjdvmujjl9ntjrm.png)

 warning примеры вардинга fdisk кончается какой-то сервис внутренней тупит но при этом если у вас критиковал нет значит вам на это условная пофигу много ошибок там из teen top фейсе самая спорная это вот это сервер не доступен на самом деле там если у вас больше одного сервера сервер недоступен это варнинг и с этим надо как бы смириться потому что вы не если у вас не знаю там умер один backend из сотни но глупо просыпаться ps смски то вы получите при всем уважении к mail.ru таких же в органах админов как работали в mail.ru 2005 году что них эсэмэски просто не переставая лились не знаю там от проекта зависит ну и такие вот мелочи которые там помогают вам все остальные верить и создана для того чтобы помочь вам разобраться с критику

![](https://habrastorage.org/webt/ze/rv/je/zervjevqnr3gnnaqugze3h1jf-g.png)

 соответственно варнинг мы пропагандируем такой подход к работе с армянками желательно закрыть течение дня скорее всего ну то есть большинстве большинство наших клиентов которые нам доверились и поверили в это они отключили нотификацию на варнинг и тем самым у них нету так называемый там мониторинговой слепоты вот это в почте который в папочку там вот эти вот 20 тысяч писем на знаете да вот они отключили уведомление на warner гей просто а если при этом они придерживаются там иной техники чистого мониторинга да там есть какая-то другая техника чистого и бокса чистой мониторинг если у вас и у вас чистый и вы смотрите целый день на те пять warner и в которые его загорелись вы спокойным спокойном режиме их чинить и не успели сегодня пока ли там ну завтра доделает если не критично соответственно если вор нинги вот так вот загораются погашают это надо крутить в мониторинге чтобы опять же вам вас не бесить как бы и тогда вы будете более терпимы к ним относиться и и соответственно жизнь наладится 

![](https://habrastorage.org/webt/xp/92/lv/xp92lvui1q6xbawczc9ltl0osys.png)

примеры info тут тоже спорно что цепную совершает у на самом деле у многих критиков на самом деле ну если при этом ничего не аффекте ца да и хрен сна вот диск и вот здесь где-то в планке

![](https://habrastorage.org/webt/xb/nn/p1/xbnnp13tktiqtspilpycu2oaxba.png)

 ворнинги опять же это такие лампочки которые вы приходите чинить critical видите рядом два таких невзначай вор не вижу тут вот на базе циpкa в планке ну пошел посмотрела все зачем как бы знать про циpкa отдельно там вы смски в письме непонятно

 совершенно соответственно здесь написано то что бессмысленный info это тоже плохо если вы их настроить исключение то вы будете инфо любить тоже сильно 





![](https://habrastorage.org/webt/ra/rc/uc/rarcucyuedf9vp6v6keycnnjbz4.png)

соответственно общие принципы подхода к конструированию alert of alert и должны показывать причину это идеально такого добиться вообще-то говоря сложном и вот full-time работаем над задачей получается там с какой-то части успеха но в целом сложно очень все говорят там про то что нужны зависимости of the man who как мы покажем кучу лишнего на самом деле если у вас замучено то что вам вообще никак нет не интересно не знаю цыпой усач на ходу пах то лишнего много не будет и в моей практике статистика говорит о том что человек момент фака по от смотрит глазами там около сотни лампочек его это не за парит займет у него меньше минуты просто так вот по диагонали зато он там найдет нужный не будет думать автору ко мне что-нибудь там dependency там скрыли какие-то лампочки которые мне бы сейчас помогли на самом деле вот вот это на практике работает и соответственно вот все что нужно делать это подчищать ненужные alert 

![](https://habrastorage.org/webt/wq/i8/mm/wqi8mmyravgx7yllannlhsgdvg8.png)



![](https://habrastorage.org/webt/ys/t_/0d/yst_0dqqfwqnra1yz0krnccw7ae.png)

и и пара слов про работу вообще с инцидентами ну тут как хорошо бы эти downtime и потом классифицировать чтобы с ними потом работать делать там не знаю там разборы делать какие-то выводы организационные там мероприятия вам нужно понимать из-за чего вы лежали соответственно мы предлагаем там ну я предлагаю это просто реклассифицировала уже когда-то разбивать примерно такие классы там человек налажал не знаю хостер налажал не знаю там пришли боты ну вот что что какие вы в класс и видите вы можете часах сделать 20 потом вы поймете что вам нужно 5 свернете их но если вы их палка классифицируйте то всем будет потом счастье

![](https://habrastorage.org/webt/_c/kz/ll/_ckzllbldi_jkamyonco194favy.png)

 соответственно вот пришла нам эсэмэску чё делаем мы сначала бежим сочинить нам пока вообще ничего не важно кроме того чтобы downtime кончился потому что все мы мотивированную меньше лежать соответственно потом когда инцидент закрылся он должен закрыться систем мониторинга то есть вот насколько я знаю в гугле инциденты мониторингом не закрываются их закрывает человек когда проверяют что все хорошо ну это было какое-то время назад в одном из проектов по которой меня есть данные соответственно я вот не очень понимаю зачем это нужно мы считаем что инцидент должен проверить мониторингом если у вас мониторинг не настроен достаточно чтобы удостовериться что проблема закончилась ночь это надо крутить соответственно а после того как инцидент закрыт мы на самом деле не закрыта он ждет пока вы докопайтесь до причины это нужно чтобы опять ну как бы любой любой менеджер там не знаю сила его там в компании говорит что мне на самом деле в первую очередь нужно чтобы проблемы не повторялись это вот их учит на имбире и короче что если у вас проблемы повторяются значит у вас люди не те там и соответственно что проблема не повторялись нужно докопаться до причины естественно до причины докопались у нас есть данные чтобы их классифицировать соответственно разбор потом как мы докопались до причиной что нам нужно сделать в будущем чтобы президент не повторялся нужно там два человека квартала для того чтобы там вписать в бэг-энд такую-то логику нужно не знаю там поставить больше реплик ну короче сделать что-то что-то что-то инцидент больше такой же от ровно такой же инцидент не произойдет ну и соответственно когда вы работаете в таком workflow через и нате рации вас ждет счастье вас ждёт хороший аптайм и так далее ну и соответственно зачем мы их классифицировали мы можем там взять статистику за квартал понять что больше всего вам дало downtime а и в этом направлении работать ну как можно работать по всем фронтам но это будет не очень эффективно особенно если у вас там ресурсов в обтяжку 

![](https://habrastorage.org/webt/b9/os/oh/b9osohrb-qilf4mcb7ddcqjckju.png)

ну и соответственно условно мы там посчитали мы лежали столько-то времени 90 процентов потому что хостер наш говнюк вот но мы берем мы съезжаем она бывает такой игры что ты моргаешь соответственно если у нас лажают люди мы их соответственно ну как как-то даст на курсы не знаю там но на самом деле самый самый эффективный способ человек уложу победить это автоматизация потому что машина уважают реже когда человек пишет не знаю условно то что он делает руками там 1 неделю если он напишет скрипт он там больше рифов напишет это будет качественнее ну и соответственно если у нас там условно релизы говёные идем там и кросс подразделения устраиваем не знаю бойню вот и как бы когда вы знаете причину вам легче искать решения 

![](https://habrastorage.org/webt/js/gl/wp/jsglwpchvythu9tvkjnbruwtcr8.png)

и вот выводы капитанские опять же мониторинг мы раскладываем на две задачи первое обнаружения проблем 2 поиск причины если вас не устраивает время которое вы ищете причину настраивайте точность мониторинга соответственно если точность вас не устраивает обнаружение там тоже тоже можно покрутить что то чет настроить короче мониторинг это вот про вот это они про графит и прочее то есть содержательная часть очень важна и что происходит солярки мы тоже очень важно ну мой спич был провод это 

![](https://habrastorage.org/webt/nn/rb/fl/nnrbflbnglbwbwggjdxuipfuxss.png)

николай пасибо очень крутой доклад очень понравилось что говорили про подходы каким-то аспектом мониторинга расскажите пожалуйста про подход к тому как взять новую ну вот мы допустим хотим новый сервис новую машину добавить обычным от как делаем подключили воткнули шаблону стандартные затем начинается такой творческий процесс мы фолз позитив убираем до пытаемся убрать ложные срабатывания пытаемся добавить . что мы там не проверяем вот о подходе к этому можете пару слов сказать

 у нас подход такой что мы с машину и снимаем все когда вы добавили 10 frontend с него снимется все все что там есть если на соседних ну то есть как бы зеравак он в подхода если у вас на всех там 9 фронтах есть тайминги влаги он десятом нет мы вот наш подход в том что мы вам зажжем alert добавь тайминги эта проблема это варнинг без модификации по моему то есть вы в течение дня его добавить и все метрики появились машина такая же какая-то если вы делаете новый сервис то опять же там условно по ресурсам мы снимаем все там по каким-то еще там где мы можем дотянуться мы снимаем все ну то есть вот этот подход очень хорошо работает чтобы не забыть добавить метрику как бы если говорить о том что вот вы хотите что-то специфичная новый сервис ставите он там на другом runtime как вот не забыть ничего там вот померить или как за инструме тировать все наперед завист ремонтировать все наперед нельзя вот вот такой цвет и вы там до 1 факап ор живете в неведении потом вы понимаете чем нам а 

я имел немножечко имел ввиду немножечко про наверно пороге и на тифа и но речь о том что скажем есть у нас там тачка с базой скажем на ней lotte world штамм 4 норм там веб-сервер туда же 20 норм может быть открыта лишь вопрос не надо мире лет палаты а что надо делать alert пола ты веришь вообще никогда это нужно осмыслить до на самом деле в среднестатистическом проекте над на несколько сотен машин как правило пороге одинаковы для всех естественно есть цепную слышно ходу пах замучен всегда то есть бестолково умереть до а диск а то что dice кончился на базах чуть поменьше порог и вот как правило это вообще у всех работает у них есть два типа тогда все остальные триггеры там одинаковые и мы как бы когда делаем автоматически триггеры которые на всех пользователей выкатывается по умолчанию мы их делаем примерно общими то есть условно в любом проекте плохо работает по сгрыз и плохо настроен of the vacuum если worker of the вакууме в планке два часа и более значит что он никогда не сделает свою работу практически там для 99 процентах случаев вот такие общие триггер вам как бы как правило говорят с черпаю информацию а критиков и что для вашего проекта критика вам клиент крутит да то есть ли мой проект a critical 10 5 соток в секунду а меньше это не критика 

вот в какой момент и каким образом определяется порог и кто это делает то что это боевые навыки приходите мы хотим все-таки задать какой-нибудь критиковали своего проекта пробуйте что-то смотрите вот если бы сейчас поставили 10 5 соток сколько боли ртов получили недель назад мы вот так предлагаем 

коль здравствуйте спасибо за доклад очень интересно вопрос вот какой нагрузка всего этого доброго мониторинга nomos сервера там в амазоне очень хочется понять какого же нагрузка если вы снимаете все

 в среднем она вообще не заметно но если вы там парсить 50000 gps влоги это будет там единицы процентов ядра на десятки процентов ядра агента занимает мы короче как так как мы занимаемся только мониторинга мы на эту тему запарились да мы меряем производительность агента мы там когда вам не подходит работают и знаем есть такие люди которые говорят что писать логина наших рпс ах это вообще невозможно но мы им говорим но заправляйте нам пусть и слогу условно из-за джон экологии в память прям ну как то так то есть всегда есть возможность и ну как бы как админ я вам говорю что если у вас нету слота для мониторинга агента по ресурсам на сервере значит зачет делаете не так всегда должен быть слот это просто условно если вы этого не сделаете вы будете как как слепой вот на ощупь подменить ваш проект по силам













