**Предлагаю ознакомиться с расшифровкой доклада начала 2019 года Алексея Лесовского - «Поиск и устранение проблем в Postgres с помощью pgCenter»**

Время от времени при эксплуатации Postgres'а возникают проблемы, и чем быстрее найдены и устранены источники проблемы, тем благодарнее пользователи. pgCenter это набор CLI утилит которые является мощным средством для выявления и устранения проблем в режиме "здесь и сейчас". В этом докладе я расскажу как эффективно использовать pgCenter для поиска и устранения проблем, в каких направлениях осуществлять поиск и как реагировать на те или иные проблемы, в частности, как:

- проверить, все ли в порядке с Postgres'ом;
- быстро найти плохих клиентов и устранить их;
- выявлять тяжелые запросы;
- и другие полезные приемы с pgCenter.

![](https://habrastorage.org/webt/qn/a4/mf/qna4mfqgy2rzglomcwb7vqfzf6c.png)

<cut />

Всем привет! Меня зовут Алексей Лесовский. Я работаю в компании Data Egret. Это консалтинговая компания. И я вам расскажу, как мы в нашей консалтинговой компании занимаемся поиском и устранением неисправностей.

Я расскажу о том, как с помощью pgCenter, с помощью консольной утилиты можно хорошо, быстро и эффективно находить самые разные проблемы и переходить к их устранению.

![](https://habrastorage.org/webt/yr/w0/xq/yrw0xql9iojdv71lootxkstpnp4.png)

Немного о себе. Я долгое время был системным администратором. Занимался Linux, виртуализацией, мониторингом. И в какой-то момент времени стал заниматься больше Postgres. И работа с Postgres стала занимать большую часть времени. И так я стал PostgreSQL DBA. И сейчас уже работая в консалтинговой компании, я работаю с Postgres каждый день. И каждый день наши заказчики предоставляют нам самый разный материал для новых конференций.

![](https://habrastorage.org/webt/un/iq/hn/uniqhn3vizz01sw-ehwfqinuou4.png)

Все общение с нашими заказчиками происходит в виде беседы в чатах. Это самые разные чаты: Slack, Telegram. Но наши заказчики часто обнаруживают какую-нибудь проблему у себя и пишут. Мы в свою очередь должны на это как-то отреагировать.

![](https://habrastorage.org/webt/by/b_/v5/byb_v5zrziwqg7uynekxbgicm5g.png)

На слайде всем широко известная диаграмма Брендана Грэгга, как находить различные проблемы, связанные с производительностью в Linix. Это довольно интересная штука. Она показывает, как устроен Linux и какие утилиты есть для нахождения проблем. По сути, можно обложиться всеми этими утилитами и смотреть, что происходит. 

![](https://habrastorage.org/webt/dw/9v/fx/dw9vfxixzbtylmq8ngyde_m0tac.png)

Но в любом случае мы увидим то, что у нас все замыкается на Postgres. Процессорное время потребляется Postgres. Дисковый ввод-вывод тоже потребляется Postgres. Всю память съел тоже Postgres. Мы будем видеть только один Postgres.

![](https://habrastorage.org/webt/h6/yh/wi/h6yhwi0yvjcmfvtwcsp4lpd1-ew.png)

Для Postgres есть аналогичная картинка. Она также разбивает Postgres на несколько подсистем и показывает из чего состоит Postgres. Кроме того, в Postgres есть большое количество статистических представлений, с помощью которых можно анализировать работу этих подсистем. 

И этих статистических представлений довольно много. Но во всех этих view и представлениях есть колонки. Эти колонки тоже имеют имена. И держать все это в голове бывает довольно-таки сложно.

![](https://habrastorage.org/webt/qs/is/z5/qsisz5kh0nwff3fnhyuuedmi4ac.png)

И когда ты начинаешь искать какую-то проблему, нужно вспомнить все имена view, найти свои скрипты, которые ты, возможно, заранее приготовил. И это довольно-таки тяжело. И всегда возникает вопрос: «Что тормозит?», «Где тормозит?» и «Что с этим делать?». На поиск всего этого нужно время.

![](https://habrastorage.org/webt/hy/1d/js/hy1djsfn24oaxtvtoenwfutnae0.png)

И ковыряясь с каким-то из заказчиков, когда я тоже расчехлял свои скрипты, пытался диагностировать проблему, мне пришла в голову идея, что нужно написать программу, которая будет это все дело облегчать. И так пришла идея написать [pgCenter](https://github.com/lesovsky/pgcenter).

Изначально она была написана на С. Это консольная утилита, которая показывала статистику в TOP-подобном виде. 

Через какое-то время я понял, что C мне не очень подходит. Я не профессиональный программист. И я переписал ее на Go, потому что это более простой язык для меня. И мне на нем легче добавлять новые функции и новые фичи.

Один из плюсов Go является то, что не нужно компилировать программу. Система сборки, которая проверяет после каждого коммита на GitHub, компилирует бинарник и выкладывает его в страницу релизов. Т. е. не нужно устанавливать какие-то пакеты, не ставить GCC. Достаточно просто зайти в релизы, скопировать по ссылке, распаковать и можно уже пользоваться.

![](https://habrastorage.org/webt/r_/ml/jv/r_mljvrlw4cy-on_0xjshhku_p8.png)

Изначально весь pgCenter вертелся вокруг именно просмотрщика статистики, который в режиме топа показывает текущие изменения статистики за последние секунду, две секунды, в зависимости от настройки.

![](https://habrastorage.org/webt/ec/zn/ll/ecznll_0zub4khs1n2jmokshn30.png)

Однако потом я начал добавлять новые функции. И позже уже появились такие штуки, как сохранение статистики в файл и построение отчетов. И буквально совсем недавно я добавил профилировщик wait_events. Это штука позволяет смотреть, на каком месте запросы проводят время в ожидании чего-либо.

![](https://habrastorage.org/webt/ky/ug/ln/kyuglnhkaayl8bu3h1fc08uzz48.png)

И по ходу разработки я постарался сохранить синтаксис команды PSQL. Если вы работаете под Postgres, то достаточно просто запустить «pgcenter top» и она начнет показывать вам какую-то статистику.

![](https://habrastorage.org/webt/9q/h_/m_/9qh_m_wcabojkl4lpuxcksrp9ae.png)

В более сложных случаях, если вы работаете от другого пользователя или нужно подключиться к какой-то другой базе, или к instance, который находится на другом хосте, то можно указать те же самые ключи, которые вы используете в PSQL, которые определяют подключения к хосту, к конкретному порту, к конкретной базе и под конкретным именем пользователя.

![](https://habrastorage.org/webt/1t/f9/bw/1tf9bw-l988uxgquo3_vxflodfu.png)

Но можно даже не указывать хост, можно подключаться по Unix Socket, т. е. гошный драйвер, который используется под капотом pgCenter позволяет подключиться не только к сетевым сокетам, но и к Unix.

![](https://habrastorage.org/webt/c1/6h/vm/c16hvmt1ulij9-dtagepnodbtxq.png)

Кроме того, поддерживается переменная окружения ли… Даже если у вас совершенно экзотический случай, например, pg_stat_statements установлен в какой-то кастомной схеме и pgCenter не может его найти, то можно переопределить поведение через переменное окружение. Это тоже поддерживается.

![](https://habrastorage.org/webt/7s/vg/kx/7svgkxnps7ythlgby1qopvdffmy.png)

И вот так примерно выглядит внешний вид утилиты. И в первый раз, когда ее запускаешь, это может немного напрячь. Это похоже, что это какой-то центр управления полетами. Много цифр, много букв, все это быстро меняется. Но это на самом деле не важно. Здесь важно помнить интерфейс pgCenter, а именно топ-просмотрщика, он состоит из трех частей.

![](https://habrastorage.org/webt/mx/xj/9y/mxxj9ydlc1chuzs0y6rkbtfop2w.png)

Первая часть – это системная информация. Т. е. вся эта информация находится в верхнем левом углу.

![](https://habrastorage.org/webt/ty/ex/8x/tyex8xl56ktalumc-pddn1sigo4.png)Следующий момент – это верхний правый угол, где располагается сводная информация по Postgres. Здесь можно получить уже какую-то детальную информацию о том, как Postgres сейчас работает в данный момент. 

![](https://habrastorage.org/webt/66/ku/np/66kunpjqe9jcqa3kas1dhrbrghe.png)

И третий элемент интерфейса – это статистика из самих статистических представлений. Все эти stat-вьюхи, которые есть в Postgres, т. е. изменения этой статистики уже показываются в этой части экрана.

![](https://habrastorage.org/webt/a7/sd/ar/a7sdarvtow0y-pcvvedv7ckkqjs.png)

Кроме того, интерфейс предоставляет некие дополнительные фишки. Нажимая стрелки влево-вправо, вы можете менять сортировку. Т. е. вы можете выбрать интересующее вас поле и настроить сортировку именно по этому полю. Например, сортировку по именам таблиц, сортировку по текстам запросов, по времени и жизни транзакций, и т. д.

Если информации слишком много, можно использовать фильтры. В качестве фильтров там применяются обычные регулярки. И вы можете ограничить показ по только той информации, которая вас интересует. Например, показать запросы конкретного пользователя или конкретно какие-то запросы: селекты или апдейты.

![](https://habrastorage.org/webt/pf/mw/vx/pfmwvxrsdgjc_12luq9vaebret8.png)

В этом докладе я расскажу, какие конкретно кейсы вы можете использовать у себя в работе и можете у себя применять, работая с Postgres. И самый основной кейс – это проверка все ли в порядке с базой и нет ли там каких-то проблем.

![](https://habrastorage.org/webt/hj/or/qw/hjorqwuc5pn4khboewm2ou3cim0.png)

И здесь мы все делаем, как по известному USE методу. Нам нужно определить использование ресурсов. Если ресурсы используются более-менее хорошо и прекрасно, то мы смотрим наличие ошибок.

![](https://habrastorage.org/webt/as/ez/_h/asez_hivnpftponwarhsbp9dr5g.png)

Для этого мы начинаем смотреть системную информацию. У нас есть информация об использовании процессора. Всем, кто знаком с утилитой линуксовой Top, вот этот раздел статистики будет очень хорошо знаком. Т. е. он показывает утилизацию процессора: системную, пользовательскую.

![](https://habrastorage.org/webt/lz/ic/el/lzicel6s5y1g6kwfam-lc9zkbig.png)

Если нам интересно посмотреть память, то в этой же строке также мы можем посмотреть и память: сколько у нас есть памяти, сколько свободно, сколько занято.

![](https://habrastorage.org/webt/np/4l/vj/np4lvjczw7fxixq-2p1sdjjuuek.png)

И, соответственно, swap. Если в системе есть swap, а для базы данных он важен, то можно посмотреть еще и статистику по swap. Т. е. здесь мы быстро определяем – есть ли у нас проблема с утилизацией ресурсов.

![](https://habrastorage.org/webt/6m/qd/g9/6mqdg9yw1ns3ap8_zzg97unyik4.png)

Кто-то может спросить: «А как с блочным вводом-выводом и сети?». Эта статистика тоже показывается. Ее я покажу чуть позже, по ней тоже есть цифры.

![](https://habrastorage.org/webt/2n/1u/uk/2n1uukefmeisgx0ixat60is_hmc.png)

Когда мы посмотрели нет ли у нас проблем с утилизацией ресурсов, мы можем идти к проверке – нет ли у нас каких-либо ошибок на уровне работы Postgres. Мы можем посмотреть uptime. Вообще, uptime в Postgres – это лживая штука, но тем не менее это лучше, чем совсем ничего. Т. е. можно быстро определить, как давно у нас работает Postgres и не было ли у него незапланированных рестартов.

![](https://habrastorage.org/webt/yg/ie/60/ygie60a26gqjyhbolxqbl-1eip0.png)

Кроме того мы можем посмотреть состояние по подключениям. Т. е. не все клиенты, которые работают с Postgres, они хорошие. У нас могут быть ждущие транзакции, у нас могут быть транзакции, которые находятся в ожидании, которые ничего не делают. Т. е. важно их отслеживать и вовремя такие ситуации разрешать.

![](https://habrastorage.org/webt/vb/7s/7y/vb7s7yoxlu5dbg4e3lizbxjc6qm.png)

И, конечно, автовакуум. Я думаю, многие из вас знают, что такое автовакуум. С ним связано много интересных историй, поэтому про вакуум тоже можно посмотреть. Например, сколько воркеров запущено и посмотреть их длительность. И после этого можно как-то реагировать на эту информацию.

![](https://habrastorage.org/webt/-l/7c/kb/-l7ckbjhj4dsylg-a7x2qcabtok.png)

И долгие транзакции, потому что Postgres MVCC база данных. В ней MVCC движок. И он очень сильно зависит от того, как долго там работают транзакции. Поэтому самые долгие транзакции тоже важно отслеживать и быстро о них узнавать.

![](https://habrastorage.org/webt/gh/j7/le/ghj7le7a-7l1u3ysgpq5wryj9lc.png)

Кроме того, системная вьюха «pg_stat_database» тоже предоставляет некоторое количество информации об ошибках, т. е. это поле «rollbacks». Это не только команда «rollbacks», которая выполняется, но еще и различные ошибки, которые происходят в базе данных. Это могут быть ошибки нарушения constraint, это могут быть ошибки синтаксиса и т. д. По этой статистике можно уже отследить, что происходит в базе. 

И плюс в pg_stat_database есть еще информация по conflicts и deadlocks. По сути, это то же виды ошибок, которые говорят о том, что в базе что-то идет не так.

![](https://habrastorage.org/webt/6n/wk/h2/6nwkh22oadmefjnbvfwleno31bo.png)

ОК, мы запустили pgCenter. И за относительно короткое время мы смогли посмотреть много вещей, ради которых нам бы пришлось запустить несколько утилит. Во-первых, это: 

- top

- vmstat

- iostat

- nicstat

- pg_stat_activity

- pg_stat_statements

Плюс там еще использовали некоторые функции, которые тоже показывают информацию в более понятном виде. 

![](https://habrastorage.org/webt/wa/m4/ho/wam4hohz7mx6rv62czpzxzmymzm.png)

Допустим, что в процессе проверки мы обнаружили, что у нас какая-то есть нагрузка на процессор.

![](https://habrastorage.org/webt/i7/cs/bj/i7csbjggspmjmj6k7igcgk-g5n4.png)

Вот такой простой пример. Вам не обязательно все это рассматривать, важно отследить те места, которые используются в процессе оценки. Т. е. здесь CPU usage – 85 %. Это говорит о том, что у нас нагрузка на процессоры довольно-таки высокая. И нам нужно найти, кто же так активно использует процессора.  Понятно, что это Postgres. Нам нужно заглянуть глубже в Postgres и посмотреть, какие типы запросов у нас больше всего потребляют процессорного времени.

![](https://habrastorage.org/webt/4i/q9/si/4iq9si3nflmq2gjob7ux81ns_bi.png)

Если мы посмотрим на вторую часть экрана, то мы увидим, что у нас 38 активных клиентов, которые что-то делают. При этом нужно посмотреть на соседние state: на waiting и на idle_xact. Waiting у нас 0, т. е. у нас клиенты не находятся в режиме ожидания и это хорошо. С другой стороны, у нас есть 20 ждущих транзакций. Соответственно, мы можем включить сортировку по времени жизни транзакций и посмотреть – сколько времени наши транзакции находятся в режиме ожидания. И здесь видно, что всего одна транзакция находится в режиме ожидания. И ее время жизни – 15 секунд. Это на самом деле нестрашно, это можно считать, что это не криминал.

![](https://habrastorage.org/webt/bs/jm/zm/bsjmzmekxk9m89iyi-incu4pkli.png)

Но мы же ищем источник, кто у нас потребляет больше всего времени. Нам нужно оценить, какие запросы используют больше всего времени. Для этого мы используем pg_stat_statements. Это contrib. Он показывает нам статистику по запросам: сколько они выполнялись, сколько ресурсов потребляли. Этот contrib должен быть установлен в базе, чтобы брать с нее статистику. К сожалению, он включен по умолчанию. И одна из основных рекомендаций по настройке Postgres – это включать pg_stat_statements.

Предположим, что он у нас стоит. Нам нужно посмотреть время, кто у нас тратить больше всего. Мы стрелочками переключаем сортировку. И видим те запросы, которые у нас тратили больше всего CPU с момента сброса статистики pg_stat_statements. Т. е. тут примерно суточный разрез – за сутки конкретный запрос намотал 2 часа с лишним. Т. е. это запрос `SELECT COUNT (*) FROM "game_competition_events"`. Т. е. уже имея на руках запрос, мы можем сходить в логи, взять параметры этого запроса и посмотреть, какой у него план, и попытаться с ним разобраться. Может быть, там нет какого-нибудь index, может быть, там запрос написан неоптимальный или еще что-то. Т. е. уже у нас есть конкретная информация о том, кто потребляет процессорное время.

Но здесь есть небольшая ловушка. Мы используем сортировку под total_time. А в total_time включается не только процессорное время, но еще и время, потраченное на блочные операции: на чтение и на запись. Соответственно, нам желательно включить сортировку по полю «t_cpu_t». Оно нам более релевантно. Оно нам позволяет смотреть именно процессороемкие запросы.

![](https://habrastorage.org/webt/rb/tx/tb/rbtxtb-h59duuj5rnzav8t_kueg.png)

Как я уже сказал, эта статистика показывает самые жирные запросы с момента сброса статистики. Если нам нужно смотреть запросы, которые отнимают процессорное время здесь и сейчас, то мы смотрим уже по полю «cpu_t», т. е. это, условно говоря, дельта. Мы берем snapshot статистики за прошлую секунду, за текущую секунду, считаем дельту и показываем. Здесь запрос уже совершенно другой. Это `SELECT "courses_logs".* FROM course_logs`. Это уже совершенно другой запрос. И здесь видно, что текущую секунду он съел уже 5 секунд времени. Т. е. это либо запрос, который использует параллельные воркеры, либо, возможно, он просто интенсивно запускается. 

И если посмотреть на соседнюю колонку «calls», то там будет видно, что запрос выполняется один. Один запрос в секунду. Т. е. вероятнее всего, что это запрос с параллельными воркерами. 

![](https://habrastorage.org/webt/be/vf/8_/bevf8_xi1tr4u8gthw1femyeqts.png)

Пока мы все это смотрели, мы могли использовать другие утилиты. Это Top и плюс нам нужно было заглянуть в pg_stat_activity и в pg_stat_statements. Но с помощью pgCenter это все в одном месте собрано и можно этим пользоваться. 

![](https://habrastorage.org/webt/lu/8u/wm/lu8uwmka4hdvnqe2ky2a5m46ave.png)

Другой вариант – это нагрузка на ввод-вывод. Это другая противоположность, когда с процессорами у нас все в порядке, но диски слабые и нужно разобраться, кто жрет ввод-вывод.

![](https://habrastorage.org/webt/5r/w4/86/5rw486zd8afdszdzbkvmjuvbwt8.png)

Ситуация похожа на предыдущий кейс. Мы смотрим на утилизацию системы и видим, что у нас время ожидания блочного ввода-вывода довольно высокое – 27 %. Нам нужно найти те запросы, которые вызывают этот ввод-вывод.

![](https://habrastorage.org/webt/gp/lb/2v/gplb2vl2exzmefukpqvmqgpr0uc.png)

Плюс мы можем еще обратить внимание на то, что многие клиенты с типом «background worker». Это явный показатель, что у нас параллелизм включен и запрос выполняется параллельно.

![](https://habrastorage.org/webt/vo/jl/cf/vojlcftweu-mwgx0gyzfvgsrz_w.png)

Посмотрим по соседним «wait_event». И тут видно, что эти клиенты находятся в ожидание ввода-вывода. Т. е. очень много времени тратится на чтение данных с диска.

![](https://habrastorage.org/webt/yp/sq/qo/ypsqqopecjuawv5sybz6ueti4iq.png)

И здесь нам уже понадобится статистика по блочному вводу-выводу. С помощью горячей клавиши мы включаем встроенный iostat. И он нам показывает утилизацию дисковых устройств. Здесь видно, что утилизация одного из устройств 99 %. Но здесь самое главное – это не попасть в ловушку, потому что устройство у нас NVME. И нужно уже смотреть не только на утилизацию, но и на latency.

![](https://habrastorage.org/webt/f0/ty/vu/f0tyvuxnxpzfx0yjkujqtplvafu.png)

Если посмотреть на latency, то latency для этого устройства будет составлять всего лишь 1 миллисекунду. И это вполне нормально.

Это значит, что у нас нет особых проблем в производительности. Это связано с тем, что современные SSD и NVME-устройства выполняют операции ввода-вывода в несколько потоков, поэтому мы можем видеть большую утилизацию, но при этом низкий latency. Если мы видим большие цифры по latency, то это значит, что у нас действительно уже есть проблемы и нужно что-то делать.

![](https://habrastorage.org/webt/e1/xe/ka/e1xekaqycwcpc248k_ak-xzcitc.png)

Но тем не менее давайте смотреть, какие запросы выполняют больше операций ввода-вывода. Мы переключаемся на pg_stat_statements и смотрим уже не процессорное время, а время ввода-вывода. Это колонка «t_read_t», т. е. время, потраченное на чтение данных с момента сброса статистики. 

Аналогичная колонка есть и для просмотра статистики за последнюю секунду. Это колонка «read_t». Мы можем менять сортировки и смотреть, какие запросы за весь интервал времени сожрали больше всего ввода-вывода, либо за последнюю секунду. 

И уже имея текст запроса мы можем переходить к его поиску в логах, найти его параметры и узнать, что там долго там работает. Но pgCenter еще предоставляет такую штуку как queryid. Это такой идентификатор запроса. Но это не такой идентификатор, который предоставляется в pg_stat_statements. Он немного другой. Его можно использовать для построения отчетов. Т. е. pgCenter предоставляет такую функцию как построение отчетов по конкретной группе запросов. Также через горячие клавиши мы смотрим по queryid. И pgCenter предоставляет отчет. 

![](https://habrastorage.org/webt/fp/3x/jj/fp3xjj2ninlijbpv5ftokqbud5s.png)

Отчет состоит из трех частей:

- Первая часть – это summary, т. е. это общая картина, составленная на основе той статистики, которая накопилась в pg_stat_statements. Это количество запросов, затраченное время в процессорах, затраченное время ввода-вывода.

- Вторая секция уже связана уже с нашим запросом, т. е. это секция описывает, какой вклад запрос вносит в общую статистику в summary. И мы уже можем видеть относительные вещи, связанные с этим запросом.  

- И, конечно, сам текст запроса.  

Т. е. строя такие отчеты, мы можем быстро посмотреть, насколько наш запрос вносит нагрузку в суммарную картину. 

![](https://habrastorage.org/webt/ix/7o/56/ix7o56r1vbmc7b_ohgunxzowrxs.png)И если рассматривать, что мы затронули под капотом, пока это все смотрели, то все это покрывается утилитами Top, iostat и вьюхами pg_stat_activity, pg_stat_statements. Плюс там есть еще несколько функций, которые приводят все это в понятный вид. 

![](https://habrastorage.org/webt/cq/lu/8k/cqlu8k4bvwzoi6-evsgvw1lu-he.png)

Но запросы клиентские – это не единственная вещь, которая позволяет делать ввод-вывод. И в Postgres есть еще всякие фоновые задачи, которые тоже могут создавать нагрузку на диск.

Это:

- Checkpointer pocess.

- WAL writer process.

- Autovacuum workers.

- Background workers.

На данный момент pgCenter показывает только прогресс по вакууму, по остальным пока информации нет, но тем не менее это уже хорошо. 

![](https://habrastorage.org/webt/jj/x7/ut/jjx7utmlxkdaeb7uh8vtyr4vnm4.png)

Предположим, что у нас с ресурсами все в порядке: блочного ввода-вывода никто особо не потребляет, с процессорами тоже полный порядок. И мы переходим к вопросу, что нужно посмотреть, что у нас на уровне ошибок.

![](https://habrastorage.org/webt/bf/dt/ma/bfdtmaslqkiiiilzlluqvg2ocfu.png)

И чаще всего это описывается ситуациями, когда клиент пишите в чат, что у него ничего не работает. И нужно что-то делать, потому что все лежит.

![](https://habrastorage.org/webt/hh/uy/mn/hhuymnjtf6zjdpubpertpzphy5e.png)

Здесь мы мельком посмотрели утилизацию ресурсов.

![](https://habrastorage.org/webt/l4/a4/vv/l4a4vvjtnowhf8fl_w2vhynmoie.png)

И тут нужно уже смотреть на состояние подключенных клиентов. Если посмотреть на клиентов, то будет видно, что у нас 22 активных клиентов и при этом 21 из них находится в режиме ожидания. Это уже показатель того, что что-то работает не так. 

Если посмотреть на wait_event этих клиентов, то будет видно, что они все находится в режиме ожидания идентификатора транзакций. Т. е. какой-то клиент что-то делает, а остальные выстроились в некий хвост и пытаются дождаться, когда эта транзакция сделает свою работу. 

Нужно посмотреть на соседнее поле, которое показывает транзакции в режиме ожидания. И здесь мы видим, что их 6 штук. И нужно включить сортировку по времени работы транзакции. Если посмотреть на отсортированное поле, то мы увидим, что у нас есть транзакция, которая 10 минут работает. Если мы посмотрим ниже, то есть еще куча транзакций, которые 7 минут работают. И они явно выстроились как раз в хвост за этой транзакцией. 

Если посмотреть на wait_etype, wait_event этой транзакции, которая ничего не делает, то мы увидим, что она ждет как раз ожидания ввода со стороны клинского приложения. Т. е. приложение открыло транзакции, что-то поделало, а потом ушло делать какую-то другую работу. И, возможно, где-то произошла ошибка, оно упало, но транзакция осталась незакрытой. Пришли другие транзакции и попытались обновить другие строки и прочитать данные, которые изменила эта транзакция, но попали в заблокированное состояние и теперь они все ждут. 

Самое просто решение – это отменить эту транзакцию. Есть две функции: pg_cancel_backend и pg_terminate_backend. Они позволяют отменить запрос, либо просто завершить работу этого backend. В pgCenter тоже есть эти функции. Можно с помощью горячих клавиш убивать как отдельный backend и запросы, либо убивать их группами на основе маски. 

Под капотом

Тем не менее под капотом здесь у нас:

- Pg_stat_activity.

- Pg_stat_statements.

- Pg_cancel_backend ().

- Pg_terminate_backend ().

Впрочем, бывает и по-другому

Опыт показывает, что ситуации бывают разные. Бывает, не только, что собрался хвост из длинных транзакций. 

Бывает долгая транзакция на таблице с очередью. Очереди реализованы в базе данных. У нас есть какая-то таблица. В нее вставляется много inserts, много строк обновляется, много строк удаляется. Пришла какая-то долгая транзакция, которая поработала с этой таблицей, но также она перешла в состояние … transaction и ничего не делает. И у нас также собрался длинный хвост из блокировок и все повисло. 

Другой кейс – это когда приложение в несколько потоков пытается обновлять одни и те же данные. И эти потоки начинают наступать друг другу на пятки. Также возникают ситуации блокировок, deadlocks и все начинает работать нехорошо.

Миграции. Можно сделать ALTER TABLE, добавление колонки, например, с простановкой дефолтных значений. Это очень тяжелая боль. Ее, к счастью, пофиксили. В 11-ой версии это все работает получше. Но тем не менее у многих заказчиков стоят старые версии Postgres, которые эту фичу не поддерживают. И любой такой тяжелый ALTER может также собрать на себе хвост ждущих транзакций и остановить работу приложения.

И классика жанра – это CREATE INDEX без CONCURRENTLY, когда кто-то по незнанию, либо просто забыл, что запустил создание index. Создание index заблокировало таблицу, и появился снова хвост из блокировок. 

1. 
2. ​	Репликация

Сложно представить, чтобы в production был сервер Postgres без реплики, поэтому репликацию тоже нужно отслеживать и смотреть все ли с ней в порядке. 

Для этого есть вьюха «pg_stat_replication». Она показывает клиентов, подключенных к текущему Postgres, которые тянут журнал транзакций с этого хоста Postgres по протоколу репликации. 

И pgCenter тоже поддерживает pg_stat_replication. И можно переключиться с помощью горячих клавиш, и посмотреть, что там происходит.

В данном случае у нас здесь 5 клиентов. Они все подключены и тянут журнал транзакций. Если посмотреть на их имена, то можно будет понять, кто это такие и что они делают. У нас здесь 2 walreceiver, т. е. это конкретно 2 реплики. 

И дальше нас интересует, какой лаг репликации у этих клиентов, потому что лаг репликации непосредственно влияет на величину проблемы, которая у нас есть. Если маленький лаг, значит, более-менее все в порядке. Большой лаг, значит, проблемы есть – реплика сильно отстает по каким-то причинам и нам нужно выяснить по каким.

Соответственно, pg_stat_replication предоставляет разную информацию, которая позволяет нам посчитать лаг в байтах и лаг в секундах. И здесь лаг у одной из реплик на уровне 1,5 GB. И replay_lag в секундах – 2 часа. На самом деле это нормальная реплика. Она просто настроена с отложенным восстановлением журнала транзакций. У нее выставлено восстановление на уровне 2-х часов. Она скачивает все журналы к себе и накатывает только те, которые уже 2 часа прошли, т. е. это вполне нормальная реплика. 

Если мы посмотрим на других клиентов, то будет видно, что у нас есть 2 pg_basebackup и 1 pg_receivewal. Pg_basebackup – это обычный basebackup, который тянет данные по протоколу репликации. Он также виден в pg_stat_replication. И pg_receivewal – это процесс, который тянет журналы транзакций в какое-то удаленное хранилище. Т. е. здесь, в принципе, никакой проблемы нет. Здесь нет каких-то криминальных реплик, которые нужно было бы расследовать.

Но тем не менее pg_stat_replication позволяет показывать лаг в нескольких единицах измерениях. Это байты. И самое интересное, что этих метрик здесь аж 5 штук. Это: pending, write, flush, replay, total_lag. Т. е. лаг репликации может быть разным. 

Pending – это когда журнал транзакций сгенерировался, лежит на Мастере. И Мастер его еще не успел передать реплике.

Write – это когда передача журналов уже идет, но до реплики еще не дошла, т. е. она еще не успела записаться. 

Flush – это когда успели записать уже на реплику, но не успели сбросить на надежное хранилище. 

Replay – это когда сбросили на надежное хранилище. И осталось только проиграть.

Total_lag – это максимальная величина от момента генерации до момента проигрывания.

Соответственно, наблюдая лаг в этих местах, в этих контрольных точках, мы можем более-менее понять, где у нас проблема. Н

апример, проблема на дисковой подсистеме Мастера; либо ошибки сети, которые снижают скорость передачи; либо это загруженная дисковая подсистема реплики, которая не успевает все это писать, прожевывать и воспроизводить.

Кроме того, есть лаг репликации во времени. Он более человекопонятный. Когда людям говоришь про минуты, про секунды, они это лучше воспринимают. 

И последний момент – это лаг репликации в транзакциях, т. е. можно отследить величину – сколько транзакций нужно проиграть реплике, чтобы она догнала Мастера. Эта штука по умолчанию выключена в Postgres, ее нужно включать отдельно. Но она редко бывает нужна, только в каких-то особых кейсах. 

Под капотом

Под капотом этой всей диагностики у нас:

- Pg_stat_replication.

- Pg_wal_lsn_diff().

- Pg_current_wal_lsn().

- Pg_last_commited_xact().

1. 
2. ​	Осталось за кадром

Я вам рассказал все эти кейсы, но за кадром есть еще много других вещей. 

PgCenter top

Например, pgCenter top показывает статистику по таблицам. Табличные статистики – это все сканы, количество апдейтов, делитов, инсертов, живые и мертвые строки. 

Статистика по индексам. Можно посмотреть утилизацию индексов. Отыскивать неиспользуемые индексы и их заносить в черный список, и потом удалять.

Статистика по функциям. Можно смотреть, какие пользовательские функции запускаются больше всего, сколько времени они потребляют. Можно также сортировать, смотреть и выбирать кандидата для оптимизации. 

И, конечно, pg_stat_progress_vacuum появился в 9.6. Раньше вакуум был темной лошадкой, было сложно понять, как долго работает, как быстро он закончиться и сколько ему еще работ надо делать. И pg_stat_progress_vacuum – это глоток свежего воздуха, новый взгляд. Можно оценить, сколько ему там осталось доработать. Хотя, конечно, есть недостатки, есть претензии к нему. Но тем не менее лучше, чем ничего. 

И есть вспомогательные админские функции для самого администратора. Это просмотр логов, просмотр конфигурации, изменение конфигурации, т. е. мы можем через горячие клавиши открыть postgresql.conf, что-то в нем поправить и потом горячей клавишей сделать reload. Это не самая правильная практика, конечно, но тем не менее возможность есть. 

Плюс есть функции по просмотру логов. Т. е. вам не нужно помнить, где же лежит лог, как он там и что. Горячую кнопку нажимаем, и он открывает в пейджере лог. Можно его смотреть, можно найти там нужный запрос с нужными параметрами, скопировать и изучить его. 

Плюс есть функция вызова PSQL, т. е. мы также нажимаем горячую клавишу и у нас открывается PSQL к той базе, к которой у нас подключен pgCenter. Т. е. если какие-то вещи, которые нам надо сделать, мы не можем сделать с помощью pgCenter, мы можем их через PSQL выполнить. 

PgCenter record, report

pgCenter top – это основная утилита, которая развивалась изначально. Но помимо Top есть еще другие утилиты, которые тоже являются частью pgCenter. Это record и report.

Суть в том, что мы делаем мгновенные снапшоты статистики и сохраняем их в файлике. Мы можем раз в минуту, раз в час запускать эти снапшоты, они будут там сохраняться. А потом с помощью report строить отчеты, аналогичные тому, что показывает Top. Т. е. для некоторых функций это бывает полезно. Я использую это для микро-benchmark. Когда мне нужно что-то потестить, погонять, я запускаю pgCenter record. Раз в секунду он там все записывает, т. е. мне не нужно ставить там никаких мониторинговых агентов. Я могу это все так быстренько посмотреть. 

Плюс недавно я добавил wait_event’ов, т. е. можно брать свои долгие запросы и смотреть, на каких участках запрос тратит свое время. Вот простой пример: SELECT* из таблицы и сортировка по балансу. Т. е. если посмотреть, куда тратится время, то видно, что 44 % времени запрос выполняется, делает какую-то полезную работу, а оставшееся время – это ожидание ввода-вывода при чтении файлов, взаимодействие между параллельными воркерами. 

Второй пример: это vacuum full. Здесь видно, что большая часть времени vacuum full делает дисковый ввод-вывод. Он читает данные, т. е. работает он всего 12 %. Вот эта штука довольно полезная, когда есть любопытство попрофилировать свои долгие запросы и посмотреть, чем они занимаются.

И на этом все, спасибо за внимание. Если есть вопросы, задавайте. 

Вопросы

*Спасибо за утилиту! Лично я ею пользуюсь. Она мне нравится. Я часто использую ее с ноутбука. И когда я смотрю, например,* *pg**_**stat**_**statements**, у меня колонка* *query* *с текстом не влезает. Есть ли какая-то возможность поменять порядок столбцов или какие-то столбцы отключить на время?*

К сожалению, такой функции нет. Архитектурно программа так устроена, что эта фичу тяжело запилить, но можно, наверное, что-то придумать там, переписать и такая функция появится. Как минимум, не перестановку колонок, а отключение-включение по желанию. Но отсюда вылезает второй вопрос. Наверняка кто-то захочет сохранить отображение этих колонок и при последующем запуске показать. Т. е. появится необходимость конфига, который нужно поддерживать, хранить где-то. Это такая задачка, которая собирает еще другие задачки, чтобы ее реализовать. Я думаю, что это можно сделать, но пока этого нет. 

*И второй комментарий из той же оперы. Когда режим базы данных, то у вас количество* *rollbacks**… Иногда хотелось бы отличать* *rollbacks**, которые были по команде от тех* *rollbacks**, которые не по команде.* 

Это, к сожалению, невозможно, потому что сам интерфейс pg_stat_database не позволяет такого. Он показывает только rollbacks и все. 

*Там можно из* *pg**_**stat**_**statements* *считать* *rollbacks**, вычитать.*

Можно, если заморочиться. Можно расширить запрос. Мы делаем SELECT*FROM pg_stat_database JNOIN pg_stat_statements под запрос к pg_stat_statements, где мы считаем rollbacks и плюс арифметика, которая это все высчитывает. Теоретически можно. Но нужно посмотреть, как быстро будет работать этот запрос и не займет ли выполнение больше 10-20 миллисекунд. 

*Алексей, спасибо за доклад! С какой минимальной версией* *Postgres* *ваша утилита работает?*

Я ее тестировал с версии 9.01, когда еще на C писал. Если какие-то запросы, особенно связанные с репликацией, не работают, то она пишет небольшую ошибку и есть возможность переключится на другой скрин, на другую статистику. Гошную версию тестировал, начиная с 9.4. Потому что в 9.4 появился функционал, когда мы берем SELECT v-filter. Это такой синтаксис интересный. В старых версиях его нет. А у меня часть запросов как раз используют этот синтаксис и в старых версиях это работать не будет. Либо это будет работать, но будет показывать нули там, где эта статистика используется. Но я стараюсь на всех версия тестировать, проверять, чтобы, как минимум, ошибок не было.

*Алексей, спасибо за утилиту! И спасибо за то, что интерфейс там от* *Top**. За это двойное спасибо.* 

Более того, я старался горячие клавиши делать, похожими на другие утилиты. Например, кнопка фильтра – это слеш. Кто знаком с лесом (пейджер такой), то слеш – это поле ввода, чтобы набрать шаблон для поиска. 

*У меня вопрос по поводу сортировки. Там так же как в* *Top* *подсветка поля идет сортируемого?*

Да. У меня на скриншотах это не видно, я, видимо, упустил этот момент. На некоторых скриншотах видно, на некоторых не видно. Да, поле подсвечивается. Когда вы стрелками перемещаетесь, вы видите, что у вас сортировка меняется и имя в колонке подсвечивается. 

*Спасибо за утилиту! Сегодня в первый раз о ней узнал. Оказывается, столько много возможностей. Вы размышляете, что вот у меня 85* *CPU* *usage**, давайте проанализирую, что сейчас происходит. Для этого пойду и обращусь к временным снимкам* *pg**_**stat**_**statements**. Но там же архив находится. А нас интересует, что сейчас происходит.* 

Не архив. Давайте я вам покажу. Вот нагрузка на CPU. У нас есть два поля. Первое – t_all_t. Это сколько времени намотал запрос со времени сброса статистики pg_stat_statements. Условно, у нас суточный срез. Если мы раз в сутки сбрасываем статистику, то мы получим статистику за текущий момент от начала суток. Плюс есть разбивка t_ и они уже здесь заканчиваются. Т. е. у нас есть аналогичные поля без префикса «t». Они как раз нам показывают статистику за текущую секунду. Т. е. мы можем смотреть, сколько процессорного времени потрачено запросом прямо сейчас.

*Это понятно. Но если сейчас происходит то, что еще нет в* *pg**_**stat**_**statements**, то как мы это проанализируем?*

Мы каждую секунду выходим к pg_stat_statements и берем снапшот статистики прямо в real time.

*Вопрос был в том, что в* *pg**_**stat**_**statements* *залетит уже после, а цифра 85* *CPU* *usage* *– она сейчас.* 

Да, расхождение статистики будет. Но вы все равно можете смотреть текущую статистику, которую вам pg_stat_statements показывает. Если вы видите, что у вас использование процессора упало, то вы уже не увидите тот срез статистики, который был 10 секунд назад, когда использование процессоров было высокое. Тут нет такой интроспекции на 10 секунд назад – запомнить и отмотать, как это сделано, например, в Atop. Вы на Atop намекаете?

*Примерно, да. Тут некое будущее и прошлое* *pg**_**stat**_**statements**, а* *CPU**, которая сейчас, нужно потом проанализировать, что залетит в* *pg**_**stat**_**statements**.*

Для этого придумана система мониторинга. Например, Grafana, там есть отрисовка графиков и вы уже в исторической перспективе все эти графики смотрите и анализируете. Т. е. pgCenter – это инструмент, который нам нужен здесь и сейчас, чтобы быстро продиагностировать, быстро понять, что происходит.

*В связи с этим же вопрос.* *pgCenter* *умеет как* *Atop* *сбрасывать статистику в текстовом виде, чтобы потом можно было запихнуть в* *Grafana**?*

Есть функции pgCenter report и pgCenter record, т. е. можно снапшоты статистики сбрасывать в текстовые файлы. Единственное, что там нет интерфейса, как по стрелочкам переключаться и смотреть. Т. е., условно говоря, с помощью pgCenter report запросить нужную статистику, например, по pg_stat_database и он прочитаем там все файлы накопленной статистики и как Corsair покажет. Я вдохновлялся больше им. Нет такого как у Atop, когда можно стрелочками работать.

*Алексей, большое спасибо! В отличие от всей известной базы Х, в* *Postgres**, к сожалению, нет, кумулятивных статистик ожиданий. Вы сделали профайлер, который показывает разброску по ожиданиям. А с какой частой вы их опрашиваете? Какая там детализация?*

Дефолтный интервал в 10 миллисекунд. А через флажок «-f», можно указывать частоту детализаций. Понятно, что высокая частота детализации, например, в 10 миллисекунд тоже создает нагрузку на систему. Но учитывая, что pg_stat_activity в памяти, то запросы там довольно легковесные. Они доли миллисекунд занимают. Но если такая частота напрягает, можно менять. Поставить, например, раз в 50 миллисекунд. Я замерял, как отражается это на конечной статистике, там погрешность есть на уровне 1-2 %. Т. е. если просуммировать все столбики, то мы увидим, что у нас куда-то 0,5-2 % потерялось. 

*Там в конце суммарная статистика есть. Можно видеть, что что-то потерялось.*

Да, там видно будет. Да, даже на нашем примере мы видим, что 0,04 % не учли. Но, я думаю, это не критично. Это не какой-то инструмент для хардкор аналитики. 

*Но лучше все равно ничего нет.* 

Интересно просто посмотреть, что там у нас происходит. 

*Алексей, спасибо за доклад! Вдогонку вопрос по профайлеру. Вот этот* *wait**_**event* *Running* *– это просто отсутствующий?*

Да.

*Я его воспринимаю как ожидание на* *CPU**.*

Да, именно так. Т. е. когда мы заметили, что wait_events у этого PID нет, то мы считаем, что backend делает какую-то полезную работу, прямо крутится на процессоре, что-то высчитывает. И мы закидываем в Running, типа он работает, т. е. он не находится в ожидании. 

*Но все же это ближе к* *CPU**?*

Да, это ближе к CPU, т. е. запрос делает какую-то работу. Это не ожидание. 

*Привет! Спасибо за доклад! Насчет пакетирования есть какие-то планы, например,* *Ubuntu**?*

Когда она была написана на C, то все майнтейнеры были радостные. Говорили, что круто, сейчас тебе пакетов насобираем. И в официальном репозитории PDGD были пакеты собраны для Ubuntu. Я на Launchpad собирал пакеты, но у них какая-то странная система сборки. Бинарник иногда сегфолтится. И я не мог понять, почему так. А сейчас на Go у меня просто Мастер-ветка, dev-ветка. В Мастере она релизы отсчитывает. И когда я делаю коммит с релизом, то travis-ci не только делает build, он еще делает build бинарника и выкатывает его в раздел релизов. Т. е. если посмотреть в Realeses, то туда релизы будут сваливаться. Вам остается только взять Vegeta, сходить по ссылке, забрать и распаковать tar’ом архив, и можно будет пользоваться. 

*Есть проект* *Goreleaser**, который позволяет автоматизировать это. И можно собирать пакеты.*

Круто, я с GO не очень знаком. Я еще раз повторяю, я не профессиональный программист. Я не знаю, что такое SOLID. И то, что вы говорите, что Goreleaser есть, это интересная штука, я посмотрю, что это такое. Раньше C’шные исходники у меня собирались, и я был счастлив. А сейчас мне приходится всем говорить, что есть ссылка на Realeses. Спасибо за совет!

*Алексей, вопрос по поводу* *queryid**. Мы там видим* *queryid**. У вас получается, что там поле немножко урезано и мы хвост не видим. Мы можем его полностью увидеть?*

Да, конечно. Если мы не будем обрезать названия, то у нас в какой-то момент ширина колонок будет прыгать. И это для глаз не очень хорошо, плохо воспринимается. Поэтому ширина колонок рассчитывается под какую-то величину. Величина рассчитывается по сложному кейсу. Но в итоге ширина колонок ужимается и не прыгает. Если мы хотим ее увеличить, то мы стрелочкой переходим на это поле через сортировку. А потом стрелкой вверх увеличиваем ширину. А стрелкой вниз можем уменьшить ширину. И она сохраняется. Вы потом дальше можете сортировку менять, у вас ширина поля останется той, какой вы задали.

*Ясно, это важный момент, потому что* *queryid* *– это четкий адрес.* 

Да, изначально ширина колонок прыгала и это раздражало. Я в dev-ветке это поправил, а в Мастер-ветке этого пока нет. В середине февраля я хочу выпустить Event Profiler. И как раз фиксированная ширина колонок будет. 

*Замечательно.* 

Да, через стрелки можно регулировать ширину.

*Спасибо, Алексей!*

Спасибо большое вам!







![](https://habrastorage.org/webt/i9/fs/a5/i9fsa52ag9kwg_5clfbyrswrsi8.png)

![](https://habrastorage.org/webt/ae/l3/ye/ael3ye_vydpudqcrho-xmqljguu.png)

![](https://habrastorage.org/webt/hh/pa/jy/hhpajyn-3_7ld00momu8b7k_gk0.png)

![](https://habrastorage.org/webt/ag/zy/rt/agzyrtdg9-nrmhktrg3ub_fx5eu.png)

![](https://habrastorage.org/webt/py/ck/gj/pyckgjbcaf1rc5gtq1vjkxbjaiw.png)

![](https://habrastorage.org/webt/rt/ij/jm/rtijjm-xng842mjtnyemrf_o-dw.png)

![](https://habrastorage.org/webt/sh/qw/rh/shqwrhk9o1v9zxcfi-vgobnb-fu.png)

![](https://habrastorage.org/webt/ff/tq/f6/fftqf6fvkjgpkhceg33r8p-ti9c.png)

![](https://habrastorage.org/webt/vq/lt/xs/vqltxssnw69vhtlzaieaygbd0hy.png)

![](https://habrastorage.org/webt/-r/uz/hf/-ruzhfbfuydomh9gk_uiqq2rx24.png)

![](https://habrastorage.org/webt/i9/qa/0x/i9qa0xjm4-wzgy7stx6-dsm6bi4.png)

![](https://habrastorage.org/webt/dd/yh/we/ddyhwentwfs65a09cmc195zpuoa.png)

![](https://habrastorage.org/webt/5h/dh/an/5hdhaneor7w8-wrzj7xs0_sbqgc.png)

![](https://habrastorage.org/webt/0z/kt/jp/0zktjpvqmouvpu3tivmsgdas6eu.png)

![](https://habrastorage.org/webt/bf/cp/qx/bfcpqxfzhmcka2_przsngz6jhs0.png)

![](https://habrastorage.org/webt/29/q5/z0/29q5z0bsl59k_q3m7prh_a5m9pi.png)

![](https://habrastorage.org/webt/gf/8i/ij/gf8iijwr61pkhdylduyhqavz0ws.png)

![](https://habrastorage.org/webt/qu/dy/ag/qudyageigyjrprl7ob74vczyrio.png)

![](https://habrastorage.org/webt/2u/4d/x0/2u4dx0bujjdlddgtnm1e6rvjnyc.png)

![](https://habrastorage.org/webt/lj/l-/lx/ljl-lx1ukvsvfnthbpzh5uyzb_k.png)

![](https://habrastorage.org/webt/dz/uk/4i/dzuk4i7gn_b0evxafqlgowz-q0m.png)

![](https://habrastorage.org/webt/nl/e7/ss/nle7ssgxr15rgjddnfjv0aiscdi.png)

![](https://habrastorage.org/webt/ac/4b/zu/ac4bzu9golpff9rger53zojeyse.png)

![](https://habrastorage.org/webt/rq/j-/bu/rqj-buxh0ebqgbwgdchhnny8xly.png)

![](https://habrastorage.org/webt/l4/ze/ro/l4zeroomn-ai2mwdkzh-wzgpna4.png)

![](https://habrastorage.org/webt/pz/n8/do/pzn8doxswlxet4kbntn3dgwmrau.png)

![](https://habrastorage.org/webt/-n/en/ms/-nenmsxqwjmvaizdhqqvdpqj6nq.png)

![](https://habrastorage.org/webt/lu/e0/wb/lue0wborpecwc8rtmx_8zjftttm.png)

![](https://habrastorage.org/webt/fd/bk/mj/fdbkmj5xbm8irymj4ccrbi-dohq.png)

![](https://habrastorage.org/webt/nj/fd/iz/njfdizke09pnj36updzdsxlpw6g.png)

![](https://habrastorage.org/webt/q7/_z/up/q7_zupl4_gnvo0quuuba33a4xn0.png)