

**Предлагаю ознакомиться с рашифровкой доклада Андрей Сальников из Data Egret "Инструменты создания бэкапов PostgreSQL"**



Данный доклад посвящен доступным инструментам бэкапирования PostgreSQL. Логические backup-ы, бинарные backup-ы, встроенные средства бэкапирования и сторонние инструменты. Нужны ли инкрементальные backup-ы, когда они могут действительно помочь. Посмотрим, когда и какой инструмент уместнее использовать. Как лучше автоматизировать процесс бэкапирования и проверки целостности сделанного бэкапа. Посмотрим вблизи на инструменты, такие как pg_dump, pg_basebackup, barman, wal-e, wal-g, pgbackrest, BART и pg_probackup.

https://www.youtube.com/watch?v=Us6cHVNA4vk

кат

Меня зовут Сальников Андрей, я сотрудник компании Data Egret и этот доклад будет посвящён инструментам создания бэкапов в PostgreSQL.

![](https://habrastorage.org/webt/qr/pa/mu/qrpamu1psbed1aonvt1shrrpedk.png)

Сначала о том, кто мы, моя компания. Основная наша деятельность: мы работаем как удалённые администраторы и у нас достаточно большое количество клиентов. Есть огромные базы, есть куча маленьких баз, есть всевозможные смеси, когда одна большая база или кучка маленьких. Также мы оказываем услуги консультирования и аудита – это случай если людям не нужна постоянная поддержка, но нужна какая-то экспертиза. 
Так как PostgreSQL является открытым продуктом, то мы, естественно, учувствуем во всевозможных конференциях, в плане того, что делится своим опытом и всячески помогать продвижению PostgreSQL. Потому что база данных PostgreSQL действительно хорошая. И получается так, что мы видели довольно много профилей нагрузки: DWH нагрузки, и WEB нагрузки, и смеси нагрузок. И базы падали по-разному. Опыта достаточно много.

![](https://habrastorage.org/webt/a0/vc/b_/a0vcb_l47qx4vvzh1hxnjcqesz4.png)

Это самая интересная часть доклада. Зачем нужны backup-ы? На самом деле они нужны, чтобы мы могли отдыхать спокойно, чтобы могли спать спокойно, чтобы мы могли тусоваться на концертах спокойно. Вот, это основная цель с точки зрения базы зачем нужны backup-ы. Чтобы все было спокойно в нашей жизни. Потому что, если есть backup-ы проверенные, то мы можем всем этим заниматься. А вот что там с базой произойдет это уже дело десятое.

![](https://habrastorage.org/webt/dj/_9/aj/dj_9ajbympb3eslx0bl1phlp6te.png)

Какой есть ассортимент инструментов для создания бэкапов в мире PostgreSQL? Это встроенный инструмент pg_dump, pg_dumpall или pg_restore для восстановления. Это единственный инструмент, который позволяет делать вам логическое бэкопирование. То есть pg_dump он вам может, как в SQL вывалить, так и в небольшом бинарном формате вывалить данные. И он идет из коробки с PostgreSQL. 
Следующий инструмент (pg_basebackup) для создания бэкапов, который тоже идет из коробки и дальше начиная с этого инструмента, и дальше они все будут инструменты для создания бинарных бэкапов базы данных. Pg_basebackup тоже инструмент, идущий из коробки, который позволяет нам наливать реприки для PostgreSQL и снимать бинарную копию базы данных, снимать персистентную базу данных и, если мы хотим еще во времени иметь возможность архивироваться, то мы можем настроить PostgreSQL так, чтобы архивные логи его сваливать на какой-то диск. Это вот базовые инструменты. Они хорошие, они делают, выполняют свой функционал на 5, но они неудобные с точки зрения управления и какой-то массовости. Когда у вас 20 баз данных, это нужно будет вам заниматься шелскриптингом самостоятельно.
Следующие два инструмента специфичные, чисто облачные инструменты – это wal-e и wal-g. Разрабатывают их одни и те же ребята, но разработка wal-e закончилась, и они переключились на wal-g. Эти инструменты ориентированы для в основном для AWS и для хранения в S3. Wal-e еще умеет работать с Google Cloud, с Azure и с дисковой системой, просто вы можете указать какой-то удаленный диск. Wal-g работает только с AWS, только с S3. Ну или любым другим с S3 похожим интерфейсом. Мы их используем, хорошие штуки. Я дальше в деталях буду разбирать каждый инструмент.

![](https://habrastorage.org/webt/h_/cs/my/h_csmywtln65xfdmoryutenb6-g.png)

И на следующей пачке инструментов, это инструменты, которые опираются на pg_basebackup или используют его напрямую, или каким-то образом реализуют его функционал. Они все написаны разработчиками, которые коммитят в основной PostgreSQL и имеют свой форк коммерческий, который продвигают в своем кругу влияния. 
Наиболее популярный инструмент barman, который у нас используется довольно широко в стране. Это по сути дела обертка на Python вокруг pg_basebackup. Еще он может работать по ssh протоколам. Очень интересный и очень многообещающий инструмент pgbackrest. разработчиками занимаются PostgreSQL и активно в него коммитят. Изначально он был написан на Python. Сейчас версия, которая используется - она написана на C для ускорения и возможности параллельного выполнения снятия бэкапов. 
Pg_probackup – эта утилита от наших коллег российских в PostgreSQL Professional, которая позволяет делать инкрементальные backup-ы, такие достаточно небольшого размера.
И последняя утилита это backup and recover tool (BART) от компании EnterpriseDB. У нас она не очень популярна. Она в основном для CentOS и Red Hat. Для Ubuntu с ней, по-моему, тяжело. И в связи с малой популярностью BART у нас, ее (BART) почти нет нигде в инсталляциях. 

![](https://habrastorage.org/webt/ow/si/t8/owsit8h0n3welzlugm95_glqdds.png)

Я бы попытался по этим инструментам разбить на какие-то вещи, которые важны.

- Первое нам важно, как мы будем это хранить, на каких дисках и на каких сервисах. И там есть список характеристик, по которым мы пройдемся. 

- Следующее разделения данных, тут я подразделяю то, что можем ли мы при снятии бэкапа или восстановлении бэкапа, отпилить от целого истанса (сервера) базы данных какой-то кусочек и работать дальше с ним как с целостным, с целостной базой.

- Насколько они поддерживают разные версии БД. 

- Какие режимы работы у них есть в плане параллельности, в плане какой-то автоматизации и тому подобное. 

- И сервисность это насколько мы можем их выделить в отдельный сервис, который сам будет ходить по базам данных и по какому-то расписанию снимать backup-ы.

- Валидирование — хотелось чтобы бэкап еще проверялся в плане того, что мы из него гарантировано потом сможем восстановится и у нас будет нормальная, не поломанная база. 

  И теперь вот, по этим шести большим пунктам пройдемся более детально. И буду помечать там какой инструмент, что нам даст. 

![](https://habrastorage.org/webt/s5/v0/h0/s5v0h0p62rsqz1r86v2upwibj5c.png)

По хранению, в файловой системе хранить они могут все, то есть мы может перемонтировать диск наш к операционке и копировать туда backup-ы. Все инструменты это позволяют делать. Примонтированный сетевой диск - это в принципе тоже самое, потому что это в нашей локальной файловой системе получается.
В AWS (S3) у нас могут работать три инструмента - это wal-g, wal-e, pgbackrest. Потому что среди вот таких утилит: barman и так далее, он единственный, который умеет работать с AWS (S3). 
С Azure только wal-e. Google Cloud только wal-e. 

![](https://habrastorage.org/webt/gw/sc/qd/gwscqdmvmqlbe1r1e545ipkemzs.png)

Логическую копию данных нам предоставляет только pg_dump, pg_dumpall. Разница между ними, то что pg_dumpall обрабатывает весь инстанс (сервер) базы данных, в pg_dump вы можете указать конкретную базу данных на инстансе и работать с ней.
Бинарный копии - все остальные. Немаловажный фактор при хранении, это то что, если у нас ограничено каким-то образом по дисковым ресурсам, то частенько возникают ситуации, когда мы разбиваем базу данных по разным табличное пространствам. Это верно и для железных серверов, потому что не хочется мучиться с RAID. Это верно для облаков, потому что потому что там есть определенное ограничение, особенно когда берете тачку с NVME дисками и сколько подключено, столько подключено. У AWS инстансы расширяются, но EBS дисками. И при восстановлении данных, нам будет важно, что мы могли бы перераспределить эти табличные пространства, назначить их по новым путям и на новые диски. И вот это хорошее свойство присутствует у wal-e. В wаl-g пока не умеют с этим работать. Pg_probackup умеют с этим работать. Barman, basebackup, pgbackrest. Эта вещь бывает довольно часто важна, особенно когда да у вас 8-10 ТБ базы данных. У нас среди клиентов production почти все эти базы данных развалены по табличным пространствам. 

![](https://habrastorage.org/webt/qd/-v/sk/qd-vskcocq-r2tv0duopeyxtvke.png)

Теперь о том, какого размера у нас могут быть backup. Это всё пойдёт в контексте бинарных backup. Понятное дело, что бинарные backup - это сколько у нас база весит, столько мы и скопировали. Весит 8 ТБ, мы скопировали 8 ТБ. 1 МБ весит 1 МБ, скопировали. Как экономить место, когда мы хотим длинную цепочку backupов? Для этого придумали некоторые инструменты. То есть, база данных хранит данные в своих файлах. Если у нас есть длиная архивная база данных, то обычно мы меняем там небольшой % этих файлов. И для этого дела придумали дифференциальный backup.

Дифференциальный backup что из себя представляет? Мы смотрим какие файлики изменились и только копируем на хранилище, где хранить backup. А все остальные файлы мы хардлинком просто прилинкуем к этой базе данных. Получается, что мы тем самым экономим место. И при этом можем спокойно удалить старые backupы базы данных, не попортив более свежие. 

Эта штука хорошая, но решили пойти дальше и придумали инкрементальные backup. Инкрементальные backupы есть два вида. 

Первый это на файловом уровне. От дифференциального backup отличается только тем, что дифференциальный backup ориентируется у вас на полный backup базы данных, и по отношению полному backup копирует diff файлов и копирует. Инкрементальный backup может ориентироваться на дифференциальные backupы, копирует только те изменившиеся файлы, которые изменились по сравнению с дифференциальным backup. Для инкрементального нужна будет вся цепочка бекапов. То есть основной backup -> 1-й инкрементальный backup (он всегда будет дифференциальным) -> дальше все инкрементальные backupы. Дифференциальный backup всегда ориентируется на полный backup базы данных. Инкрементальный может ориентироваться на другие виды backup. 
Pg_probackup и BART пошли по пути создания инкрементальных backup по блоку. Потому что мы можем изменить не весь файл, а блок данных. И эти утилиты бегут по wal файлам и выбирают у вас ровно те блоки, которые изменились. В backup копируют именно вот эти блоки. Для того, чтобы восстановиться с таким инкрементальным backup, вам тоже нужна будет полная копия базы данных и плюс ещё нужно сохранить вот эти инкрементальные кусочки, которые набирают из wal. Это накладывает некоторые ограничения утилиты, потому что они должны бегать по wal файлам. У PostgreSQL Professional наложен еще слой на файловую структуру базы данных. Поэтому они довольно быстро эти блоки ищут. Такие инкрементальные backup получаются совсем небольшими. Если у вас меняется небольшой % базы и из-за того, что в wal файл пишется довольно много технической информации, эти утилиты бекапят по десяткам килобайтам данных для 1 wal.

![](https://habrastorage.org/webt/s3/d9/ca/s3d9ca1otjtkwql3_qakv67am7c.png)

Дальше разделение данных. Тут подразумевается то, что, если нам нужно бекапировать не всё. Или восстанавливать не всё. Это возможно только при логических backup, и это нам позволяет делать только pg_dump. Утилиты довольно широкий функционал предоставляют. Pg_dump может позволить вам сдампить базу данных, структуру, если вам нужна. Можете конкретно одну таблицу сдампить или можете исключить одну таблицу из дампа или список таблиц сдампить, список исключить. Функционал довольно широкий в этом плане. Минус за это то, что при восстановлении с такого дампа, если у вас большая база данных, вам придется потратить достаточно много времени на чтобы восстановиться с него, потому что это всё нужно проигрывать на чистом instance PostgreSQL. 
Очень удобны эти утилиты использовать случай, когда мы переоценили свои силы и на создавали кучу мелких баз данных. Мы можем их слить в один instance. Мы можем распилить так, если мы опять теперь оценили наши силы, у нас распухла база данных или меняем архитектуру там с монолита на сервисную и распиливаем данные. Pg_dump в этом случае единственная вещь, которая позволяет это делать болезненно. 

Ещё можно восстановить одну БД и вот тут вот указан pgbackrest. У него есть такая фишка, то что мы можем указать, что нам из бинарного backup нужна только одна база данных. Что он делает? Он восстанавливает база данных по умолчанию из backup, это template и postgres и ту базу данных, которую мы указали. Все остальные базы данных, он файлы обнуляет и делает нулевой длины. То есть у PostgreSQL прозрачная структура хранения баз данных в файлах, там можно на этом уровне, как бы сократить восстанавливаемую базу данных. Допустим нам нужно найти какие срочные данные из бинарника, не хочется 10 ТБ базу поднимать, у нас там две базы, и мы поднимаем одну, которая допустим 5ТБ всего занимает. В данном случае, конечно консистентность нарушается, но для каких-то быстрых решений, когда вам необходимо срочно кровь из носа поднять данные с большой базы данных, которых несколько, то это очень хорошие фичи, которые есть. Но как полноценную backup базы не стоит рассматривать при восстановлении. То есть, это именно для аварийных работ.

![](https://habrastorage.org/webt/bq/pf/aj/bqpfaj0wvrtn1atsq0yj1j4x7de.png)

Как обстоит работа с множеством версий БД? Тут тоже всё достаточно интересно. Pg_dump очень хорош в плане того, что мы не привязаны к тому, в какую версию БД восстанавливаться. Там есть режим plain text и это просто чистый SQL, который описывает всю структуру базы данных, все данные. Вы можете в принципе оттуда восстановиться куда хотите, в MySQL, в MSSQL, в Oracle с небольшими правками этого дампа. Между мажорными версиями PostgreSQL тоже достаточно легко использовать эти дампы. 
Мульти-версионность, что под этим подразумеваю? Это то, что насколько утилита может обрабатывать разные версии баз данных и работать одновременно с PostgreSQL 9.6, 10, 11. Все, кроме встроенных от pg_dump и pg_basebackup, потому что они привязаны к конкретной версии, с которой идут. Остальные ориентируется на эти утилиты. Им можно указывать где находится pg_basebackup, pg_dump разных версий. Они соответственно с версией PostgreSQL выбирают актуальную утилиту для снятия backup. 
Для создания реплик, standby серверов подходят все утилиты, кроме pg_dump, потому что это логические backup-ы. Используя любую из этих утилит, вы можете, восстановить серверы и подключить к мастеру для работы, как реплика этого сервера.

![](https://habrastorage.org/webt/rk/mr/jp/rkmrjpvyme8ifuybv7jvpkqd0r4.png)

Как могут сниматься backup-ы вообще, какие режимы существуют для снятия бэкапов. Можно просто копировать файлы стандартными средствами операционки: по ssh (rsync, scp) протоколу и возможно какие-то другие утилиты, которые есть. Почему такая возможность есть, потому что они позволяют параллелить копирование. Pgbackrest только так работает, barman он может работать так, а может работать по протоколу PostgreSQL.
Протокол PostgreSQL - когда утилита бэкапирования подключается к PostgreSQL и по протоколу репликации тянет все файлы и плюс еще архивные логи, которые возникают в процессе снятия бэкапа. Это умеют все остальные и barman.
Бэкап с реплики умеют в принципе все, это зависит от версии PostgreSQL. С PostgreSQL 10 и 11 мы можем с реплики снимать backup-ы. Но я этого не рекомендую делать, вообще никто из нашей компании не будет это рекомендовать делать. Потому что есть ситуации, когда проморгали по мониторингу, месяц снимали с реплики бэкап, которая отвалилась от мастер-сервера и не актуальна. То есть backup-ы в любом случае всегда нужно снимать с мастер-сервера. Только в таком случае вы будете уверены то, что у вас действительно актуальная бэкап база данных.
Многопоточность бэкапов - это умеют все, потому что все по разным причинам, кто-то через ssh протокол, кто-то реализовал на уровне копирования базы данных. Кроме pg_basebackup и BART, потому что BART операция только на pg_basebackup при снятии бэкапа и он, к сожалению, однопоточный и не будет многопоточный.

![](https://habrastorage.org/webt/72/4x/j0/724xj0dcehoennfciyo2uzucisq.png)

Пример многопоточности. Я восстанавливал 8 ТБ базу данных. Когда будете ориентироваться на выбор системы для снятия бэкапов, то знайте что wal-e написан на Python, wal-g написан на Golang. Мне 8 ТБ базу приходилось восстанавливать. Wal-e уперся в ограничение Python и тянул меня с AWS со скоростью 600 мбит/с. Когда я переключился на wal-g, то у него был ситуация, что он не мог работать с бэкапами wal-e, но мог тянуть wal файлы. Поэтому вот эта вот картина по середиине - это  восстановление базы данных. Дальше накатывал wal, которые лежали там в S3 и к определенной точке во времени восстанавливался. Wal-e уперся в ограничение Python и параллелизм в Python она такой условный. A wal-g уперся в интерфейс S3, то есть насколько быстрый S3 каждый момент мог отдавать, настолько быстро он и забирал. В среднем это было 2 гбит/с, что достаточно хорошо. То есть с wal-e час изменений в базу получали за 45 минут накатывания бекапа. С wal-g получилось, что они час изменения базы данных накатывали где-то минут за 5.

![](https://habrastorage.org/webt/rj/nk/fa/rjnkfaa9ld-am4dazwrasjqwfbk.png)



Режимы работы, что тут есть у нас интересного в системе бэкапирования. 

- Восстановление во времени к определенной точки. Если у нас есть архивные логи, и мы их копируем, мы можем их восстановить. Позволяет это делать система бэкапирования, это как бы стандарт фактор. Главное, чтобы мы хранили wal файлы где-нибудь. Дампы, естественно, это не умеют, потому что они немножечко о другом.
- Регулировка нагрузки на сеть – это довольно важная вещь, потому что как я говорил снимать дамп с мастер-сервера желательно, тогда вы себе гарантируете то, что вы действительно актуальные бэкап получаете. Ну иногда бывает сервера настолько нагружены, что вклинится туда довольно сложно. У нас некоторые клиенты втыкают отдельный сетевой интерфейс. Иногда там минимальные время нагрузки делается. Еще хорошо, когда мы можем указать нагрузку на сеть при создании бекапа. Это позволяет делать pg_basebackup, barman и BART, wal-e, wal-g.
- Сжатие на лету. Это вопрос к тому сколько мы будем передавать по сети. Если мы сможем сжать файлик до отправки в хранилище, то это хорошо налету. И это умеют почти все, вот. Главное там указать уровень сжатия.

![](https://habrastorage.org/webt/lv/pe/vd/lvpevdlrpqrg-9hypasdcs9-dse.png)

Сервисность, что тут у нас интересного по системам бэкапирования может быть.

- Мощный достаточно CLI — это довольно хорошая штука, потому что он нам позволяет прикрутится с точки зрения мониторинга к бэкапу и посмотреть там, сколько бэкапов у нас есть, к какой точке по времени мы можем восстановиться, можем вообще просто статус посмотреть утилиты. И в принципе все, кроме встроенных они имеют довольно хорошие CLI, полезный и его желательно изучать, когда выбираешь себе систему бэкапирования, чтобы знать какие возможности дает. Некоторые даже для мониторинга специальные команды имеют, чтобы вываливать в удобном читаемом формате данные, а там дальше просто распарсить их.
- Как выделенный сервис на отдельном сервере могут работать barman, pgbackrest и BART, все остальные должны стоять рядом с базой данных. И это плохо, потому что когда мы хотим собирать до 20-30 баз данных, а есть такие люди, у которых там развалено, то куда проще поменять конфик у сервиса на одном сервере, подцепить туда как бы точку базы данных откуда тянуть нам backup-ы и тянуть их и сваливать на один сервер выделенный для этого. Но, к сожалению, это позволяет делать вот немногие.
- Структурированное хранение бэкапов – это вот как раз важная вещь с точки зрения того, что мы могли быстренько посмотреть, за какие числа у нас есть backup-ы, какого они размера, валидные ли эти backup-ы. Есть ли у нас необходимое количество архивных логов для этого дела, для того чтобы восстановиться куда-то по времени дальше. Все утилиты сторонние это умеют это с разной степенью. Минимальный функционал в данном случае все предоставляют.
- Политики хранения – это то насколько долго нам необходимо хранить бэкап и насколько сама утилита бэкапирования может ротировать эти backup-ы, вовремя удалять ненужные, оставлять какие-то на долгое время. Вот все вот эти перечисленные, они имеют политику хранения, которую можно прописать в конфиге. И вы, прописав в конфиге, просто, когда в очередной раз утилитка запускается, она при снятии бэкапа или запихивания wal файла, она просто проверит, если что удалять в политике хранения и удалит. Случай с wal-e, wal-g, там нужно в крон запихать задачу, что мы удаляем backup старее или чем больше чем столько-то бекапов. Мы 7 backup храним у клиентов обычно.

![](https://habrastorage.org/webt/zj/r0/es/zjr0esauswimuw1itkqosshmyla.png)

Валидирование у backup. Хотелось бы, чтобы мы были уверены при снятии backup, потому что хороший backup это тот, который потом ещё поднят, поднят сервер и прогнали на нём теми тестами. Практика показывает, что среди наших клиентов никто не делает. Пока они мы не пришли, никто не делал. Потом начинают делать. Потому что на stage накатывают из дампа. Есть некоторые вещи, которые позволяют нам быть достаточно хорошо уверены, что у нас backup валидный. С помощью CLI можем посмотреть, что же там у нас сохранилось и валидный ли эти backup и как это проверяется.

Первое что нам интересно то, что мы действительно скопировали все файлы, которые нужны. Эти системы бэкапирования после того как зальют все файлы, должны показать что backup валидный. Пока бекап заливается, он должен быть в прогрессе. если отвалились, он должен быть фейл. В принципе, они все так умеют, хочется ещё больше, есть ещё больше вещи. Этот механизм checksum в PostgreSQL, он работает только в том случае, если вы включили у себя checksum в PostgreSQL. Если у вас база данных без checksum, к сожалению, никак не провериться. Вот эти вот две утилиты они в процессе снятия backup вообще ругаются, что у нас нет checksum. Если что-то не так произошло и проверяют в общем валидность файликов и блоков файликов по checksum. Второй пункт, который валидность завершение backup, там в процессе копирования снимается checksum файлика, он, когда скопирован checksum проверяется на хранилище. Это вот так мы валидируем.

![](https://habrastorage.org/webt/mj/_e/di/mj_edibaxks4v2_4-t5kanbxghe.png)

В принципе у меня получилось не очень много на удивление, обычно я дальше рассказываю. Это ссылочки по всем этим утилитам, которые могут, ну если какая-то приглянется, которую вы можете почитать конкретно. Тут все перечислены. Да я скину, только чуть-чуть попозже. Вот вообще, как это сказать, они в общем доступе, докладывает слайды готовые, так что можете там найти. В общем у меня всё, это довольно такая тема короткая, но я, когда смотрел, обзора полного нету, что могут делать тоже непонятно. В данном случае в основном было дать представление о том, кто что из них умеет. У меня будет не то после, где в зависимости от того, кто придет и что пожелает, мы настроим ту или иную систему бэкапирования прямо на практике. Тут сейчас, если есть вопросы, они должны быть по идее, задавайте, потому что говорить можно про это бесконечно, вот так что давайте по вопросам. Тут микрофон будут раздавать поэтому…

![](https://habrastorage.org/webt/tt/qn/i7/ttqni7mc49sw-n6bww9bpi1gese.png)



Вопрос: Вот вы сказали, что backup лучше снимать с мастера по причине, что реплика может там отстать, вывалиться из мониторинга, быть не актуальна. И соответственно уже есть даже такие методы, которые позволяют нам ограничить пропускную способность, чтобы не сильно нагружать мастера вовремя backup. А не лучше ли, как альтернативу, рассмотреть всё-таки бэ копирование реплики и одновременно, например, мониторить эту реплику, мониторить лак, отставание не реплики там, что ну как бы убеждаться, что она актуальна. Вот здесь есть какие-то может быть подводные камни?

Ответ: В таких случаях можно с реплики снимать, но в данном это если вы гарантированно уверены, что она не отстаёт и так далее. Большинстве случаев как настраивать бэкопирование. Настроили не забыли. Всё. Если что-то пошло не так, по таким причинам, которые ну backup снимется с реплики, если отвалилась, а качество настраиваемых мониторингов жизнь показала, что она в большинстве случаев ужасна. И конкретно с базами данных на них довольно частенько плюют, чтобы мониторить в необходимом количестве и реагировать на allure. Пришёл allure благ большой, один раз, второй, пришёл, она отвалилась allure перестали идти, что там как бы чек за мьюзер это Тайлер ты всё забыл, а потом через месяц оказывается оп, а у нас реплики нет, особенно если она не участвует в нагрузке. Если она в нагрузке участвует читающей, да вы это сразу обнаружить, если не участвуют, то поэтому сначала лучше настраивать на мастере. Просто не раз сталкивался с такими ситуациями, то что люди просто то как бы забили, мы вот как бы так, а потом выяснил что отвалилась.

Вопрос: Сравнивали ли вы производительность там, скорость, как они системы нагружают? Ну некоторые могут там несколько потоков забьют сеть, например, и так далее. 

Ответ: У нас есть только один проект на поддержки, где действительно ребята, сервис такой сетевой, на каждом сервере базы данных есть четыре интерфейса и это в их случае действительно там забивается интерфейс, то есть, есть один интерфейс для репликации, я есть один интерфейс для снятия этих backup и два интерфейса для обслуживания нагрузки от приложений. Во всех остальных случаях, сетевых интерфейсов хватает как правило. 

Вопрос: Скажите вашу любимую утилиту или вы выбираете под задачи?

Ответ: Это зависит от задач, я потому что что в облаках там особо нет вариантов нет в амазоне там wal-e, ну wal-g, без вариантов без вариантов. Сейчас я на pgbackrest в этом контексте попробую, потому что интересная штука. А так стандартно borman, pg_dum, в принципе basebackup. Всё зависит от того, что хочет у нас конкретно клиент, что он готов и какое оборудование предоставляет. Соответственно выбираем систему.

Вопрос: Скажите пожалуйста, могут ли быть или возникнуть какие-то сложности при использовании расширения postgres, добавление типа данных, например, postgis или чего-нибудь такого-либо?

Ответ: Потенциально вряд ли возможно, потому что к случаю бинарных backup мы копируем файлы, нам без разницы наполнение этих файлов. Postgres случай если checksum мы включим, postgres сам проверяет checksum, если кривой расширение, но она убьет вам базу и работающую. Вот, но это не postgis, допустим вы сами как-то там с логической репликации неудачно игрались. pg_dum он вообще шикарен в этом плане, потому что он вываливает, по сути дела. То есть его всегда можно развернуть в эскюэль команды. Надампил и вырезать ненужные вещи. Он кстати используется в этом плане как проверка возможности мажорного апгрейда. Когда мы снимаем dump, на катаем на новую версию база данных. К вот, а так, нет проблем, не возникает из-за расширения. Ещё вопросы вроде были.

Вопрос: Вы сказали, что причина реплики может станцевать, это единственная причина, по которой вы против бекапа или есть какие-то другие весомые? 

Ответ: Это основная самая важная причина, от бекапа к dumpa нам важно, чтобы всегда были актуальные данные на момент снятие ее. Если они не актуальны, ну то есть – это обычно как происходит, вот забили, потом что-то случилось, начали искать, а этого нету и все.

Ну если сделали дамбов, сначала проверили насколько реплик отстаем, если сильно, то как-нибудь запалились. 

Ну тут этот не вариант. 

Оба варианта.

Вот эта рекомендация снимает с мастера, это чисто человеческий фактор. Вот, просто она из-за человеческого фактора, потому что люди имеют тенденцию забивать.

Вопрос: Я понял, спасибо. И второй вопрос еще, я правильно понимаю, что в инструментах бинарных бэкапов, весь вот фракционный мусор, весь болот бэкапах идет?

Ответ: Да.

Вопрос: Все это многообразие — это хорошо, но в организациях бывает какое-то централизованное система резервных копирований, там симантек, капэбзек, виритос и другие. Умеют ли они работать с погрес?

Ну, в принципе их можно научить работать, потому что можно просто скопировать файлы.

Ну можно просто да, скрипты какие-то накидать.

Постгресту можно дать команду для бэкапирования, отправить им команду старбэкапу, ну там веточку поставить.

Ну в общем, через скрипты какие-то.

Да, шел скриптинг будет, но в принципе можно обучить систему.

Не слышно, чтобы какие-то системы пытались начать, нативно взаимодействовать.

Ну у нас в практике мы не сталкивались, просто…

Окей.

Вопрос: А расскажите, пожалуйста, по подробнее как вы валидируете бэкап, это, то есть только чиксом или есть еще какие-то техники, типа развернуть там, какие-то тесты.

Нормальной валидации бэкапа — это поднять этот бэкап в отдельную базу данных и запустить на нем приложение, ну то есть полезные валидации это когда у вас есть какой-то стейч сервер, где вы откатываете приложение, и вы этот стейч сервер обновляете, когда вы сделали бэкап, вы его обновили с новой версией. Вот это самое адекватное и интересный способ валидации. Можно просто поднять баз на отдельный сервер и прогнать какие-то тесты на целостность данных, вот. Но тесты целостность данных, они больше будут завязаны на бизнес-логику, потому что тут их нужно будет самим написать. Вот это самый правильные варианты, вот. Но на это тоже многие забивают. Так еще вот вопросы. 

Вопрос: Если представить ситуацию к примеру, что наш бэкап восстанавливается из рэгалогов лежавших на S3, если мы их будем тащить с помощью вали, валджи или с помощью каких-нибудь авэсклик к примеру, что из этого всего будет быстрее и будет ли быстрее.

Вот Андрею лучше ответит на этот вопрос. Давай, ты ответь на вопрос и задай следующий.

Слушай, я разработчик волджи поэтому расскажу, что быстрее. Валджи, конечно, ну то есть. Не ну я зачем разрабатывали валджи, если вали хорошо работал, вот. У меня доклад целый на сорок минут за счёт чего валджи быстрее, я не могу ответить, одним словом. Можно сказать, мы долго работали, да.

Да там честные параллелизм, более честные и хорошие.

Там параллелизм, там prefetch, мы закачиваем wal до того, как он тебе понадобился. Поэтому, когда вон там график был — это график, на самом деле упертый в кат вала, а не в этот самый. Но даже кат вала мы стараемся оптимизировать, подготавливая в page cache страницы базы данных, к тому, что к ним скоро подъедет wal, то есть там это не просто технология, которой типа заархивировала и поменьше данных унесла в сеть, там мы наворотили космоса всякого, сложно коротка сказать. Я хотел про валидацию сказать, вот мне кажется, что правильный способ Прове легировать PostgreSQL это дамп девнул, который проверяет если у тебя включенный контрольные суммы, он тебе проверит все контрольные суммы и проверит, что ты можешь прочитать все свои данные в базе данных. Но это еще недостаточно для полного смок теста, желательно делать амчек, который проверит инварианты корректности графа индексов и, если эти инварианты выполняются при этом мы знаем, что все контрольные суммы на странице графа корректны, мы можем говорить о том, что в базе данных логические ошибки отсутствуют. Вот, что я хотел сказать, спасибо.

Вот, услышали, как это сложно. Кто будет это делать поднимите руку, ага, ну. В тебе не сомневаюсь, потому что, судя по тому, как часто я вижу тебя с активностями разными то да. Вопросы еще есть? 

Вопрос: Да есть вопрос, небольшой такой специфический. Возможно кейс, вот у меня есть большая база данных 10 терабайт допустим, и я собираюсь делать массированные изменения в базе, но в любой момент мне захочется вернутся возможно вот в эту точку, причем сделать это быстро. Просто сделаю в бинарный дамп и волос соответствующий это потом будет достаточно долго накатывать, можно как-то вот зная, что мне эта точка нужна, ее…

Это просто отдельный сервер поднимать для базы данных.

То есть реплику делаем и останавливаем репликацию.

Да, вы ее отцепляете. Скорее всего это у вас миграция данных, обычно реплику просто отцепляют на этот момент и подразумевают то, что эту миграция данных может навернуть вашу бизнес логику, но с этим обычно…

То есть кроме реплики таких. 

Реплика, ну а все остальное оно упрется в копирование файлов, а тут у вас уже готовый инстас база данных, куда вы просто перекинете нагрузку в случае проблемы.

Я тоже хотел бы добавить чуть по предыдущему вопросу, есть погореваент, который позволяет вернуться в прошлое, но я не уверен, что он подходит для таких случаев, надо исследовать.

Для него нужен мастер, то есть он используется как, ну в общем копия нужна, смысл тратить на ревайнт времени, когда мы вот отцепили реплику, случилась проблема мы ее сделали мастером, старый мастер натравили на реплику. Для ревайнта нужен мастер, чтобы он блоки там откатил. В общем сомнительная туза и проще просто на реплику переключиться, и мастером ее сделать. 

А вот такой вопрос, по сути говоря если у нас в принципе база сама по себе целостная, то если мы снимаем дамп, то очень маленькая вероятность через pg_dump, то очень маленькая вероятность что он будет битый, ну дамп. Или это просто вот какая-то есть вероятность и все.

По-хорошему его нужно установить проверить, а вообще так да, ну как бы вероятность маленькая достаточно.

То есть скорее всего, грубо говоря дамп, битый то скорее всего проблема в базе, а не в чем-нибудь еще, что-то может пойти не так.

pg_dump не снимет у вас так, то есть не снимет этот дамп.

У меня просто снимал pg_dump, и он был битый, я не знаю, как это работало, но я не мог его накатить его после этого, он не писал ошибку.

Вы могли не накатить его просто по причине того, что у вас не хватало расширения какого-нибудь, криво расширения были поставлены. Например, витчстор 

База чистая была, без всего вообще. 

Ну не знаю, это надо посмотреть почему у вас так происходило, скорее всего просто сам файлик дамп каким-то образом побился.

Вопрос: Это уже не вопрос, это дополнение к предыдущему вопросу, почему бамп логически может побиться, остановиться. А потом молодой человек, который вопрос спрашивал, ну как раз к вашему вопросу дополнение могу сказать, что бывают такие случаи логический дамп останавливается. Например, у нас было пару случаев, когда был силок файл битый, и были покоцанный данные и по годам просто вот так вот внезапно останавливался, выдавал какую-то ошибку, но эксикод был нормальный как бы и все волбы вроде нормальный, а на самом деле дамп был битый, неполный. И не восстанавливался, и так что следите за этим. 

