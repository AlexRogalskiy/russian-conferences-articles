

![](https://habrastorage.org/webt/ht/t7/nd/htt7ndh6ckmduc_6afxebioa9hs.png)

В общем теперь официально здравствуйте, меня зовут Сальников Андрей, я сотрудник компании Data Egret и этот доклад будет посвящён инструментам создания бэкапов в PostgreSQL.

![](https://habrastorage.org/webt/qr/pa/mu/qrpamu1psbed1aonvt1shrrpedk.png)

Сначала о том, кто мы, моя компания в плане того, что основная наша деятельность — это мы работаем как удалённые администраторы и у нас достаточно большое количество клиентов. Есть огромные базы, есть куча маленьких баз, есть всевозможные смеси, когда одна большая база или кучка маленьких, или маленькие и не совсем маленькие. Также мы оказываем услуги консультирования аудита – это случай если людям не нужна поддержка постоянная, но нужна какая-то экспертиза. 
Так как PostgreS является опенс открытым продуктом, то мы, естественно, учувствуем всевозможных конференциях. В плане того, что делится своим опытом и всячески помогать продвижению PostgreSу. Потому что база данных она действительно хорошая. И получается так что мы видели довольно много профилей нагрузки и девехашные нагрузки, и вэб нагрузки, и смеси нагрузок. И базы падали по-разному, в общем опыта достаточно много.

![](https://habrastorage.org/webt/a0/vc/b_/a0vcb_l47qx4vvzh1hxnjcqesz4.png)

Вопрос такой, это самая кстати интересная часть слайда. Зачем нужны бэкапы? Скажет ну кто, на ваш взгляд. Еще варианты. А, ясно. Ну смотрите, на самом деле они нужны, чтобы мы могли отдыхать спокойно, чтобы могли спать спокойно, чтобы мы могли тусоваться на концертах спокойно, ну и такие случаи всякие. Вот, это основная цель с точки зрения дебазы зачем нужны бэкапы. Чтобы все было спокойно в нашей жизни. Потому что, если есть бэкапы проверенные, то мы можем всем этим заниматься. А вот что там с базой произойдет это уже дело десятое.

![](https://habrastorage.org/webt/dj/_9/aj/dj_9ajbympb3eslx0bl1phlp6te.png)

Какой есть ассортимент инструментов для создания бэкапов в мире PostgreSа. Это встроенный инструмент pg-dump, pg-dumpall или pg-restore для восстановления. Это единственный инструмент, который позволяет делать вам логическое бэкопирование. То есть pg-dump он вам может, как в поинте эксистель вывалить, так и в небольшом бинарном форматике вывалить данные. И он идет из коробки с Погресом. 
Следующий инструмент для создания бэкапов, который тоже идет из коробки и дальше начиная с этого инструмента, и дальше они все будут инструменты для создания бинарных бэкапов базы данных. Pg- basebackup тоже инструмент, идущий из коробки, который позволяет нам наливать реприки для постгриса. И соответственно снимать бинарную копию базы данных, снимать пенсистентную базу данных и если мы хотим еще во времени иметь возможность архивироваться, то мы можем настроить постгрес так, чтобы архивные логи его сваливать на какой-то диск. Это вот базовые инструменты. Они хорошие, они делают, выполняют свой функционал на пять, но они неудобные с точки зрения управления и какой-то массовости. Когда у вас 20 баз данных, это нужно будет вам заниматься шелскриптингом самостоятельно.
Следующие два инструмента специфичные, чисто облачные инструменты – это wal-e и wal-g. Разрабатывают их одни и те же ребята, но разработка вали закончилась, и они переключились на wal-g. Эти инструменты ориентированы для в основном для амазона и для хранения вэстри. Вали еще умеет работать с гугл клаудом, с азуром и с дисковой системой, просто вы можете указать какой-то удаленный диск. Валджи работает только с амазоном, только с вэстри. Ну или любым другим с эстри похожим интерфейсом. Мы их пользуем, хорошие штуки. Я дальше в деталях буду разбирать каждый инструмент.

![](https://habrastorage.org/webt/h_/cs/my/h_csmywtln65xfdmoryutenb6-g.png)

И на следующей пачке инструментов, это инструменты, которые опираются на пиджибэйс бикап или используют его сам, или каким-то образом реализуют его функционал. Они все написаны разработчиками, которые комедят в основной постгрейс, и имеют свой форб коммерческий, который продвигают в своем кругу влияния. 
Наиболее популярный инструмент бармен (barman), который у нас используется довольно широко по стране. Это по сути дела обертка на питоне вокруг джибейсбэкапа, еще он может работать по эссаш протоколам. Очень интересный и очень многообещающий инструмент pgbackrest. Он, я не помню от кого, но тоже ребята продвигают его, ну то есть занимаются постгресом и активно его комедят. Изначально он был написан на питоне, сейчас версия, которая используется она написана на сид для ускорения и возможности параллельного выполнения снятия бэкапов. 
Пиджипробэкап (Pg-probackup) – эта фтуза от наших коллег российских в постгрес профешенол, которая позволяет делать инкривинтальные бэкапы, такие достаточно маленького размера.
И последняя туза это backup and recover tool (BART) от компании энтерпрайз диби. У нас она не очень популярна, и она в основном для цинтоз и рейхад ветки линукса, для убунту с ней, по-моему, тяжело. И в связи с малой популярностью у нас ее почти нету нигде в инсталляциях. 

![](https://habrastorage.org/webt/ow/si/t8/owsit8h0n3welzlugm95_glqdds.png)

Дальше основные составляют, я бы попытался по этим инструментам, вообще, потому что мы хотим от бэ копирования, разбить на какие-то вещи, которые важны достаточно.
Первое нам важно, как мы будем это хранить, на каких дисках и на каких сервисах. И там есть список характеристик, по которым мы пройдемся. 
Следующее разделения данных, тут я подразделяю то, что можем ли мы при снятии бэкапа или восстановлении бэкапа, отпилить от целой истансбазы данных какой-то кусочек и работать дальше с ним как с целостным, с целостной базой. 
Насколько они поддерживают разные версии БД. 
Какие режимы работы у них есть. В плане параллельности, в плане какой-то автоматизации и тому подобное. 
И сервисность это насколько мы можем их выделить в отдельный сервер, который сам будет ходить по базам данных и по какому-то расписанию снимать бэкапы.
И давайте пойдем по этим с, какие характеристики нам. Еще валидирование. Валидирование — это, хотелось, чтобы бэкап еще проверялся в плане того, что мы из него гарантировано потом сможем восстановится и у нас будет нормальная, не поломанная база. 
И теперь вот, по этим шести большим пунктам пройдемся более детально. И буду помечать там какой инструмент, что нам даст. 

![](https://habrastorage.org/webt/s5/v0/h0/s5v0h0p62rsqz1r86v2upwibj5c.png)

По хранению, в файловой системе хранить они могут все, то есть мы может перемонтировать диск наш к операционке и сваливать туда бэкапы. Все инструменты это позволяют делать. Это в принципе тоже самое, потому что это в нашей локальной файловой системе получается.
В амазоне у нас могут работать три инструмента -это валджи, вали, причем тут ходит коллега, который занимается разработкой валджи, вали, вы его можете поймать из компании Яндекс, их двое кстати товарищей ходит. Сюда они еще не дошли, хотя обещали. 
А еще пиджибакрест позволяет работать, сваливать бэкапы в эстри, и эти он очень интересен. Потому что среди вот таких туз, бармен и так далее, он единственный, который умеет работать с амазоном. 
С азуром и так далее только вали. Гугл только вали, вот. 
Кто-нибудь, кстати, пользует азур, гугл для своих баз данных. Да, у вас без вариантов ребята. Если вы хотите их облачными хранилищами пользоваться. 
Я сталкивался с азуром, но там как бы сталкивался в плане миграции на амазон базы данных. 

![](https://habrastorage.org/webt/gw/sc/qd/gwscqdmvmqlbe1r1e545ipkemzs.png)

Дальше по хранению. Логическую копию данных нам предоставляет только pg_dump, pg_dumpall. Разница между ними, то что dump_all обрабатывает весь сбор базы данных, в pg_dumpall вы можете указать конкретную базу данных на инстенсе и работать с ней.
Бинарный копии - все остальные. Об этом уже говорил. Немаловажный фактор при хранении, это то что, если у нас ограничено каким-то образом по дисковым ресурсам, то частенько возникают ситуации, когда мы разбиваем базу данных по разным табличное пространствам. Это верная и для железных серверов, потому что не хочется там мучиться и добавляешь новый. Это верно для облаков, потому что потому что там есть определенное ограничение, особенно когда берете тачку с нве дисками и там как бы их сколько воткнуто, столько воткнуто. У амазона там расширяется, можно с ебс дисками. И при восстановлении данных, нам будет важно, что мы могли бы перераспределить эти табличные пространства, назначить их по новым путям и на новые диски. И вот это хорошее свойство присутствует у Wal-e. В wаl-g пока не умеют с этим работать. Probackup умеют с этим работать. Barman, basebackup, pgbackrest. Довольно широкий спектр инструментов и эта вещь бывает довольно часто важно, особенно когда да у вас 8-ми, 10-ти терабайтные базы данных. У нас среди клиентов production почти все эти базы данных развалены по табличным пространствам, или 2 или 3 табличных пространства. 

![](https://habrastorage.org/webt/qd/-v/sk/qd-vskcocq-r2tv0duopeyxtvke.png)

Теперь другая вещь. О том, какого размера у нас могут быть backup. Это всё пойдёт в контексте бинарных backup. Понятное дело, что бинарные backup-это сколько у нас база весит, столько мы и скопировали. Весит 8 терабайт, мы скопировали 8 терабайт. 1 мегабайт весит 1 мегабайт, скопировали. Как экономить место, когда мы хотим длинную цепочку backupов? Для этого придумали некоторые инструменты. То есть, база данных хранит данные в своих файликах, если у нас допустим какая-то это длина архивная база данных, понятное дело, что мы меняем там небольшой процент этих файлов. И для этого дела придумали дифференциальные backupы.
Дифференциальный backup что из себя представляет? Мы смотрим какие файлики изменились и только копируем на хранилище, где хранить backup. А все остальные файлы мы хардлинком просто присобачиваем к этой базе данных. Получается, что мы тем самым экономя место. И при этом можем спокойно удалить старые backupы база данных, не попортив более свежие. Эта штука хорошая, но решили пойти дальше и придумали инкрементальные backup, их две штуки есть. Вы заодно для себя помечается, какие инструменты с этим умеют работать. Инкрементальные backupы есть два вида. Первый это на файловом уровне. Дифференциальный backup отличается только тем, что дифференциальный ориентируется у вас на полный backup базы данных, и по отношению к нему как раз вот этот диф файл и копирует. Инкрементальный backup может ориентироваться на дифференциальные backupы, копирует только те изменившиеся файлы, которые изменились по сравнению с дифференциальным backup. Для инкрементального нужна будет цепочка. То есть основной backup. 1 инкрементальный backup он всегда будет дифференциальным и дальше там вот эти все инкрементальные backupы. Дифференциальный backup всегда ориентируется на полный backup базы данных. Инкрементальный может на другие виды backup. 
Ребята ещё сделали в двух компаниях, это вот postgres professional, там кстати как-то не всё видно, что ли получается, картинка. Pg_probackup и enterprise dbm, система хранения backup они пошли по другому пути инкрементальных. Это по блоку, потому что в файлики мы можем изменить не весь файлик, а блок данных, которые мы изменили. И они, эти тузы, они бегут по wal файлам и выбирают у вас ровно те блоки, которые изменились и backup сваливают именно вот это блоки. Для того, чтобы восстановиться с таким backup инкрементальным, вам тоже нужна будет полная копия базы данных, и плюс ещё можно сохранить вот эти инкриминальные кусочки, которые набирают из wal-оф. Это накладывает некоторые ограничения утилиты, потому что они должны бегать по в walфайлам. Для ванильного postgresа они всегда бегают, у postgres professional для версии у них там ещё один слой на файловую структуру базы данных наложен. Они довольно быстро эти блоки ищут. Такие инкрементальные backup получаются совсем маленькими. Если у вас меняется небольшой процент базы, потому что wal файл пишется довольно много технической информации. И вырезая там 16 мегабайт, они вырезают реально там по десятке килобайтов для backup.

![](https://habrastorage.org/webt/s3/d9/ca/s3d9ca1otjtkwql3_qakv67am7c.png)

Дальше разделение данных. Тут подразумевается то, что, если нам нужно копировать не всё. Или устанавливать не всё. Это возможно только при логических backup, и это нам позволяет делать только pg_dump. Утилиты довольно широкий функционал предоставляют. Pg_dump может позволить вам без данных сдампить базу данных, структуру, если вам нужна. Можете конкретно одну таблицу сдампить или можете исключить одну таблицу из дампа или список таблиц сдампить, список исключить. Функционал довольно широкий в этом плане. Минус за это то, что при восстановлении с такого дампа, если у вас большая база данных, вам придется потратить достаточно много времени на чтобы восстановиться с него, потому что это всё нужно проигрывать на чистом instance и postgres. 
Очень удобны эти утилиты использовать случай, когда мы переоценили свои силы и на создавали кучу мелких баз данных. Мы можем их слить в один instance. Мы можем распилить так, если мы опять теперь оценили наши силы, у нас распухла база данных или меняем архитектуру там с монолита на сервисную и распиливаем данные. Pg_dump в этом случае единственная вещь, которая позволяет это делать болезненно. Ещё можно восстановить одну БД и вот тут вот указан pgbackrest. У него есть такая фишка, то что мы можем указать, что нам из бинарного backup нужна только одна база данных. 
Что он делает? Он восстанавливает база данных по умолчанию из backup, это template и postgres и ту базу данных, которую мы указали. Все остальные базы данных, он файлики обнуляет и делает нулевой длины. То есть у postgres прозрачная структура хранения баз данных в файликах, там можно на этом уровне, как бы сократить восстанавливаемую базу данных. Допустим нам нужно найти какие срочные данные из бинарника, не хочется вести терабайтную базу поднимать, у нас там две базы, и мы поднимаем одну, которая допустим там пять всего терабайт занимает, то есть две по десять были. В данном случае, конечно консистентность нарушается, но для каких-то быстрых решений, когда вам необходимо срочно кровь из носа поднять данные с большой базы данных, который их несколько, то это очень хорошие фичи, которые есть. Но как полноценную базу, это не стоит рассматривать при восстановлении. То есть, это именно для аварийных работ.



![](https://habrastorage.org/webt/bq/pf/aj/bqpfaj0wvrtn1atsq0yj1j4x7de.png)

Как обстоит работа с множеством версий БД? Тут тоже всё достаточно интересно. Pg_dump очень хорош в плане того, что мы не привязаны к тому, в какую версию БД восстанавливаться. Там есть режим point текста и это просто чисто SQL который описывает всю структуру баз данных, все данные. Вы можете в принципе оттуда восстановиться куда хотите, mail SQL, s SQL, vertical, с небольшими правками этого дампа. Ну и соответственно между версиями postgres мажорными тоже достаточно легко гуляет вот эти лампы. 
Мульти-версионность, что под этим подразумеваю? Это то, что насколько туза может обрабатывать разные версии баз данных и работать одновременно с десятым postgres, с 9.6, с одиннадцатым, все, кроме встроенных от Pg_dump и pg_basebackup, потому что они привязаны к конкретной версии, с которой идут. Остальные ориентируется на эти утилиты, и им подсовывается можно, ну говоришь, где находится все эти pg_basebackup разных версий, и они соответственно с версией postgres выбирают актуальную утилиту для снятия backup. 
Для создания реплик, сэнпай серверов подходят все утилиты, кроме пиджидампа, потому что это логические вэкапы. Вот, и используя любую из этих утилит вы можете, как бы, восстановить серверы и подключить к мастеру для работы, как реплика этого сервера. Тут кстати не политкорректность в плане реплик, а мы у себя это давно используем это слово, вот. 

![](https://habrastorage.org/webt/rk/mr/jp/rkmrjpvyme8ifuybv7jvpkqd0r4.png)

Следящее это как могут сниматься бэкапы вообще, какие режимы существуют для снятия бэкапов. Можно просто копировать файлы стандартными средствами операционки, то есть используется пэаш протокол и использует для этого ирспи и возможно какие-то другие утилиты, которые есть. Почему такая возможность есть, потому что они позволяют параллелить копирование и делать это в несколько потоков. Pgbackrest и barman позволяют так работать, бакрест только так работает, бармен он может работать так, а может работать по протоколу постгресовому.
Протокол постгреса, который, когда утилита бэ копирования подключается к постгресу и по протоколу репликации тянет, собственно говоря, все файлики и плюс еще архивные логи, которые возникают в процессе снятия бэкапа. Это умеют все остальные и бармен. Все остальные это инерлаз, диби, пиджи, бэйбекап в общем из того списка, вали и так далее.
Бэкап с реплики умеют в принципе все, это зависит от версии пострегса. С десятки и одиннадцатого мы можем с реплики снимать бэкапы. Но я этого не рекомендую делать, вообще никто из нашей компании не будет это рекомендовать делать, потому что есть ситуации, когда проморгали по мониторингу, месяц снимали с реплики бэкап, которая отвалилась от мастер-сервера и не актуальна. То есть бэкапы в любом случае всегда нужно снимать с мастер-сервера. Только в таком случае вы будете уверены то, что у вас действительно актуальная бэкап база данных. 
Многопоточность бэкапов -это умеют все, потому что все по разным причинам, кто-то через эссаш протокол, кто-то реализовал на уровне подсасывания базы данных. Кроме байзбэкапа и барта, потому что барта операция только на бэйсбэкап при снятии бэкапа и он, к сожалению, однопоточный и не будет многопоточный.

![](https://habrastorage.org/webt/72/4x/j0/724xj0dcehoennfciyo2uzucisq.png)

Ага, это я хотел вам показать в плане того, что многопоточность и воткнул картинку. У меня была ситуации восстанавливал восьми терабайтную базу данных и когда будете ориентироваться на выбор системы для снятия бэкапов, вали написан на питоне, валджи написан на гош и мне восьми терабайтную базу приходилось восстанавливать, вали уперся в ограничение питона и тянул меня с амазона со скоростью 600 килобит в секунду, щас Мегабит в секунду и все никак выше. Когда я переключился на валджи, ну там оказывается вали был косяк в плане того, что он не мог, точнее в валджи был баг, он не мог работать с бэкапами вали, но мог тянуть волфайлы. Поэтому вот эта вот картинка маленькая, это я снял, восстановил базу данных, а дальше накатывал валы, которые лежали там в эстри и к определенной точке во времени восстанавливался. И вот тут-то валджи, ну они оба параллелелятся, но вали уперся в ограничение питона и параллелизм в питоне она такой условный, а валджи уперся по сути дела в интерфейс эстри, то есть насколько быстрый эстри каждый момент мог отдавать, настолько быстро он и забирал.
В среднем это было два гигабита в секунду, что достаточно хорошо, вот. То есть с вали ребят час изменений в базу на получали за 45 минут проигрывания за счет того, что, ну высасывал с такой скоростью. С валджи получилось, что они час изменения базы данных накатывали где-то минут за 5, вот. 
И как бы на восьми терабайтной баз данных, когда там изменения наваливаются сопоставимыми количествами, то терабайт — это довольно актуальная вещь. 

![](https://habrastorage.org/webt/rj/nk/fa/rjnkfaa9ld-am4dazwrasjqwfbk.png)



Режимы работы, что тут есть у нас интересного в системе бэ копирования. Восстановление во времени к определенной точки. Если у нас есть архивные логи, и мы их копируем, мы можем восстановить. Позволяет это делать система бэ копирования, это как бы стандарт фактор. Главное, чтобы мы хранили валфайлы где-нибудь. Дампы, естественно, это не умеют, потому что они немножечко о другом. 
Регулировка нагрузки на сеть – это довольно важная вещь, потому что как я говорил снимать дамп с матер-сервера желательно, тогда вы себе гарантируете то, что вы действительно актуальные бэка получаете. Ну иногда бывает сервера настолько нагружены, что вклинится туда довольно сложно. 
У нас некоторые клиенты втыкают отдельный сетевой интерфейс. Иногда там минимальные время нагрузки делается, а еще хорошо, когда если мы можем как-то отрегулировать сетевую нагрузку на сервер и что сказать тяни бэка вот с такой скоростью. Это позволяет делать базбэка, бармен и барт, это таки конфигурационные параметры имеют. В принципе вали, валджи тоже позволяют через параллельность, то есть меньше потоков дал, нет? Да, ясно. Я просто не обновлялся за последние два месяца. Ну вот вали, валджи тоже умеют регулировать нагрузку на сеть и это очень полезные свойства. 
Следующий фактор — это сжатие на лету и тут в принципе, ну то есть это опять-таки вопрос того сколько мы будем передавать по сети. Если мы сможем сжать файлик до отправки в хранилище, то это хорошо налету. И это умеют почти все, вот. Главное там указать уровень сжатия.

![](https://habrastorage.org/webt/lv/pe/vd/lvpevdlrpqrg-9hypasdcs9-dse.png)

Сервисность, что тут у нас интересного по системам бэ копирования может быть. Мощный достаточно силай — это довольно хорошая штука, потому что он нам позволяет прикрутится с точки зрения мониторинга к бэкапу и посмотреть там, сколько бэкапов у нас есть, какой точке по времени мы можем восстановиться, можем вообще просто статус посмотреть утилиты. И в принципе все, кроме встроенных они имеют довольно хорошие силай, полезный и его желательно изучать, когда выбираешь себе систему бэ копирования, чтобы знать какие возможности дает. Некоторые даже для мониторинга специальные команды имеют, чтобы вываливать в удобном читаемом формате данные, а там дальше просто распарсить их и, как по простенькому и все.
Как выделенный сервис на отдельном сервере могут работать бармен, баскрет и барт, все остальные должны стоять рядом с базой данных. И это плохо, потому что когда мы хотим собирать до 20-30 баз данных, а есть такие люди, у которых там развалено, то куда проще поменять конфик у сервиса на одном сервере, подцепить туда как бы точку базы данных откуда тянуть нам бэкапы и тянуть их и сваливать на один сервер выделенный для этого. Но, к сожалению, это позволяет делать вот немногие.
Структурированное хранение бэкапов – это вот как раз важная вещь с точки зрения того, что мы могли быстренько посмотреть, за какие числа у нас есть бэкапы, какого они размера, валидные ли эти бэкапы. Есть ли у нас необходимое количество архивных логов для этого дела, для того чтобы восстановиться куда-то по времени дальше. Все тузы сторонние невстроенные, они это умеют это с разной степенью хорошисте. Ну в принципе минимальный функционал в данном случае все предоставляют.
Политики хранения – это то насколько долго нам необходимо хранить бэкап и насколько сама утилита бэ копирования может ратировать эти бэкапы, вовремя удалять ненужные, оставлять какие-то на долгое время. Вот все вот эти перечисленные, они имеют политику хранения, которую можно прописать в конфиге. И вы, прописав в конфиге, просто, когда в очередной раз утилитка запускается, она при снятии бэкапа или запихивания вал файла, она просто проверит, если что удалять в политике хранения и удалит. Случай с wal-e, wal-g, там нужно в крон запихать задачу, что мы удаляем backup, там далее старее чем столько-то количество, ну мы по количеству удаляем. Мы семь backup храним у клиентов обычно, я не знаю, по времени там можно посмотреть Андрей? Вот, wal-e тоже позволяет через крон назначать такую политику. 

![](https://habrastorage.org/webt/zj/r0/es/zjr0esauswimuw1itkqosshmyla.png)

Валидирование у backup. Хотелось бы, чтобы мы были уверены при снятии backupа, потому что хороший backup это тот, который потом ещё поднят, поднят сервер и прогнали на нём теми тестами, кто это делает. Вот две руки, уже шесть, да. Так ну, практика показывает, что делают среди наших клиентов никто не делает. Пока они не пришли, никто не делает, хотя потом начинает делать, потому что Настей накатывает из дампа, какие-то утилитки пишем, есть некоторые вещи, которые позволяют нам быть не стопроцентно, но достаточно хорошо уверены, что у нас backup валидный приснятии. Во-первых, с помощью силая посмотреть, что же там у нас сохранилось и валидный ли эти backup и как это проверяется. 
Есть несколько вариантов, первое что нам интересно то, что мы действительно скопировали все файлы, которые нужны эти системы бэ копирования после того как зальют все файлики, должны поставить что backup валидный пока заливают, он должен быть в прогрессе, если отвалились, он должен быть фейл. В принципе, они все так умеют, хочется ещё больше, есть ещё больше вещи. Этот механизм checksum в postgres, он работает только в том случае, если вы включили у себя checksum в postgres. Если у вас база данных без checksum, к сожалению, никак не провериться. Вот эти вот две утилиты они в процессе снятия backup вообще ругаются, что у нас нет checksum. Если что-то не так произошло и проверяют в общем валидность файликов и блоков файликов по checksum. Второй пункт, который валидность завершение backup, там в процессе копирования снимается checksum файлика, он, когда скопирован checksum проверяется на хранилище. Это вот так мы валидируем.

![](https://habrastorage.org/webt/mj/_e/di/mj_edibaxks4v2_4-t5kanbxghe.png)

В принципе у меня получилось не очень много на удивление, обычно я дальше рассказываю. Это ссылочки по всем этим утилитам, которые могут, ну если какая-то приглянется, которую вы можете почитать конкретно. Тут все перечислены. Да я скину, только чуть-чуть попозже. Вот вообще, как это сказать, они в общем доступе, докладывает слайды готовые, так что можете там найти. В общем у меня всё, это довольно такая тема короткая, но я, когда смотрел, обзора полного нету, что могут делать тоже непонятно. В данном случае в основном было дать представление о том, кто что из них умеет. У меня будет не то после, где в зависимости от того, кто придет и что пожелает, мы настроим ту или иную систему бэ копирования прямо на практике. Тут сейчас, если есть вопросы, они должны быть по идее, задавайте, потому что говорить можно про это бесконечно, вот так что давайте по вопросам. Тут микрофон будут раздавать поэтому…

![](https://habrastorage.org/webt/tt/qn/i7/ttqni7mc49sw-n6bww9bpi1gese.png)



Вопрос: Вот вы сказали, что backup лучше снимать с мастера по причине, что реплика может там отстать, вывалиться из мониторинга, быть не актуальна. И соответственно уже есть даже такие методы, которые позволяют нам ограничить пропускную способность, чтобы не сильно нагружать мастера вовремя backup. А не лучше ли, как альтернативу, рассмотреть всё-таки бэ копирование реплики и одновременно, например, мониторить эту реплику, мониторить лак, отставание не реплики там, что ну как бы убеждаться, что она актуальна. Вот здесь есть какие-то может быть подводные камни?

Ответ: В таких случаях можно с реплики снимать, но в данном это если вы гарантированно уверены, что она не отстаёт и так далее. Большинстве случаев как настраивать бэкопирование. Настроили не забыли. Всё. Если что-то пошло не так, по таким причинам, которые ну backup снимется с реплики, если отвалилась, а качество настраиваемых мониторингов жизнь показала, что она в большинстве случаев ужасна. И конкретно с базами данных на них довольно частенько плюют, чтобы мониторить в необходимом количестве и реагировать на allure. Пришёл allure благ большой, один раз, второй, пришёл, она отвалилась allure перестали идти, что там как бы чек за мьюзер это Тайлер ты всё забыл, а потом через месяц оказывается оп, а у нас реплики нет, особенно если она не участвует в нагрузке. Если она в нагрузке участвует читающей, да вы это сразу обнаружить, если не участвуют, то поэтому сначала лучше настраивать на мастере. Просто не раз сталкивался с такими ситуациями, то что люди просто то как бы забили, мы вот как бы так, а потом выяснил что отвалилась.

Вопрос: Сравнивали ли вы производительность там, скорость, как они системы нагружают? Ну некоторые могут там несколько потоков забьют сеть, например, и так далее. 

У нас есть только один проект на поддержки, где действительно ребята, сервис такой сетевой, на каждом сервере базы данных есть четыре интерфейса и это в их случае действительно там забивается интерфейс, то есть, есть один интерфейс для репликации, я есть один интерфейс для снятия этих backup и два интерфейса для обслуживания нагрузки от приложений. Во всех остальных случаях, сетевых интерфейсов хватает как правило. 

Вопрос: Скажите вашу любимую утилиту или вы выбираете под задачи?

Это зависит от задач, я потому что что в облаках там особо нет вариантов нет в амазоне там wal-e, ну wal-g, без вариантов без вариантов. Сейчас я на pgbackrest в этом контексте попробую, потому что интересная штука. А так стандартно borman, pg_dum, в принципе basebackup. Всё зависит от того, что хочет у нас конкретно клиент, что он готов и какое оборудование предоставляет. Соответственно выбираем систему.

Вопрос: Скажите пожалуйста, могут ли быть или возникнуть какие-то сложности при использовании расширения postgres, добавление типа данных, например, postgis или чего-нибудь такого-либо?

Потенциально вряд ли возможно, потому что к случаю бинарных backup мы копируем файлы, нам без разницы наполнение этих файлов. Postgres случай если checksum мы включим, postgres сам проверяет checksum, если кривой расширение, но она убьет вам базу и работающую. Вот, но это не postgis, допустим вы сами как-то там с логической репликации неудачно игрались. pg_dum он вообще шикарен в этом плане, потому что он вываливает, по сути дела. То есть его всегда можно развернуть в эскюэль команды. Надампил и вырезать ненужные вещи. Он кстати используется в этом плане как проверка возможности мажорного апгрейда. Когда мы снимаем dump, на катаем на новую версию база данных. К вот, а так, нет проблем, не возникает из-за расширения. Ещё вопросы вроде были.

Вопрос: Вы сказали, что причина реплики может станцевать, это единственная причина, по которой вы против бекапа или есть какие-то другие весомые? 

Это основная самая важная причина, от бекапа к dumpa нам важно, чтобы всегда были актуальные данные на момент снятие ее. Если они не актуальны, ну то есть – это обычно как происходит, вот забили, потом что-то случилось, начали искать, а этого нету и все.

Ну если сделали дамбов, сначала проверили насколько реплик отстаем, если сильно, то как-нибудь запалились. 

Ну тут этот не вариант. 

Оба варианта.

Вот эта рекомендация снимает с мастера, это чисто человеческий фактор. Вот, просто она из-за человеческого фактора, потому что люди имеют тенденцию забивать.

Я понял, спасибо. И второй вопрос еще, я правильно понимаю, что в инструментах бинарных бэкапов, весь вот фракционный мусор, весь болот бэкапах идет?

Да.

Я понял, спасибо.

Вопрос: Все это многообразие — это хорошо, но в организациях бывает какое-то централизованное система резервных копирований, там симантек, капэбзек, виритос и другие. Умеют ли они работать с погрес?

Ну, в принципе их можно научить работать, потому что можно просто скопировать файлы.

Ну можно просто да, скрипты какие-то накидать.

Постгресту можно дать команду для бэ копирования, отправить им команду старбэкапу, ну там веточку поставить.

Ну в общем, через скрипты какие-то.

Да, шел скриптинг будет, но в принципе можно обучить систему.

Не слышно, чтобы какие-то системы пытались начать, нативно взаимодействовать.

Ну у нас в практике мы не сталкивались, просто…

Окей.

Вопрос: А расскажите, пожалуйста, по подробнее как вы валидируете бэкап, это, то есть только чиксом или есть еще какие-то техники, типа развернуть там, какие-то тесты.

Нормальной валидации бэкапа — это поднять этот бэкап в отдельную базу данных и запустить на нем приложение, ну то есть полезные валидации это когда у вас есть какой-то стейч сервер, где вы откатываете приложение, и вы этот стейч сервер обновляете, когда вы сделали бэкап, вы его обновили с новой версией. Вот это самое адекватное и интересный способ валидации. Можно просто поднять баз на отдельный сервер и прогнать какие-то тесты на целостность данных, вот. Но тесты целостность данных, они больше будут завязаны на бизнес-логику, потому что тут их нужно будет самим написать. Вот это самый правильные варианты, вот. Но на это тоже многие забивают. Так еще вот вопросы. 

Вопрос: Если представить ситуацию к примеру, что наш бэкап восстанавливается из рэгалогов лежавших на истри, если мы их будем тащить с помощью вали, валджи или с помощью каких-нибудь авэсклик к примеру, что из этого всего будет быстрее и будет ли быстрее.

Вот Андрею лучше ответит на этот вопрос. Давай, ты ответь на вопрос и задай следующий.

Слушай, я разработчик волджи поэтому расскажу, что быстрее. Валджи, конечно, ну то есть. Не ну я зачем разрабатывали валджи, если вали хорошо работал, вот. У меня доклад целый на сорок минут за счёт чего валджи быстрее, я не могу ответить, одним словом. Можно сказать, мы долго работали, да.

Да там честные параллелизм, более честные и хорошие.

Там параллелизм, там прифейч, мы закачиваем вал до того, как он тебе понадобился. Поэтому, когда вон там график был — это график, на самом деле упертый в кат вала, а не в этот самый. Но даже кат вала мы стараемся оптимизировать, подготавливая в пейдкэше страницы базы данных, к тому, что к ним скоро подъедет вал, то есть там это не просто технология, которой типа заархивировала и поменьше данных унесла в сеть, там мы наворотили космоса всякого, сложно коротка сказать. Я хотел про валидацию сказать, вот мне кажется, что правильный способ Прове легировать постгрес это дамп девнул, который проверяет если у тебя включенный контрольные суммы, он тебе проверит все контрольные суммы и проверит, что ты можешь прочитать все свои данные в базе данных. Но это еще недостаточно для полного смок теста, желательно делать амчек, который проверит инварианты корректности графа индексов и, если эти инварианты выполняются при этом мы знаем, что все контрольные суммы на странице графа корректны, мы можем говорить о том, что в базе данных логические ошибки отсутствуют. Вот, что я хотел сказать, спасибо.

Вот, услышали, как это сложно. Кто будет это делать поднимите руку, ага, ну. В тебе не сомневаюсь, потому что, судя по тому, как часто я вижу тебя с активностями разными то да. Вопросы еще есть? 

Вопрос: Да есть вопрос, небольшой такой специфический. Возможно кейс, вот у меня есть большая база данных 10 терабайт допустим, и я собираюсь делать массированные изменения в базе, но в любой момент мне захочется вернутся возможно вот в эту точку, причем сделать это быстро. Просто сделаю в бинарный дамп и волос соответствующий это потом будет достаточно долго накатывать, можно как-то вот зная, что мне эта точка нужна, ее…

Это просто отдельный сервер поднимать для базы данных.

То есть реплику делаем и останавливаем репликацию.

Да, вы ее отцепляете. Скорее всего это у вас миграция данных, обычно реплику просто отцепляют на этот момент и подразумевают то, что эту миграция данных может навернуть вашу бизнес логику, но с этим обычно…

То есть кроме реплики таких. 

Реплика, ну а все остальное оно упрется в копирование файлов, а тут у вас уже готовый инстас база данных, куда вы просто перекинете нагрузку в случае проблемы.

Хорошо, спасибо.

Так.

Я тоже хотел бы добавить чуть по предыдущему вопросу, есть погореваент, который позволяет вернуться в прошлое, но я не уверен, что он подходит для таких случаев, надо исследовать.

Для него нужен мастер, то есть он используется как, ну в общем копия нужна, смысл тратить на ревайнт времени, когда мы вот отцепили реплику, случилась проблема мы ее сделали мастером, старый мастер натравили на реплику. Для ревайнта нужен мастер, чтобы он блоки там откатил. В общем сомнительная туза и проще просто на реплику переключиться, и мастером ее сделать. 

А вот такой вопрос, по сути говоря если у нас в принципе база сама по себе целостная, то если мы снимаем дамп, то очень маленькая вероятность через пэгэдам, то очень маленькая вероятность что он будет битый, ну дамп. Или это просто вот какая-то есть вероятность и все.

По-хорошему его нужно установить проверить, а вообще так да, ну как бы вероятность маленькая достаточно.

То есть скорее всего, грубо говоря дамп, битый то скорее всего проблема в базе, а не в чем-нибудь еще, что-то может пойти не так.

Пиджидамп не снимет у вас так, то есть не снимет этот дамп.

У меня просто снимал погэдэ дамп, и он был битый, я не знаю, как это работало, но я не мог его накатить его после этого, он не писал ошибку.

Вы могли не накатить его просто по причине того, что у вас не хватало расширения какого-нибудь, криво расширения были поставлены. Например, витчстор 

База чистая была, без всего вообще. 

Ну не знаю, это надо посмотреть почему у вас так происходило, скорее всего просто сам файлик дамп каким-то образом побился.

Спасибо

Вот. Чем меньше доклад, тем больше вопросов. 

Вопрос: Это уже не вопрос, это дополнение к предыдущему вопросу, почему бамп логически может побиться, остановиться. А потом молодой человек, который вопрос спрашивал, ну как раз к вашему вопросу дополнение могу сказать, что бывают такие случаи логический дамп останавливается. Например, у нас было пару случаев, когда был силок файл битый, и были покоцанный данные и по годам просто вот так вот внезапно останавливался, выдавал какую-то ошибку, но эксикод был нормальный как бы и все волбы вроде нормальный, а на самом деле дамп был битый, неполный. И не восстанавливался, и так что следите за этим. 

